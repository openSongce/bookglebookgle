"""
Gemini 2.0 Flash ê¸°ë°˜ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ì„œë¹„ìŠ¤
OCR ê²°ê³¼ í…ìŠ¤íŠ¸ì˜ í’ˆì§ˆì„ LLMì„ í†µí•´ í–¥ìƒì‹œí‚¤ëŠ” ì„œë¹„ìŠ¤
"""

import asyncio
import time
import json
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import asdict

from loguru import logger

from src.models.ocr_models import (
    OCRBlock, ProcessedOCRBlock, TextCorrection, CorrectionType
)
from src.services.llm_client import LLMClient, LLMProvider
from src.utils.position_mapper import PositionMapper


class TextPostProcessor:
    """Gemini 2.0 Flash ê¸°ë°˜ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, llm_client: LLMClient):
        """
        í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ê¸° ì´ˆê¸°í™”
        
        Args:
            llm_client: LLM í´ë¼ì´ì–¸íŠ¸ ì¸ìŠ¤í„´ìŠ¤
        """
        self.llm_client = llm_client
        self.model = "gemini-2.0-flash"
        self.batch_size = 100  # ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸° (API í˜¸ì¶œ ê°ì†Œë¥¼ ìœ„í•´ 10 -> 100ìœ¼ë¡œ ìƒí–¥)
        self.max_retries = 3  # ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜
        
        # Gemini 2.0 Flash ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        self.system_prompt = """ë‹¹ì‹ ì€ OCR í…ìŠ¤íŠ¸ êµì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë‹¤ìŒ ê·œì¹™ì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ êµì •í•´ì£¼ì„¸ìš”:

ğŸ“‹ êµì • ê·œì¹™:
1. ë§ì¶¤ë²•ê³¼ ë„ì–´ì“°ê¸° ì˜¤ë¥˜ë¥¼ ì •í™•íˆ ìˆ˜ì •
2. ë¬¸ë²•ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ê°œì„ 
3. ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ë§ ê²ƒ
4. ì›ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´ì™€ ë¹„ìŠ·í•˜ê²Œ ìœ ì§€ (Â±20% ì´ë‚´)
5. í•œêµ­ì–´ì™€ ì˜ì–´ í˜¼ì¬ ë¬¸ì„œ ì²˜ë¦¬ ê°€ëŠ¥
6. ìˆ«ì, ê¸°í˜¸, íŠ¹ìˆ˜ë¬¸ìëŠ” ì‹ ì¤‘í•˜ê²Œ ì²˜ë¦¬

ğŸ“¤ ì‘ë‹µ í˜•ì‹:
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{
  "corrected_text": "êµì •ëœ í…ìŠ¤íŠ¸",
  "corrections": [
    {
      "original": "ì›ë³¸ ë‹¨ì–´/êµ¬ë¬¸",
      "corrected": "êµì •ëœ ë‹¨ì–´/êµ¬ë¬¸", 
      "type": "spelling|grammar|spacing|style|punctuation",
      "confidence": 0.95,
      "explanation": "êµì • ì´ìœ "
    }
  ],
  "confidence": 0.92
}

âš ï¸ ì£¼ì˜ì‚¬í•­:
- êµì •ì´ ë¶ˆí•„ìš”í•œ ê²½ìš° corrections ë°°ì—´ì„ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜
- confidenceëŠ” 0.0~1.0 ì‚¬ì´ì˜ ê°’
- ì‘ë‹µì€ ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ì´ì–´ì•¼ í•¨"""
        
        logger.info(f"ğŸ¤– TextPostProcessor initialized:")
        logger.info(f"   ğŸ¯ Model: {self.model}")
        logger.info(f"   ğŸ“¦ Batch size: {self.batch_size}")
        logger.info(f"   ğŸ”„ Max retries: {self.max_retries}")
    
    async def process_text_blocks(
        self, 
        ocr_blocks: List[OCRBlock],
        enable_batch_processing: bool = True
    ) -> List[ProcessedOCRBlock]:
        """
        OCR ë¸”ë¡ë“¤ì„ ë°°ì¹˜ë¡œ í›„ì²˜ë¦¬
        
        Args:
            ocr_blocks: ì›ë³¸ OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            enable_batch_processing: ë°°ì¹˜ ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
            
        Returns:
            ProcessedOCRBlock ë¦¬ìŠ¤íŠ¸
        """
        if not ocr_blocks:
            logger.warning("âš ï¸ No OCR blocks to process")
            return []
        
        start_time = time.time()
        logger.info(f"ğŸš€ Starting text post-processing for {len(ocr_blocks)} blocks")
        
        try:
            if enable_batch_processing and len(ocr_blocks) > 1:
                processed_blocks = await self._process_blocks_in_batches(ocr_blocks)
            else:
                processed_blocks = await self._process_blocks_individually(ocr_blocks)
            
            total_time = time.time() - start_time
            
            # ì²˜ë¦¬ í†µê³„ ë¡œê¹…
            total_corrections = sum(len(block.corrections) for block in processed_blocks)
            avg_confidence = sum(block.processing_confidence for block in processed_blocks) / len(processed_blocks)
            
            logger.info(f"âœ… Text post-processing completed:")
            logger.info(f"   â±ï¸ Total time: {total_time:.2f}s")
            logger.info(f"   ğŸ“Š Blocks processed: {len(processed_blocks)}")
            logger.info(f"   ğŸ”§ Total corrections: {total_corrections}")
            logger.info(f"   ğŸ¯ Average confidence: {avg_confidence:.3f}")
            logger.info(f"   âš¡ Speed: {len(processed_blocks)/total_time:.1f} blocks/sec")
            
            return processed_blocks
            
        except Exception as e:
            logger.error(f"âŒ Text post-processing failed: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¸”ë¡ë“¤ì„ ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
            return self._create_fallback_processed_blocks(ocr_blocks, str(e))
    
    async def _process_blocks_in_batches(self, ocr_blocks: List[OCRBlock]) -> List[ProcessedOCRBlock]:
        """
        ìµœì í™”ëœ ë°°ì¹˜ ë‹¨ìœ„ ë¸”ë¡ ì²˜ë¦¬
        ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì • ë° ë³‘ë ¬ ì²˜ë¦¬ ì§€ì›
        """
        processed_blocks = []
        
        # ë™ì  ë°°ì¹˜ í¬ê¸° ê²°ì •
        optimal_batch_size = self._calculate_optimal_batch_size(ocr_blocks)
        
        # ë¸”ë¡ë“¤ì„ ìµœì í™”ëœ ë°°ì¹˜ë¡œ ë¶„í• 
        batches = self._create_smart_batches(ocr_blocks, optimal_batch_size)
        
        logger.info(f"ğŸ“¦ Processing {len(batches)} batches (optimal size: {optimal_batch_size})")
        
        # ë°°ì¹˜ë³„ ì²˜ë¦¬ í†µê³„
        batch_stats = {
            'total_batches': len(batches),
            'successful_batches': 0,
            'failed_batches': 0,
            'total_processing_time': 0,
            'total_corrections': 0
        }
        
        for batch_idx, batch in enumerate(batches):
            try:
                batch_start_time = time.time()
                
                # ë°°ì¹˜ ì „ì²˜ë¦¬ (í…ìŠ¤íŠ¸ í’ˆì§ˆ í™•ì¸)
                filtered_batch = self._preprocess_batch(batch)
                
                if not filtered_batch:
                    logger.warning(f"âš ï¸ Batch {batch_idx + 1} is empty after preprocessing")
                    continue
                
                # ë°°ì¹˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ
                batch_texts = [block.text for block in filtered_batch]
                
                # LLMìœ¼ë¡œ ë°°ì¹˜ êµì • (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
                correction_results = await self._correct_text_batch_with_retry(
                    batch_texts, batch_idx + 1
                )
                
                # ProcessedOCRBlock ìƒì„±
                batch_processed = self._create_processed_blocks_from_results(
                    filtered_batch, correction_results
                )
                
                processed_blocks.extend(batch_processed)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                batch_time = time.time() - batch_start_time
                batch_corrections = sum(len(block.corrections) for block in batch_processed)
                
                batch_stats['successful_batches'] += 1
                batch_stats['total_processing_time'] += batch_time
                batch_stats['total_corrections'] += batch_corrections
                
                logger.info(f"âœ… Batch {batch_idx + 1}/{len(batches)} completed:")
                logger.info(f"   â±ï¸ Time: {batch_time:.2f}s")
                logger.info(f"   ğŸ”§ Corrections: {batch_corrections}")
                logger.info(f"   ğŸ“Š Blocks: {len(batch_processed)}")
                
            except Exception as e:
                logger.error(f"âŒ Batch {batch_idx + 1} processing failed: {e}")
                batch_stats['failed_batches'] += 1
                
                # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” fallback ì²˜ë¦¬
                fallback_blocks = self._create_fallback_processed_blocks(batch, str(e))
                processed_blocks.extend(fallback_blocks)
        
        # ìµœì¢… í†µê³„ ë¡œê¹…
        self._log_batch_processing_stats(batch_stats)
        
        return processed_blocks
    
    def _calculate_optimal_batch_size(self, ocr_blocks: List[OCRBlock]) -> int:
        """
        OCR ë¸”ë¡ íŠ¹ì„±ì— ë”°ë¥¸ ìµœì  ë°°ì¹˜ í¬ê¸° ê³„ì‚°
        
        Args:
            ocr_blocks: OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ìµœì  ë°°ì¹˜ í¬ê¸°
        """
        total_blocks = len(ocr_blocks)
        avg_text_length = sum(len(block.text) for block in ocr_blocks) / total_blocks
        
        # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¥¸ ë°°ì¹˜ í¬ê¸° ì¡°ì • (ë” ê³µê²©ì ìœ¼ë¡œ ì„¤ì •)
        if avg_text_length < 50:  # ì§§ì€ í…ìŠ¤íŠ¸
            optimal_size = min(100, total_blocks)
        elif avg_text_length < 150:  # ë³´í†µ í…ìŠ¤íŠ¸
            optimal_size = min(50, total_blocks)
        elif avg_text_length < 300:  # ê¸´ í…ìŠ¤íŠ¸
            optimal_size = min(25, total_blocks)
        else:  # ë§¤ìš° ê¸´ í…ìŠ¤íŠ¸
            optimal_size = min(10, total_blocks)
        
        # ìµœì†Œ/ìµœëŒ€ ì œí•œ
        optimal_size = max(1, min(optimal_size, self.batch_size))
        
        logger.debug(f"ğŸ“Š Batch size optimization:")
        logger.debug(f"   ğŸ“ Avg text length: {avg_text_length:.1f}")
        logger.debug(f"   ğŸ“¦ Optimal batch size: {optimal_size}")
        
        return optimal_size
    
    def _create_smart_batches(
        self, 
        ocr_blocks: List[OCRBlock], 
        batch_size: int
    ) -> List[List[OCRBlock]]:
        """
        ìŠ¤ë§ˆíŠ¸ ë°°ì¹˜ ìƒì„± (ìœ ì‚¬í•œ íŠ¹ì„±ì˜ ë¸”ë¡ë“¤ì„ ê·¸ë£¹í™”)
        
        Args:
            ocr_blocks: OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸°
            
        Returns:
            ìµœì í™”ëœ ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸
        """
        # ë¸”ë¡ë“¤ì„ íŠ¹ì„±ë³„ë¡œ ì •ë ¬ (í˜ì´ì§€ ë²ˆí˜¸, í…ìŠ¤íŠ¸ ê¸¸ì´ ìˆœ)
        sorted_blocks = sorted(
            ocr_blocks, 
            key=lambda b: (b.page_number, len(b.text), b.confidence)
        )
        
        # ê¸°ë³¸ ë°°ì¹˜ ë¶„í• 
        batches = [
            sorted_blocks[i:i + batch_size] 
            for i in range(0, len(sorted_blocks), batch_size)
        ]
        
        return batches
    
    def _preprocess_batch(self, batch: List[OCRBlock]) -> List[OCRBlock]:
        """
        ë°°ì¹˜ ì „ì²˜ë¦¬ (í’ˆì§ˆì´ ë‚®ì€ ë¸”ë¡ í•„í„°ë§)
        
        Args:
            batch: ì›ë³¸ ë°°ì¹˜
            
        Returns:
            í•„í„°ë§ëœ ë°°ì¹˜
        """
        filtered_batch = []
        
        for block in batch:
            # ìµœì†Œ í…ìŠ¤íŠ¸ ê¸¸ì´ í™•ì¸
            if len(block.text.strip()) < 2:
                logger.debug(f"âš ï¸ Skipping block with too short text: '{block.text}'")
                continue
            
            # ì‹ ë¢°ë„ í™•ì¸
            if block.confidence < 0.1:
                logger.debug(f"âš ï¸ Skipping block with low confidence: {block.confidence}")
                continue
            
            # íŠ¹ìˆ˜ ë¬¸ìë§Œ ìˆëŠ” ë¸”ë¡ ì œì™¸
            if re.match(r'^[^\w\sê°€-í£]+$', block.text.strip()):
                logger.debug(f"âš ï¸ Skipping block with only special characters: '{block.text}'")
                continue
            
            filtered_batch.append(block)
        
        logger.debug(f"ğŸ“‹ Batch preprocessing: {len(batch)} â†’ {len(filtered_batch)} blocks")
        return filtered_batch
    
    async def _correct_text_batch_with_retry(
        self, 
        text_batch: List[str], 
        batch_number: int
    ) -> List[Dict[str, Any]]:
        """
        ì¬ì‹œë„ ë¡œì§ì´ ê°•í™”ëœ ë°°ì¹˜ í…ìŠ¤íŠ¸ êµì •
        
        Args:
            text_batch: êµì •í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            batch_number: ë°°ì¹˜ ë²ˆí˜¸ (ë¡œê¹…ìš©)
            
        Returns:
            êµì • ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        last_error = None
        
        for attempt in range(self.max_retries):
            try:
                # ë°°ì¹˜ í¬ê¸°ì— ë”°ë¥¸ íƒ€ì„ì•„ì›ƒ ì¡°ì •
                timeout_seconds = 30 + (len(text_batch) * 2)
                
                # ë¹„ë™ê¸° íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ êµì • ìˆ˜í–‰
                correction_task = self._correct_text_batch(text_batch)
                correction_results = await asyncio.wait_for(
                    correction_task, 
                    timeout=timeout_seconds
                )
                
                if correction_results and len(correction_results) == len(text_batch):
                    logger.debug(f"âœ… Batch {batch_number} correction successful (attempt {attempt + 1})")
                    return correction_results
                else:
                    logger.warning(f"âš ï¸ Batch {batch_number} incomplete results (attempt {attempt + 1})")
                    last_error = "Incomplete correction results"
                
            except asyncio.TimeoutError:
                last_error = f"Timeout after {timeout_seconds}s"
                logger.warning(f"â° Batch {batch_number} timeout (attempt {attempt + 1})")
                
            except Exception as e:
                last_error = str(e)
                logger.warning(f"âš ï¸ Batch {batch_number} correction failed (attempt {attempt + 1}): {e}")
            
            # ì¬ì‹œë„ ì „ ëŒ€ê¸° (ì§€ìˆ˜ ë°±ì˜¤í”„)
            if attempt < self.max_retries - 1:
                wait_time = 0.5 * (2 ** attempt)  # 0.5s, 1s, 2s
                await asyncio.sleep(wait_time)
        
        logger.error(f"âŒ Batch {batch_number} failed after {self.max_retries} attempts: {last_error}")
        return self._create_fallback_correction_results(text_batch)
    
    def _log_batch_processing_stats(self, stats: Dict[str, Any]):
        """ë°°ì¹˜ ì²˜ë¦¬ í†µê³„ ë¡œê¹…"""
        total_batches = stats['total_batches']
        successful_batches = stats['successful_batches']
        failed_batches = stats['failed_batches']
        total_time = stats['total_processing_time']
        total_corrections = stats['total_corrections']
        
        success_rate = (successful_batches / total_batches * 100) if total_batches > 0 else 0
        avg_time_per_batch = (total_time / successful_batches) if successful_batches > 0 else 0
        
        logger.info(f"ğŸ“Š Batch processing statistics:")
        logger.info(f"   âœ… Success rate: {success_rate:.1f}% ({successful_batches}/{total_batches})")
        logger.info(f"   âŒ Failed batches: {failed_batches}")
        logger.info(f"   â±ï¸ Avg time per batch: {avg_time_per_batch:.2f}s")
        logger.info(f"   ğŸ”§ Total corrections: {total_corrections}")
        logger.info(f"   âš¡ Processing speed: {successful_batches/total_time:.1f} batches/sec")
    
    async def _process_blocks_individually(self, ocr_blocks: List[OCRBlock]) -> List[ProcessedOCRBlock]:
        """ê°œë³„ ë¸”ë¡ ë‹¨ìœ„ë¡œ ì²˜ë¦¬"""
        processed_blocks = []
        
        logger.info(f"ğŸ”„ Processing blocks individually")
        
        for idx, block in enumerate(ocr_blocks):
            try:
                block_start_time = time.time()
                
                # ë‹¨ì¼ í…ìŠ¤íŠ¸ êµì •
                correction_results = await self._correct_text_batch([block.text])
                
                # ProcessedOCRBlock ìƒì„±
                if correction_results:
                    processed_block = self._create_processed_blocks_from_results(
                        [block], correction_results
                    )[0]
                else:
                    processed_block = self._create_fallback_processed_blocks([block], "No correction result")[0]
                
                processed_blocks.append(processed_block)
                
                block_time = time.time() - block_start_time
                logger.debug(f"âœ… Block {idx + 1}/{len(ocr_blocks)} completed in {block_time:.3f}s")
                
            except Exception as e:
                logger.error(f"âŒ Block {idx + 1} processing failed: {e}")
                fallback_block = self._create_fallback_processed_blocks([block], str(e))[0]
                processed_blocks.append(fallback_block)
        
        return processed_blocks
    
    async def _correct_text_batch(self, text_batch: List[str]) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ë°°ì¹˜ë¥¼ Gemini 2.0 Flashë¡œ êµì •
        
        Args:
            text_batch: êµì •í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµì • ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if not text_batch:
            return []
        
        # ë°°ì¹˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
        batch_prompt = self._create_batch_prompt(text_batch)
        
        # LLM í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
        for attempt in range(self.max_retries):
            try:
                response = await self._call_gemini_flash(
                    prompt=batch_prompt,
                    max_tokens=2000,  # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
                    temperature=0.2   # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ temperature
                )
                
                # ì‘ë‹µ íŒŒì‹±
                correction_results = self._parse_correction_response(response, len(text_batch))
                
                if correction_results:
                    logger.debug(f"âœ… Batch correction successful (attempt {attempt + 1})")
                    return correction_results
                else:
                    logger.warning(f"âš ï¸ Empty correction results (attempt {attempt + 1})")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Correction attempt {attempt + 1} failed: {e}")
                if attempt == self.max_retries - 1:
                    logger.error(f"âŒ All correction attempts failed")
                    return self._create_fallback_correction_results(text_batch)
                
                # ì¬ì‹œë„ ì „ ì ì‹œ ëŒ€ê¸°
                await asyncio.sleep(0.5 * (attempt + 1))
        
        return self._create_fallback_correction_results(text_batch)
    
    def _create_batch_prompt(self, text_batch: List[str]) -> str:
        """ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if len(text_batch) == 1:
            return f"""ë‹¤ìŒ OCR í…ìŠ¤íŠ¸ë¥¼ êµì •í•´ì£¼ì„¸ìš”:

í…ìŠ¤íŠ¸: "{text_batch[0]}"

ìœ„ì—ì„œ ì„¤ëª…í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
        
        # ë‹¤ì¤‘ í…ìŠ¤íŠ¸ ë°°ì¹˜ ì²˜ë¦¬
        numbered_texts = []
        for i, text in enumerate(text_batch, 1):
            numbered_texts.append(f"{i}. \"{text}\"")
        
        texts_str = "\n".join(numbered_texts)
        
        return f"""ë‹¤ìŒ {len(text_batch)}ê°œì˜ OCR í…ìŠ¤íŠ¸ë¥¼ ê°ê° êµì •í•´ì£¼ì„¸ìš”:

{texts_str}

ê° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë³„ë„ì˜ JSON ê°ì²´ë¡œ ì‘ë‹µí•˜ë˜, ì „ì²´ë¥¼ JSON ë°°ì—´ë¡œ ê°ì‹¸ì£¼ì„¸ìš”:
[
  {{ "corrected_text": "...", "corrections": [...], "confidence": 0.95 }},
  {{ "corrected_text": "...", "corrections": [...], "confidence": 0.92 }},
  ...
]"""
    
    async def _call_gemini_flash(
        self,
        prompt: str,
        max_tokens: int = 1000,
        temperature: float = 0.2
    ) -> str:
        """
        Gemini 2.0 Flash ëª¨ë¸ í˜¸ì¶œ
        
        Args:
            prompt: ì…ë ¥ í”„ë¡¬í”„íŠ¸
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            temperature: ìƒì„± ì˜¨ë„
            
        Returns:
            LLM ì‘ë‹µ í…ìŠ¤íŠ¸
        """
        try:
            response = await self.llm_client.generate_completion(
                prompt=prompt,
                system_message=self.system_prompt,
                max_tokens=max_tokens,
                temperature=temperature,
                provider=LLMProvider.GEMINI,
                model=self.model
            )
            
            return response.strip()
            
        except Exception as e:
            logger.error(f"âŒ Gemini Flash API call failed: {e}")
            raise
    
    def _parse_correction_response(self, response: str, expected_count: int) -> List[Dict[str, Any]]:
        """
        LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµì • ê²°ê³¼ ì¶”ì¶œ
        
        Args:
            response: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            expected_count: ì˜ˆìƒë˜ëŠ” ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            êµì • ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # JSON ì‘ë‹µ íŒŒì‹± ì‹œë„
            if response.startswith('[') and response.endswith(']'):
                # ë°°ì—´ í˜•íƒœ ì‘ë‹µ
                results = json.loads(response)
                if isinstance(results, list) and len(results) == expected_count:
                    return self._validate_correction_results(results)
            else:
                # ë‹¨ì¼ ê°ì²´ ì‘ë‹µ
                result = json.loads(response)
                if isinstance(result, dict) and expected_count == 1:
                    return self._validate_correction_results([result])
            
            logger.warning(f"âš ï¸ Unexpected response format or count mismatch")
            return []
            
        except json.JSONDecodeError as e:
            logger.warning(f"âš ï¸ JSON parsing failed: {e}")
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œ ì‹œë„
            return self._extract_from_text_response(response, expected_count)
        
        except Exception as e:
            logger.error(f"âŒ Response parsing failed: {e}")
            return []
    
    def _validate_correction_results(self, results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """êµì • ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦"""
        validated_results = []
        
        for result in results:
            try:
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(key in result for key in ['corrected_text', 'corrections', 'confidence']):
                    logger.warning(f"âš ï¸ Missing required fields in correction result")
                    continue
                
                # ì‹ ë¢°ë„ ë²”ìœ„ í™•ì¸
                confidence = float(result['confidence'])
                if not 0.0 <= confidence <= 1.0:
                    logger.warning(f"âš ï¸ Invalid confidence value: {confidence}")
                    result['confidence'] = max(0.0, min(1.0, confidence))
                
                # corrections ë°°ì—´ ê²€ì¦
                corrections = result['corrections']
                if not isinstance(corrections, list):
                    logger.warning(f"âš ï¸ Invalid corrections format")
                    result['corrections'] = []
                
                validated_results.append(result)
                
            except Exception as e:
                logger.warning(f"âš ï¸ Result validation failed: {e}")
                continue
        
        return validated_results
    
    def _extract_from_text_response(self, response: str, expected_count: int) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ì‘ë‹µì—ì„œ êµì • ì •ë³´ ì¶”ì¶œ (fallback)"""
        logger.info("ğŸ”„ Attempting to extract correction info from text response")
        
        # ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ êµì •ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        results = []
        
        # "êµì •ëœ í…ìŠ¤íŠ¸:" ë˜ëŠ” "corrected:" íŒ¨í„´ ì°¾ê¸°
        corrected_patterns = [
            r'êµì •ëœ?\s*í…ìŠ¤íŠ¸\s*[:ï¼š]\s*["\']?([^"\'\n]+)["\']?',
            r'corrected[_\s]*text\s*[:ï¼š]\s*["\']?([^"\'\n]+)["\']?',
            r'ìˆ˜ì •ëœ?\s*í…ìŠ¤íŠ¸\s*[:ï¼š]\s*["\']?([^"\'\n]+)["\']?'
        ]
        
        for pattern in corrected_patterns:
            matches = re.findall(pattern, response, re.IGNORECASE | re.MULTILINE)
            if matches:
                for match in matches[:expected_count]:
                    results.append({
                        'corrected_text': match.strip(),
                        'corrections': [],
                        'confidence': 0.7  # ê¸°ë³¸ ì‹ ë¢°ë„
                    })
                break
        
        return results[:expected_count]
    
    def _create_fallback_correction_results(self, text_batch: List[str]) -> List[Dict[str, Any]]:
        """êµì • ì‹¤íŒ¨ ì‹œ fallback ê²°ê³¼ ìƒì„±"""
        return [
            {
                'corrected_text': text,
                'corrections': [],
                'confidence': 0.5  # ë‚®ì€ ì‹ ë¢°ë„ë¡œ ì„¤ì •
            }
            for text in text_batch
        ]
    
    def _create_processed_blocks_from_results(
        self,
        original_blocks: List[OCRBlock],
        correction_results: List[Dict[str, Any]]
    ) -> List[ProcessedOCRBlock]:
        """êµì • ê²°ê³¼ë¡œë¶€í„° ProcessedOCRBlock ìƒì„±"""
        processed_blocks = []
        
        for block, result in zip(original_blocks, correction_results):
            try:
                # TextCorrection ê°ì²´ë“¤ ìƒì„±
                corrections = []
                for corr_data in result.get('corrections', []):
                    try:
                        correction = TextCorrection(
                            original=corr_data.get('original', ''),
                            corrected=corr_data.get('corrected', ''),
                            correction_type=CorrectionType(corr_data.get('type', 'grammar')),
                            confidence=float(corr_data.get('confidence', 0.8)),
                            explanation=corr_data.get('explanation', '')
                        )
                        corrections.append(correction)
                    except Exception as e:
                        logger.warning(f"âš ï¸ Failed to create TextCorrection: {e}")
                        continue
                
                # ProcessedOCRBlock ìƒì„±
                processed_block = ProcessedOCRBlock(
                    text=result['corrected_text'],
                    page_number=block.page_number,
                    bbox=block.bbox,  # ì›ë³¸ ìœ„ì¹˜ ì •ë³´ ë³´ì¡´
                    confidence=block.confidence,
                    block_type=block.block_type,
                    original_text=block.text,
                    corrections=corrections,
                    processing_confidence=float(result['confidence']),
                    llm_model=self.model
                )
                
                processed_blocks.append(processed_block)
                
            except Exception as e:
                logger.error(f"âŒ Failed to create ProcessedOCRBlock: {e}")
                # ì‹¤íŒ¨ ì‹œ fallback ë¸”ë¡ ìƒì„±
                fallback_block = self._create_fallback_processed_blocks([block], str(e))[0]
                processed_blocks.append(fallback_block)
        
        return processed_blocks
    
    def _create_fallback_processed_blocks(
        self, 
        original_blocks: List[OCRBlock], 
        error_message: str
    ) -> List[ProcessedOCRBlock]:
        """ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ fallback ProcessedOCRBlock ìƒì„±"""
        fallback_blocks = []
        
        for block in original_blocks:
            fallback_block = ProcessedOCRBlock(
                text=block.text,  # ì›ë³¸ í…ìŠ¤íŠ¸ ìœ ì§€
                page_number=block.page_number,
                bbox=block.bbox,
                confidence=block.confidence,
                block_type=block.block_type,
                original_text=block.text,
                corrections=[],  # êµì • ì—†ìŒ
                processing_confidence=0.0,  # ì²˜ë¦¬ ì‹¤íŒ¨ í‘œì‹œ
                llm_model=f"{self.model} (failed: {error_message[:50]})"
            )
            fallback_blocks.append(fallback_block)
        
        return fallback_blocks
    
    def get_processor_info(self) -> Dict[str, Any]:
        """í›„ì²˜ë¦¬ê¸° ì •ë³´ ë°˜í™˜"""
        return {
            "processor_name": "TextPostProcessor",
            "llm_model": self.model,
            "batch_size": self.batch_size,
            "max_retries": self.max_retries,
            "system_prompt_length": len(self.system_prompt),
            "llm_client_available": self.llm_client is not None
        }  
  
    def analyze_correction_quality(
        self, 
        processed_blocks: List[ProcessedOCRBlock]
    ) -> Dict[str, Any]:
        """
        êµì • í’ˆì§ˆ ë¶„ì„ ë° í‰ê°€
        
        Args:
            processed_blocks: ì²˜ë¦¬ëœ OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í’ˆì§ˆ ë¶„ì„ ê²°ê³¼
        """
        if not processed_blocks:
            return {"error": "No processed blocks to analyze"}
        
        # ê¸°ë³¸ í†µê³„
        total_blocks = len(processed_blocks)
        blocks_with_corrections = sum(1 for block in processed_blocks if block.has_corrections)
        total_corrections = sum(block.correction_count for block in processed_blocks)
        
        # êµì • ìœ í˜•ë³„ í†µê³„
        correction_type_stats = {}
        confidence_scores = []
        processing_confidences = []
        text_length_changes = []
        
        for block in processed_blocks:
            processing_confidences.append(block.processing_confidence)
            
            # í…ìŠ¤íŠ¸ ê¸¸ì´ ë³€í™” ë¶„ì„
            original_length = len(block.original_text)
            corrected_length = len(block.text)
            if original_length > 0:
                length_change_ratio = corrected_length / original_length
                text_length_changes.append(length_change_ratio)
            
            # êµì • ìœ í˜•ë³„ ë¶„ì„
            for correction in block.corrections:
                correction_type = correction.correction_type.value
                if correction_type not in correction_type_stats:
                    correction_type_stats[correction_type] = {
                        'count': 0,
                        'total_confidence': 0.0,
                        'examples': []
                    }
                
                correction_type_stats[correction_type]['count'] += 1
                correction_type_stats[correction_type]['total_confidence'] += correction.confidence
                confidence_scores.append(correction.confidence)
                
                # ì˜ˆì‹œ ìˆ˜ì§‘ (ìµœëŒ€ 3ê°œ)
                if len(correction_type_stats[correction_type]['examples']) < 3:
                    correction_type_stats[correction_type]['examples'].append({
                        'original': correction.original,
                        'corrected': correction.corrected,
                        'confidence': correction.confidence
                    })
        
        # í‰ê·  ê³„ì‚°
        avg_processing_confidence = sum(processing_confidences) / len(processing_confidences)
        avg_correction_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
        avg_length_change = sum(text_length_changes) / len(text_length_changes) if text_length_changes else 1.0
        
        # êµì • ìœ í˜•ë³„ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        for type_name, stats in correction_type_stats.items():
            if stats['count'] > 0:
                stats['avg_confidence'] = stats['total_confidence'] / stats['count']
            else:
                stats['avg_confidence'] = 0.0
        
        # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0-100)
        quality_score = self._calculate_quality_score(
            avg_processing_confidence,
            avg_correction_confidence,
            blocks_with_corrections / total_blocks,
            avg_length_change
        )
        
        return {
            "overall_stats": {
                "total_blocks": total_blocks,
                "blocks_with_corrections": blocks_with_corrections,
                "correction_rate": blocks_with_corrections / total_blocks,
                "total_corrections": total_corrections,
                "avg_corrections_per_block": total_corrections / total_blocks,
                "quality_score": quality_score
            },
            "confidence_analysis": {
                "avg_processing_confidence": avg_processing_confidence,
                "avg_correction_confidence": avg_correction_confidence,
                "processing_confidence_range": {
                    "min": min(processing_confidences),
                    "max": max(processing_confidences)
                },
                "correction_confidence_range": {
                    "min": min(confidence_scores) if confidence_scores else 0.0,
                    "max": max(confidence_scores) if confidence_scores else 0.0
                }
            },
            "text_change_analysis": {
                "avg_length_change_ratio": avg_length_change,
                "length_preserved_blocks": sum(1 for ratio in text_length_changes if 0.9 <= ratio <= 1.1),
                "significantly_changed_blocks": sum(1 for ratio in text_length_changes if ratio < 0.8 or ratio > 1.2)
            },
            "correction_type_breakdown": correction_type_stats
        }
    
    def _calculate_quality_score(
        self,
        processing_confidence: float,
        correction_confidence: float,
        correction_rate: float,
        length_change_ratio: float
    ) -> float:
        """
        ì¢…í•© í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
        
        Args:
            processing_confidence: í‰ê·  ì²˜ë¦¬ ì‹ ë¢°ë„
            correction_confidence: í‰ê·  êµì • ì‹ ë¢°ë„
            correction_rate: êµì • ë¹„ìœ¨
            length_change_ratio: í‰ê·  ê¸¸ì´ ë³€í™” ë¹„ìœ¨
            
        Returns:
            í’ˆì§ˆ ì ìˆ˜ (0-100)
        """
        # ê°€ì¤‘ì¹˜ ì„¤ì •
        weights = {
            'processing_confidence': 0.4,
            'correction_confidence': 0.3,
            'correction_rate': 0.2,
            'length_preservation': 0.1
        }
        
        # ê¸¸ì´ ë³´ì¡´ ì ìˆ˜ (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜)
        length_preservation_score = 1.0 - abs(length_change_ratio - 1.0)
        length_preservation_score = max(0.0, min(1.0, length_preservation_score))
        
        # êµì • ë¹„ìœ¨ ì ìˆ˜ (ì ì ˆí•œ êµì • ë¹„ìœ¨: 0.2-0.8)
        if 0.2 <= correction_rate <= 0.8:
            correction_rate_score = 1.0
        elif correction_rate < 0.2:
            correction_rate_score = correction_rate / 0.2
        else:  # correction_rate > 0.8
            correction_rate_score = max(0.0, 1.0 - (correction_rate - 0.8) / 0.2)
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        quality_score = (
            processing_confidence * weights['processing_confidence'] +
            correction_confidence * weights['correction_confidence'] +
            correction_rate_score * weights['correction_rate'] +
            length_preservation_score * weights['length_preservation']
        ) * 100
        
        return round(quality_score, 2)
    
    def generate_correction_report(
        self, 
        processed_blocks: List[ProcessedOCRBlock]
    ) -> str:
        """
        êµì • ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            processed_blocks: ì²˜ë¦¬ëœ OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            í…ìŠ¤íŠ¸ í˜•íƒœì˜ ë¦¬í¬íŠ¸
        """
        quality_analysis = self.analyze_correction_quality(processed_blocks)
        
        if "error" in quality_analysis:
            return f"ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {quality_analysis['error']}"
        
        overall = quality_analysis["overall_stats"]
        confidence = quality_analysis["confidence_analysis"]
        text_change = quality_analysis["text_change_analysis"]
        correction_types = quality_analysis["correction_type_breakdown"]
        
        report_lines = [
            "=" * 60,
            "ğŸ“Š OCR í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬ ê²°ê³¼ ë¦¬í¬íŠ¸",
            "=" * 60,
            "",
            "ğŸ“ˆ ì „ì²´ í†µê³„:",
            f"  â€¢ ì´ ë¸”ë¡ ìˆ˜: {overall['total_blocks']:,}ê°œ",
            f"  â€¢ êµì •ëœ ë¸”ë¡ ìˆ˜: {overall['blocks_with_corrections']:,}ê°œ ({overall['correction_rate']:.1%})",
            f"  â€¢ ì´ êµì • ìˆ˜: {overall['total_corrections']:,}ê°œ",
            f"  â€¢ ë¸”ë¡ë‹¹ í‰ê·  êµì • ìˆ˜: {overall['avg_corrections_per_block']:.2f}ê°œ",
            f"  â€¢ ì¢…í•© í’ˆì§ˆ ì ìˆ˜: {overall['quality_score']:.1f}/100",
            "",
            "ğŸ¯ ì‹ ë¢°ë„ ë¶„ì„:",
            f"  â€¢ í‰ê·  ì²˜ë¦¬ ì‹ ë¢°ë„: {confidence['avg_processing_confidence']:.3f}",
            f"  â€¢ í‰ê·  êµì • ì‹ ë¢°ë„: {confidence['avg_correction_confidence']:.3f}",
            f"  â€¢ ì²˜ë¦¬ ì‹ ë¢°ë„ ë²”ìœ„: {confidence['processing_confidence_range']['min']:.3f} ~ {confidence['processing_confidence_range']['max']:.3f}",
            "",
            "ğŸ“ í…ìŠ¤íŠ¸ ë³€í™” ë¶„ì„:",
            f"  â€¢ í‰ê·  ê¸¸ì´ ë³€í™” ë¹„ìœ¨: {text_change['avg_length_change_ratio']:.3f}",
            f"  â€¢ ê¸¸ì´ ë³´ì¡´ëœ ë¸”ë¡: {text_change['length_preserved_blocks']:,}ê°œ",
            f"  â€¢ í¬ê²Œ ë³€ê²½ëœ ë¸”ë¡: {text_change['significantly_changed_blocks']:,}ê°œ",
            "",
            "ğŸ”§ êµì • ìœ í˜•ë³„ ë¶„ì„:"
        ]
        
        # êµì • ìœ í˜•ë³„ ìƒì„¸ ì •ë³´
        for correction_type, stats in correction_types.items():
            type_name_kr = {
                'spelling': 'ë§ì¶¤ë²•',
                'grammar': 'ë¬¸ë²•',
                'spacing': 'ë„ì–´ì“°ê¸°',
                'style': 'ë¬¸ì²´',
                'punctuation': 'êµ¬ë‘ì '
            }.get(correction_type, correction_type)
            
            report_lines.extend([
                f"  â€¢ {type_name_kr} êµì •:",
                f"    - íšŸìˆ˜: {stats['count']:,}íšŒ",
                f"    - í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.3f}",
            ])
            
            if stats['examples']:
                report_lines.append("    - ì˜ˆì‹œ:")
                for example in stats['examples']:
                    report_lines.append(f"      '{example['original']}' â†’ '{example['corrected']}' (ì‹ ë¢°ë„: {example['confidence']:.3f})")
            
            report_lines.append("")
        
        # í’ˆì§ˆ í‰ê°€ ë° ê¶Œì¥ì‚¬í•­
        report_lines.extend([
            "ğŸ’¡ í’ˆì§ˆ í‰ê°€ ë° ê¶Œì¥ì‚¬í•­:",
            self._generate_quality_recommendations(quality_analysis),
            "",
            "=" * 60
        ])
        
        return "\n".join(report_lines)
    
    def _generate_quality_recommendations(self, quality_analysis: Dict[str, Any]) -> str:
        """í’ˆì§ˆ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        overall = quality_analysis["overall_stats"]
        confidence = quality_analysis["confidence_analysis"]
        text_change = quality_analysis["text_change_analysis"]
        
        recommendations = []
        
        # í’ˆì§ˆ ì ìˆ˜ ê¸°ë°˜ í‰ê°€
        quality_score = overall["quality_score"]
        if quality_score >= 90:
            recommendations.append("âœ… ë§¤ìš° ìš°ìˆ˜í•œ êµì • í’ˆì§ˆì…ë‹ˆë‹¤.")
        elif quality_score >= 80:
            recommendations.append("âœ… ì–‘í˜¸í•œ êµì • í’ˆì§ˆì…ë‹ˆë‹¤.")
        elif quality_score >= 70:
            recommendations.append("âš ï¸ ë³´í†µ ìˆ˜ì¤€ì˜ êµì • í’ˆì§ˆì…ë‹ˆë‹¤. ì¼ë¶€ ê°œì„ ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            recommendations.append("âŒ êµì • í’ˆì§ˆì´ ë‚®ìŠµë‹ˆë‹¤. ì„¤ì • ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        if confidence["avg_processing_confidence"] < 0.7:
            recommendations.append("âš ï¸ ì²˜ë¦¬ ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. LLM ëª¨ë¸ ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ì¡°ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        if confidence["avg_correction_confidence"] < 0.8:
            recommendations.append("âš ï¸ êµì • ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ë” ë³´ìˆ˜ì ì¸ êµì • ì„¤ì •ì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # êµì • ë¹„ìœ¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        correction_rate = overall["correction_rate"]
        if correction_rate > 0.9:
            recommendations.append("âš ï¸ êµì • ë¹„ìœ¨ì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤. OCR í’ˆì§ˆ ë˜ëŠ” êµì • ì„ê³„ê°’ì„ í™•ì¸í•˜ì„¸ìš”.")
        elif correction_rate < 0.1:
            recommendations.append("âš ï¸ êµì • ë¹„ìœ¨ì´ ë§¤ìš° ë‚®ìŠµë‹ˆë‹¤. êµì • ë¯¼ê°ë„ë¥¼ ë†’ì´ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”.")
        
        # í…ìŠ¤íŠ¸ ë³€í™” ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
        avg_length_change = text_change["avg_length_change_ratio"]
        if avg_length_change > 1.3:
            recommendations.append("âš ï¸ í…ìŠ¤íŠ¸ê°€ í¬ê²Œ ëŠ˜ì–´ë‚˜ê³  ìˆìŠµë‹ˆë‹¤. ê³¼ë„í•œ êµì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        elif avg_length_change < 0.7:
            recommendations.append("âš ï¸ í…ìŠ¤íŠ¸ê°€ í¬ê²Œ ì¤„ì–´ë“¤ê³  ìˆìŠµë‹ˆë‹¤. ì¤‘ìš”í•œ ë‚´ìš©ì´ ì†ì‹¤ë˜ì§€ ì•Šì•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        
        return "\n  ".join(recommendations) if recommendations else "  íŠ¹ë³„í•œ ê¶Œì¥ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤."
    
    def track_correction_patterns(
        self, 
        processed_blocks: List[ProcessedOCRBlock]
    ) -> Dict[str, Any]:
        """
        êµì • íŒ¨í„´ ì¶”ì  ë° ë¶„ì„
        
        Args:
            processed_blocks: ì²˜ë¦¬ëœ OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            êµì • íŒ¨í„´ ë¶„ì„ ê²°ê³¼
        """
        patterns = {
            'common_corrections': {},  # ìì£¼ ë°œìƒí•˜ëŠ” êµì •
            'error_patterns': {},      # ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜ íŒ¨í„´
            'confidence_patterns': {}, # ì‹ ë¢°ë„ë³„ íŒ¨í„´
            'page_patterns': {}        # í˜ì´ì§€ë³„ íŒ¨í„´
        }
        
        for block in processed_blocks:
            page_num = block.page_number
            
            # í˜ì´ì§€ë³„ íŒ¨í„´ ì´ˆê¸°í™”
            if page_num not in patterns['page_patterns']:
                patterns['page_patterns'][page_num] = {
                    'total_blocks': 0,
                    'corrected_blocks': 0,
                    'total_corrections': 0,
                    'avg_confidence': 0.0
                }
            
            page_stats = patterns['page_patterns'][page_num]
            page_stats['total_blocks'] += 1
            
            if block.has_corrections:
                page_stats['corrected_blocks'] += 1
                page_stats['total_corrections'] += len(block.corrections)
            
            page_stats['avg_confidence'] += block.processing_confidence
            
            # êµì •ë³„ íŒ¨í„´ ë¶„ì„
            for correction in block.corrections:
                # ê³µí†µ êµì • íŒ¨í„´
                correction_key = f"{correction.original} â†’ {correction.corrected}"
                if correction_key not in patterns['common_corrections']:
                    patterns['common_corrections'][correction_key] = {
                        'count': 0,
                        'type': correction.correction_type.value,
                        'avg_confidence': 0.0,
                        'total_confidence': 0.0
                    }
                
                common_corr = patterns['common_corrections'][correction_key]
                common_corr['count'] += 1
                common_corr['total_confidence'] += correction.confidence
                common_corr['avg_confidence'] = common_corr['total_confidence'] / common_corr['count']
                
                # ì˜¤ë¥˜ íŒ¨í„´ (ì›ë³¸ í…ìŠ¤íŠ¸ ê¸°ì¤€)
                error_pattern = correction.original.lower().strip()
                if len(error_pattern) > 1:  # ë‹¨ì¼ ë¬¸ì ì œì™¸
                    if error_pattern not in patterns['error_patterns']:
                        patterns['error_patterns'][error_pattern] = {
                            'count': 0,
                            'corrections': set(),
                            'types': set()
                        }
                    
                    error_pat = patterns['error_patterns'][error_pattern]
                    error_pat['count'] += 1
                    error_pat['corrections'].add(correction.corrected)
                    error_pat['types'].add(correction.correction_type.value)
                
                # ì‹ ë¢°ë„ë³„ íŒ¨í„´
                confidence_range = self._get_confidence_range(correction.confidence)
                if confidence_range not in patterns['confidence_patterns']:
                    patterns['confidence_patterns'][confidence_range] = {
                        'count': 0,
                        'types': {}
                    }
                
                conf_pat = patterns['confidence_patterns'][confidence_range]
                conf_pat['count'] += 1
                
                corr_type = correction.correction_type.value
                if corr_type not in conf_pat['types']:
                    conf_pat['types'][corr_type] = 0
                conf_pat['types'][corr_type] += 1
        
        # í˜ì´ì§€ë³„ í‰ê·  ì‹ ë¢°ë„ ê³„ì‚°
        for page_num, page_stats in patterns['page_patterns'].items():
            if page_stats['total_blocks'] > 0:
                page_stats['avg_confidence'] /= page_stats['total_blocks']
        
        # ê²°ê³¼ ì •ë¦¬ (setì„ listë¡œ ë³€í™˜)
        for error_pattern in patterns['error_patterns'].values():
            error_pattern['corrections'] = list(error_pattern['corrections'])
            error_pattern['types'] = list(error_pattern['types'])
        
        return patterns
    
    def _get_confidence_range(self, confidence: float) -> str:
        """ì‹ ë¢°ë„ë¥¼ ë²”ìœ„ë¡œ ë¶„ë¥˜"""
        if confidence >= 0.9:
            return "very_high"
        elif confidence >= 0.8:
            return "high"
        elif confidence >= 0.7:
            return "medium"
        elif confidence >= 0.6:
            return "low"
        else:
            return "very_low"
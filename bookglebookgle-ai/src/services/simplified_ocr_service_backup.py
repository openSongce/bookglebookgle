"""
ë‹¨ìˆœí™”ëœ OCR ì„œë¹„ìŠ¤
PaddleOCR ì „ìš© OCR ì„œë¹„ìŠ¤ - LLM í›„ì²˜ë¦¬ ì—†ì´ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ
ê¸°ì¡´ì˜ ë³µìž¡í•œ ë‹¤ì¤‘ ì—”ì§„ êµ¬ì¡°ë¥¼ ëŒ€ì²´í•˜ëŠ” ìµœì í™”ëœ ì„œë¹„ìŠ¤
"""

import asyncio
import time
import traceback
from typing import Dict, Any, List, Optional, Tuple
import psutil
import os

import fitz  # PyMuPDF
from loguru import logger

from src.models.ocr_models import (
    OCRBlock, ProcessedOCRBlock, ProcessingMetrics
)
from src.services.paddleocr_engine import PaddleOCREngine, PaddleOCRConfig
from src.services.vector_db import VectorDBManager


class SimplifiedOCRService:
    """
    ë‹¨ìˆœí™”ëœ OCR ì„œë¹„ìŠ¤ - Tesseract + LLM í›„ì²˜ë¦¬ í†µí•©
    ê¸°ì¡´ ë³µìž¡í•œ ë‹¤ì¤‘ ì—”ì§„ êµ¬ì¡°ë¥¼ ëŒ€ì²´í•˜ëŠ” ìµœì í™”ëœ ì„œë¹„ìŠ¤
    """
    
    def __init__(
        self,
        tesseract_config: Optional[TesseractConfig] = None,
        enable_llm_postprocessing: bool = True
    ):
        """
        SimplifiedOCRService ì´ˆê¸°í™”
        
        Args:
            tesseract_config: Tesseract ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ ì„¤ì •)
            enable_llm_postprocessing: LLM í›„ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€
        """
        # ì„¤ì • ì´ˆê¸°í™”
        self.tesseract_config = tesseract_config or TesseractConfig()
        self.enable_llm_postprocessing = enable_llm_postprocessing
        
        # ì—”ì§„ ì´ˆê¸°í™”
        self.tesseract_engine = TesseractEngine(self.tesseract_config)
        self.llm_client = None
        self.text_post_processor = None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.processing_stats = {
            'total_documents': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_processing_time': 0.0,
            'total_ocr_time': 0.0,
            'total_llm_time': 0.0,
            'total_pages_processed': 0,
            'total_blocks_extracted': 0,
            'total_corrections_made': 0
        }
        
        logger.info(f"ðŸš€ SimplifiedOCRService initialized:")
        logger.info(f"   ðŸ”§ Tesseract config: {self.tesseract_config.languages}")
        logger.info(f"   ðŸ¤– LLM post-processing: {'Enabled' if enable_llm_postprocessing else 'Disabled'}")
        logger.info(f"   ðŸ“Š DPI: {self.tesseract_config.dpi}")
        logger.info(f"   ðŸŽ¯ Confidence threshold: {self.tesseract_config.confidence_threshold}")
    
    async def initialize(self) -> bool:
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë¹„ë™ê¸° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”)
        
        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("ðŸ”„ Initializing SimplifiedOCRService components...")
            
            # 1. Tesseract ì—”ì§„ ì´ˆê¸°í™”
            tesseract_success = await self.tesseract_engine.initialize()
            if not tesseract_success:
                logger.error("âŒ Tesseract engine initialization failed")
                return False
            
            # 2. LLM í›„ì²˜ë¦¬ ì´ˆê¸°í™” (í™œì„±í™”ëœ ê²½ìš°)
            if self.enable_llm_postprocessing:
                try:
                    self.llm_client = LLMClient()
                    await self.llm_client.initialize()
                    
                    self.text_post_processor = TextPostProcessor(self.llm_client)
                    
                    logger.info("âœ… LLM post-processor initialized")
                except Exception as e:
                    logger.warning(f"âš ï¸ LLM post-processor initialization failed: {e}")
                    logger.info("ðŸ”„ Continuing with OCR-only mode")
                    self.enable_llm_postprocessing = False
            
            logger.info("âœ… SimplifiedOCRService initialization completed")
            return True
            
        except Exception as e:
            logger.error(f"âŒ SimplifiedOCRService initialization failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False
    
    async def process_pdf_stream(
        self, 
        pdf_stream: bytes, 
        document_id: str,
        enable_llm_postprocessing: Optional[bool] = None
    ) -> Dict[str, Any]:
        """
        PDF ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•˜ì—¬ OCR + LLM í›„ì²˜ë¦¬ ìˆ˜í–‰
        
        Args:
            pdf_stream: PDF ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
            document_id: ë¬¸ì„œ ID
            enable_llm_postprocessing: LLM í›„ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€ (Noneì´ë©´ ê¸°ë³¸ ì„¤ì • ì‚¬ìš©)
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì²˜ë¦¬ ì‹œìž‘
        start_time = time.time()
        process_memory_start = self._get_memory_usage()
        
        # LLM í›„ì²˜ë¦¬ ì„¤ì • ê²°ì •
        use_llm = (enable_llm_postprocessing 
                  if enable_llm_postprocessing is not None 
                  else self.enable_llm_postprocessing)
        
        logger.info(f"ðŸš€ Starting PDF processing for document: {document_id}")
        logger.info(f"   ðŸ“„ PDF size: {len(pdf_stream):,} bytes")
        logger.info(f"   ðŸ¤– LLM post-processing: {'Enabled' if use_llm else 'Disabled'}")
        
        try:
            # 1ë‹¨ê³„: PDF íŒŒì‹± ë° OCR ì²˜ë¦¬
            ocr_result = await self._extract_with_tesseract(pdf_stream, document_id)
            
            if not ocr_result["success"]:
                return self._create_error_response(
                    document_id, 
                    ocr_result["error"], 
                    start_time
                )
            
            ocr_blocks = ocr_result["ocr_blocks"]
            ocr_time = ocr_result["processing_time"]
            
            # 2ë‹¨ê³„: LLM í›„ì²˜ë¦¬ (í™œì„±í™”ëœ ê²½ìš°)
            if use_llm and self.text_post_processor and ocr_blocks:
                llm_result = await self._postprocess_with_llm(ocr_blocks, document_id)
                processed_blocks = llm_result["processed_blocks"]
                llm_time = llm_result["processing_time"]
            else:
                # LLM í›„ì²˜ë¦¬ ì—†ì´ OCRBlockì„ ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜
                processed_blocks = self._convert_to_processed_blocks(ocr_blocks)
                llm_time = 0.0
            
            # 3ë‹¨ê³„: ê²°ê³¼ í†µí•© ë° í˜•ì‹ ë³€í™˜
            final_result = await self._create_final_response(
                document_id=document_id,
                processed_blocks=processed_blocks,
                ocr_time=ocr_time,
                llm_time=llm_time,
                start_time=start_time,
                process_memory_start=process_memory_start,
                pdf_size=len(pdf_stream)
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(final_result, success=True)
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ PDF processing failed for {document_id}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            
            error_result = self._create_error_response(document_id, str(e), start_time)
            self._update_processing_stats(error_result, success=False)
            
            return error_result
    
    async def _extract_with_tesseract(
        self, 
        pdf_stream: bytes, 
        document_id: str
    ) -> Dict[str, Any]:
        """
        Tesseractë¥¼ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            pdf_stream: PDF ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
            document_id: ë¬¸ì„œ ID
            
        Returns:
            OCR ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            ocr_start_time = time.time()
            logger.info(f"ðŸ” Starting Tesseract OCR for document: {document_id}")
            
            # PDF ë¬¸ì„œ ì—´ê¸°
            pdf_document = None
            try:
                if hasattr(fitz, 'Document'):
                    pdf_document = fitz.Document(stream=pdf_stream, filetype="pdf")
                else:
                    pdf_document = fitz.open(stream=pdf_stream, filetype="pdf")
            except Exception as e:
                logger.error(f"Failed to open PDF: {e}")
                return {"success": False, "error": f"Cannot open PDF: {e}"}
            
            total_pages = len(pdf_document)
            logger.info(f"ðŸ“„ PDF has {total_pages} pages")
            
            # Tesseract ì—”ì§„ìœ¼ë¡œ íŽ˜ì´ì§€ ì²˜ë¦¬
            ocr_blocks = await self.tesseract_engine.process_pdf_pages(pdf_document)
            
            # PDF ë¬¸ì„œ ì •ë¦¬
            pdf_document.close()
            
            ocr_time = time.time() - ocr_start_time
            
            logger.info(f"âœ… Tesseract OCR completed for {document_id}:")
            logger.info(f"   â±ï¸ OCR time: {ocr_time:.2f}s")
            logger.info(f"   ðŸ“Š Blocks extracted: {len(ocr_blocks)}")
            logger.info(f"   ðŸ“ Total characters: {sum(len(block.text) for block in ocr_blocks)}")
            
            return {
                "success": True,
                "ocr_blocks": ocr_blocks,
                "total_pages": total_pages,
                "processing_time": ocr_time
            }
            
        except Exception as e:
            logger.error(f"âŒ Tesseract OCR failed for {document_id}: {e}")
            return {"success": False, "error": str(e)}
    
    async def _postprocess_with_llm(
        self, 
        ocr_blocks: List[OCRBlock], 
        document_id: str
    ) -> Dict[str, Any]:
        """
        LLMì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ í›„ì²˜ë¦¬
        
        Args:
            ocr_blocks: OCR ë¸”ë¡ ë¦¬ìŠ¤íŠ¸
            document_id: ë¬¸ì„œ ID
            
        Returns:
            LLM í›„ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            llm_start_time = time.time()
            logger.info(f"ðŸ¤– Starting LLM post-processing for document: {document_id}")
            logger.info(f"   ðŸ“Š Blocks to process: {len(ocr_blocks)}")
            
            # TextPostProcessorë¡œ í›„ì²˜ë¦¬ ìˆ˜í–‰
            processed_blocks = await self.text_post_processor.process_text_blocks(
                ocr_blocks, 
                enable_batch_processing=True
            )
            
            llm_time = time.time() - llm_start_time
            
            # í›„ì²˜ë¦¬ í†µê³„
            total_corrections = sum(len(block.corrections) for block in processed_blocks)
            avg_confidence = (sum(block.processing_confidence for block in processed_blocks) 
                            / len(processed_blocks) if processed_blocks else 0.0)
            
            logger.info(f"âœ… LLM post-processing completed for {document_id}:")
            logger.info(f"   â±ï¸ LLM time: {llm_time:.2f}s")
            logger.info(f"   ðŸ”§ Total corrections: {total_corrections}")
            logger.info(f"   ðŸŽ¯ Average confidence: {avg_confidence:.3f}")
            
            return {
                "success": True,
                "processed_blocks": processed_blocks,
                "processing_time": llm_time,
                "total_corrections": total_corrections,
                "average_confidence": avg_confidence
            }
            
        except Exception as e:
            logger.error(f"âŒ LLM post-processing failed for {document_id}: {e}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë¸”ë¡ë“¤ì„ ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜
            processed_blocks = self._convert_to_processed_blocks(ocr_blocks)
            return {
                "success": False,
                "processed_blocks": processed_blocks,
                "processing_time": 0.0,
                "error": str(e)
            }
    
    def _convert_to_processed_blocks(self, ocr_blocks: List[OCRBlock]) -> List[ProcessedOCRBlock]:
        """OCRBlockì„ ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜ (LLM í›„ì²˜ë¦¬ ì—†ì´)"""
        processed_blocks = []
        
        for block in ocr_blocks:
            processed_block = ProcessedOCRBlock(
                text=block.text,
                page_number=block.page_number,
                bbox=block.bbox,
                confidence=block.confidence,
                block_type=block.block_type,
                original_text=block.text,
                corrections=[],  # êµì • ì—†ìŒ
                processing_confidence=1.0,  # LLM ì²˜ë¦¬ ì—†ìœ¼ë¯€ë¡œ ìµœëŒ€ê°’
                llm_model="none (OCR only)"
            )
            processed_blocks.append(processed_block)
        
        return processed_blocks
    
    async def _create_final_response(
        self,
        document_id: str,
        processed_blocks: List[ProcessedOCRBlock],
        ocr_time: float,
        llm_time: float,
        start_time: float,
        process_memory_start: int,
        pdf_size: int
    ) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        total_time = time.time() - start_time
        process_memory_peak = self._get_memory_usage()
        memory_used = process_memory_peak - process_memory_start
        
        # íŽ˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ API í˜¸í™˜ì„±)
        page_texts = self._create_page_texts(processed_blocks)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„±
        full_text = "\n\n".join([
            block.text for block in processed_blocks 
            if block.text.strip()
        ])
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ í˜•íƒœë¡œ ë³€í™˜ (ê¸°ì¡´ API í˜¸í™˜ì„±)
        text_blocks = [block.to_dict() for block in processed_blocks]
        
        # ì²˜ë¦¬ í†µê³„ ìƒì„±
        total_corrections = sum(len(block.corrections) for block in processed_blocks)
        avg_ocr_confidence = (sum(block.confidence for block in processed_blocks) 
                             / len(processed_blocks) if processed_blocks else 0.0)
        avg_processing_confidence = (sum(block.processing_confidence for block in processed_blocks) 
                                   / len(processed_blocks) if processed_blocks else 0.0)
        
        # íŽ˜ì´ì§€ ìˆ˜ ê³„ì‚°
        total_pages = max((block.page_number for block in processed_blocks), default=0)
        
        # ProcessingMetrics ìƒì„±
        metrics = ProcessingMetrics(
            document_id=document_id,
            total_pages=total_pages,
            ocr_time=ocr_time,
            llm_processing_time=llm_time,
            total_time=total_time,
            memory_peak=memory_used,
            text_blocks_count=len(processed_blocks),
            corrections_count=total_corrections,
            average_ocr_confidence=avg_ocr_confidence,
            average_processing_confidence=avg_processing_confidence
        )
        
        logger.info(f"ðŸŽ‰ Final processing completed for {document_id}:")
        logger.info(f"   â±ï¸ Total time: {total_time:.2f}s")
        logger.info(f"   ðŸ“„ Pages: {total_pages}")
        logger.info(f"   ðŸ“Š Blocks: {len(processed_blocks)}")
        logger.info(f"   ðŸ”§ Corrections: {total_corrections}")
        logger.info(f"   ðŸ’¾ Memory used: {memory_used / 1024 / 1024:.1f} MB")
        logger.info(f"   âš¡ Speed: {len(processed_blocks) / total_time:.1f} blocks/sec")
        
        return {
            "success": True,
            "document_id": document_id,
            "total_pages": total_pages,
            "full_text": full_text,
            "page_texts": page_texts,
            "text_blocks": text_blocks,
            "engine_used": f"SimplifiedOCRService v1.0 (Tesseract + {'Gemini-2.0-flash' if llm_time > 0 else 'OCR-only'})",
            "processing_stats": metrics.to_dict(),
            "llm_postprocessing_enabled": llm_time > 0,
            "performance_metrics": {
                "pdf_size_bytes": pdf_size,
                "processing_speed_blocks_per_sec": len(processed_blocks) / total_time if total_time > 0 else 0,
                "memory_efficiency_mb_per_page": (memory_used / 1024 / 1024) / max(total_pages, 1),
                "ocr_to_total_time_ratio": ocr_time / total_time if total_time > 0 else 0,
                "llm_to_total_time_ratio": llm_time / total_time if total_time > 0 else 0
            }
        }
    
    def _create_page_texts(self, processed_blocks: List[ProcessedOCRBlock]) -> List[Dict[str, Any]]:
        """íŽ˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ API í˜¸í™˜ì„±)"""
        page_groups = {}
        
        # íŽ˜ì´ì§€ë³„ë¡œ ë¸”ë¡ ê·¸ë£¹í™”
        for block in processed_blocks:
            page_num = block.page_number
            if page_num not in page_groups:
                page_groups[page_num] = []
            page_groups[page_num].append(block.text)
        
        # íŽ˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ìƒì„±
        page_texts = []
        for page_num in sorted(page_groups.keys()):
            page_text = "\n".join(page_groups[page_num])
            page_texts.append({
                "page_number": page_num,
                "text": page_text.strip(),
                "processing_time": 0  # ì „ì²´ ì²˜ë¦¬ì— í¬í•¨ë¨
            })
        
        return page_texts
    
    def _create_error_response(
        self, 
        document_id: str, 
        error_message: str, 
        start_time: float
    ) -> Dict[str, Any]:
        """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
        total_time = time.time() - start_time
        
        return {
            "success": False,
            "document_id": document_id,
            "error": error_message,
            "total_pages": 0,
            "full_text": "",
            "page_texts": [],
            "text_blocks": [],
            "engine_used": "SimplifiedOCRService v1.0 (Failed)",
            "processing_stats": {
                "total_time": total_time,
                "error": error_message
            }
        }
    
    def _get_memory_usage(self) -> int:
        """í˜„ìž¬ í”„ë¡œì„¸ìŠ¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (ë°”ì´íŠ¸)"""
        try:
            process = psutil.Process(os.getpid())
            return process.memory_info().rss
        except:
            return 0
    
    def _update_processing_stats(self, result: Dict[str, Any], success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.processing_stats['total_documents'] += 1
        
        if success:
            self.processing_stats['successful_documents'] += 1
            stats = result.get('processing_stats', {})
            self.processing_stats['total_processing_time'] += stats.get('total_time', 0)
            self.processing_stats['total_ocr_time'] += stats.get('ocr_time', 0)
            self.processing_stats['total_llm_time'] += stats.get('llm_processing_time', 0)
            self.processing_stats['total_pages_processed'] += result.get('total_pages', 0)
            self.processing_stats['total_blocks_extracted'] += stats.get('text_blocks_count', 0)
            self.processing_stats['total_corrections_made'] += stats.get('corrections_count', 0)
        else:
            self.processing_stats['failed_documents'] += 1
    
    def get_service_info(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "SimplifiedOCRService",
            "version": "1.0.0",
            "tesseract_engine": self.tesseract_engine.get_engine_info(),
            "llm_postprocessing_enabled": self.enable_llm_postprocessing,
            "text_post_processor": (self.text_post_processor.get_processor_info() 
                                  if self.text_post_processor else None),
            "processing_statistics": self.processing_stats.copy()
        }
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        stats = self.processing_stats.copy()
        
        # ì¶”ê°€ ê³„ì‚°ëœ í†µê³„
        if stats['successful_documents'] > 0:
            stats['average_processing_time'] = stats['total_processing_time'] / stats['successful_documents']
            stats['average_pages_per_document'] = stats['total_pages_processed'] / stats['successful_documents']
            stats['average_blocks_per_document'] = stats['total_blocks_extracted'] / stats['successful_documents']
            stats['average_corrections_per_document'] = stats['total_corrections_made'] / stats['successful_documents']
        
        if stats['total_documents'] > 0:
            stats['success_rate'] = stats['successful_documents'] / stats['total_documents']
        
        return stats
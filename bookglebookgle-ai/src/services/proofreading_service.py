"""
Proofreading Service for BGBG AI Server
Handles text correction, grammar analysis, and diff generation
"""

import hashlib
from typing import Dict, List, Optional, Any
from loguru import logger

from src.services.mock_proofreading_service import MockProofreadingService
from src.services.llm_client import LLMClient, ProofreadingLLMClient
from src.config.settings import get_settings


class ProofreadingService:
    """Service for AI-powered text proofreading and correction"""
    
    def __init__(self):
        self.settings = get_settings()
        self.mock_service = MockProofreadingService()
        self.llm_client: Optional[LLMClient] = None
        self.proofreading_llm_client: Optional[ProofreadingLLMClient] = None
        self.correction_cache: Dict[str, Dict[str, Any]] = {}
    
    async def initialize(self):
        """Initialize proofreading service dependencies"""
        try:
            logger.info("Initializing Proofreading Service...")
            
            # Initialize LLM client only if not already set by ServiceInitializer
            if self.llm_client is None and not self.settings.ai.MOCK_AI_RESPONSES:
                logger.info("ðŸ”§ Creating new LLM client for Proofreading Service")
                self.llm_client = LLMClient()
                await self.llm_client.initialize()
                self.proofreading_llm_client = ProofreadingLLMClient(self.llm_client)
                logger.info("LLM client initialized for proofreading")
            elif self.llm_client is not None:
                logger.info("ðŸ”„ Using existing LLM client for Proofreading Service")
                # proofreading_llm_clientëŠ” ServiceInitializerì—ì„œ ì´ë¯¸ ì„¤ì •ë¨
            else:
                logger.info("Using mock responses for proofreading")
                
        except Exception as e:
            logger.error(f"Failed to initialize Proofreading Service: {e}")
            self.llm_client = None
    
    async def proofread_text(self, proofread_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Proofread and correct text with contextual analysis
        
        Args:
            proofread_data: Dict containing:
                - original_text: str
                - context_text: Optional[str] 
                - language: str (default: "ko")
                - user_id: str
        
        Returns:
            Dict with corrected text, corrections, and confidence score
        """
        try:
            logger.info(f"Starting proofreading for user: {proofread_data.get('user_id')}")
            
            # Validate input
            if not self._validate_proofread_request(proofread_data):
                return {"success": False, "error": "Invalid proofreading request data"}
            
            original_text = proofread_data["original_text"]
            
            # Check cache first
            cache_key = self._generate_cache_key(original_text)
            if cache_key in self.correction_cache:
                logger.info("Using cached proofreading result")
                return self.correction_cache[cache_key]
            
            # ì‹¤ì œ LLM ì—°ë™ ë˜ëŠ” Mock ì„ íƒ
            if not self.settings.ai.MOCK_AI_RESPONSES and self.proofreading_llm_client:
                # ProofreadingLLMClient ì‚¬ìš©í•˜ì—¬ ì‹¤ì œ ì²¨ì‚­
                result = await self._process_with_llm(proofread_data)
            else:
                # Mock ì„œë¹„ìŠ¤ ì‚¬ìš© (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
                result = await self.mock_service.proofread_text(proofread_data)
            
            # Cache the result
            self.correction_cache[cache_key] = result
            
            logger.info(f"Proofreading completed with {len(result.get('corrections', []))} corrections")
            return result
            
        except Exception as e:
            logger.error(f"Proofreading failed: {e}")
            return {"success": False, "error": f"Proofreading failed: {str(e)}"}
    
    def _validate_proofread_request(self, proofread_data: Dict[str, Any]) -> bool:
        """Validate proofreading request data"""
        if not proofread_data.get("original_text"):
            logger.error("Missing original_text in proofread request")
            return False
        
        if not proofread_data.get("user_id"):
            logger.error("Missing user_id in proofread request")
            return False
        
        return True
    
    async def _process_with_llm(self, proofread_data: Dict[str, Any]) -> Dict[str, Any]:
        """LLMì„ ì‚¬ìš©í•œ ì‹¤ì œ ì²¨ì‚­ ì²˜ë¦¬"""
        try:
            original_text = proofread_data["original_text"]
            context_text = proofread_data.get("context_text", "")
            language = proofread_data.get("language", "ko")
            
            # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„±
            system_message = """ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ í…ìŠ¤íŠ¸ êµì • ì „ë¬¸ê°€ìž…ë‹ˆë‹¤. 
ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì˜ ë¬¸ë²•, ë§žì¶¤ë²•, ë¬¸ì²´ë¥¼ ê²€í† í•˜ê³  ê°œì„  ì‚¬í•­ì„ ì œì•ˆí•´ì£¼ì„¸ìš”.
ì‘ë‹µì€ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”:

{
  "corrected_text": "êµì •ëœ ì „ì²´ í…ìŠ¤íŠ¸",
  "corrections": [
    {
      "original": "ì›ë³¸ í…ìŠ¤íŠ¸",
      "corrected": "êµì •ëœ í…ìŠ¤íŠ¸", 
      "type": "grammar|spelling|style|clarity",
      "explanation": "êµì • ì´ìœ  ì„¤ëª…"
    }
  ],
  "confidence_score": 0.95
}"""
            
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            prompt = f"""ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ êµì •í•´ì£¼ì„¸ìš”:

ì›ë³¸ í…ìŠ¤íŠ¸:
{original_text}

ë§¥ë½ ì •ë³´:
{context_text}

ì–¸ì–´: {language}

ë¬¸ë²•, ë§žì¶¤ë²•, ë¬¸ì²´ì˜ ì˜¤ë¥˜ë¥¼ ì°¾ì•„ êµì •í•˜ê³ , ê° ìˆ˜ì •ì‚¬í•­ì— ëŒ€í•œ ì„¤ëª…ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
            
            # LLM í˜¸ì¶œ (GMS API ì‚¬ìš©)
            from src.services.llm_client import LLMProvider
            response = await self.llm_client.generate_completion(
                prompt=prompt,
                system_message=system_message,
                max_tokens=1500,
                temperature=0.3,  # êµì • ìž‘ì—…ì´ë¯€ë¡œ ë‚®ì€ temperature ì‚¬ìš©
                provider=LLMProvider.GMS
            )
            
            # JSON ì‘ë‹µ íŒŒì‹±
            import json
            import re
            
            json_match = re.search(r'\{.*\}', response, re.DOTALL)
            if json_match:
                try:
                    result_data = json.loads(json_match.group())
                    
                    # ì‘ë‹µ í¬ë§· ë³€í™˜
                    formatted_result = {
                        "success": True,
                        "corrected_text": result_data.get("corrected_text", original_text),
                        "corrections": [
                            {
                                "original": corr.get("original", ""),
                                "corrected": corr.get("corrected", ""),
                                "type": corr.get("type", "grammar"),
                                "explanation": corr.get("explanation", ""),
                                "start_position": 0,  # ì •í™•í•œ ìœ„ì¹˜ ê³„ì‚°ì€ í–¥í›„ ê°œì„ 
                                "end_position": len(corr.get("original", ""))
                            }
                            for corr in result_data.get("corrections", [])
                        ],
                        "confidence_score": result_data.get("confidence_score", 0.85)
                    }
                    
                    logger.info(f"LLM proofreading completed with {len(formatted_result['corrections'])} corrections")
                    return formatted_result
                    
                except json.JSONDecodeError as e:
                    logger.error(f"Failed to parse LLM response as JSON: {e}")
                    
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì‘ë‹µ
            return {
                "success": True,
                "corrected_text": original_text,
                "corrections": [],
                "confidence_score": 0.5
            }
            
        except Exception as e:
            logger.error(f"LLM proofreading failed: {e}")
            return {
                "success": False,
                "error": f"LLM proofreading failed: {str(e)}"
            }
    
    def _generate_cache_key(self, text: str) -> str:
        """Generate cache key for text"""
        return hashlib.md5(text.encode('utf-8')).hexdigest()
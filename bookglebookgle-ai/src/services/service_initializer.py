"""
Service Initializer for BGBG AI Server
Manages the initialization of all AI services with proper dependency injection
"""

import asyncio
from dataclasses import dataclass
from typing import Dict, Any, Optional
from loguru import logger

from src.services.llm_client import LLMClient
from src.services.quiz_service import QuizService
from src.services.proofreading_service import ProofreadingService
from src.services.vector_db import VectorDBManager
from src.services.redis_connection_manager import RedisConnectionManager
from src.config.settings import get_settings


@dataclass
class ServiceInitializationStatus:
    """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ìƒíƒœë¥¼ ì¶”ì í•˜ëŠ” ë°ì´í„° í´ë˜ìŠ¤"""
    llm_client: bool = False
    quiz_service: bool = False
    proofreading_service: bool = False
    vector_db: bool = False
    redis_manager: bool = False
    
    @property
    def all_critical_services_ready(self) -> bool:
        """í•„ìˆ˜ ì„œë¹„ìŠ¤ë“¤ì´ ëª¨ë‘ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.llm_client and self.vector_db
    
    @property
    def ai_features_ready(self) -> bool:
        """AI ê¸°ëŠ¥ë“¤ì´ ì¤€ë¹„ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        return self.quiz_service and self.proofreading_service
    
    def get_status_summary(self) -> str:
        """ì´ˆê¸°í™” ìƒíƒœ ìš”ì•½ ë°˜í™˜"""
        services = {
            "LLM Client": self.llm_client,
            "Quiz Service": self.quiz_service,
            "Proofreading Service": self.proofreading_service,
            "Vector DB": self.vector_db,
            "Redis Manager": self.redis_manager
        }
        
        ready_count = sum(services.values())
        total_count = len(services)
        
        status_details = []
        for name, status in services.items():
            status_icon = "âœ…" if status else "âŒ"
            status_details.append(f"{status_icon} {name}")
        
        return f"Services Ready: {ready_count}/{total_count}\n" + "\n".join(status_details)


class ServiceInitializationError(Exception):
    """ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨ ì˜ˆì™¸"""
    pass


class CriticalServiceFailure(ServiceInitializationError):
    """í•„ìˆ˜ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨"""
    pass


class OptionalServiceFailure(ServiceInitializationError):
    """ì„ íƒì  ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨"""
    pass


class ServiceInitializer:
    """AI ì„œë¹„ìŠ¤ë“¤ì˜ ì´ˆê¸°í™”ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.settings = get_settings()
        self.status = ServiceInitializationStatus()
        self.services: Dict[str, Any] = {}
    
    async def initialize_all_services(self) -> Dict[str, Any]:
        """ëª¨ë“  ì„œë¹„ìŠ¤ë¥¼ ì˜¬ë°”ë¥¸ ìˆœì„œë¡œ ì´ˆê¸°í™”"""
        logger.info("ğŸ”§ Starting comprehensive service initialization...")
        
        try:
            # 1. ê¸°ë³¸ ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™” (ë³‘ë ¬)
            basic_services = await self._initialize_basic_services()
            
            # 2. LLM ê¸°ë°˜ ì„œë¹„ìŠ¤ë“¤ ì´ˆê¸°í™” (ìˆœì°¨) - basic_services ì „ë‹¬
            ai_services = await self._initialize_ai_services(
                basic_services.get('llm_client'),
                basic_services  # basic_services ì „ë‹¬
            )
            
            # 3. ëª¨ë“  ì„œë¹„ìŠ¤ í†µí•©
            all_services = {**basic_services, **ai_services}
            self.services = all_services
            
            # 4. ì´ˆê¸°í™” ìƒíƒœ ë¡œê¹…
            logger.info("ğŸ“Š Service Initialization Summary:")
            logger.info(f"\n{self.status.get_status_summary()}")
            
            # 5. í•„ìˆ˜ ì„œë¹„ìŠ¤ í™•ì¸
            if not self.status.all_critical_services_ready:
                raise CriticalServiceFailure("Critical services failed to initialize")
            
            logger.info("âœ… All services initialized successfully")
            return all_services
            
        except Exception as e:
            logger.error(f"âŒ Service initialization failed: {e}")
            logger.info(f"ğŸ“Š Final Status:\n{self.status.get_status_summary()}")
            raise
    
    async def _initialize_basic_services(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„œë¹„ìŠ¤ë“¤ì„ ë³‘ë ¬ë¡œ ì´ˆê¸°í™”"""
        logger.info("ğŸ”§ Initializing basic services...")
        
        services = {}
        
        # Redis Manager ì´ˆê¸°í™” (ì„ íƒì )
        try:
            logger.info("ğŸ”— Initializing Redis Connection Manager...")
            redis_manager = RedisConnectionManager()
            await redis_manager.initialize()
            services['redis_manager'] = redis_manager
            self.status.redis_manager = True
            logger.info("âœ… Redis Connection Manager initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Redis Connection Manager failed: {e}")
            logger.info("ğŸ’¡ Continuing without Redis (chat history will be limited)")
            services['redis_manager'] = None
            self.status.redis_manager = False
        
        # Vector DB Manager ì´ˆê¸°í™” (í•„ìˆ˜)
        try:
            logger.info("ğŸ—„ï¸ Initializing Vector DB Manager...")
            vector_db = VectorDBManager()
            await vector_db.initialize()
            services['vector_db'] = vector_db
            self.status.vector_db = True
            logger.info("âœ… Vector DB Manager initialized")
        except Exception as e:
            logger.error(f"âŒ Vector DB Manager failed: {e}")
            services['vector_db'] = None
            self.status.vector_db = False
            raise CriticalServiceFailure(f"Vector DB initialization failed: {e}")
        
        # LLM Client ì´ˆê¸°í™” (í•„ìˆ˜)
        try:
            logger.info("ğŸ¤– Initializing LLM Client...")
            llm_client = LLMClient()
            await llm_client.initialize()
            services['llm_client'] = llm_client
            self.status.llm_client = True
            logger.info("âœ… LLM Client initialized")
        except Exception as e:
            logger.error(f"âŒ LLM Client failed: {e}")
            services['llm_client'] = None
            self.status.llm_client = False
            raise CriticalServiceFailure(f"LLM Client initialization failed: {e}")
        
        return services
    
    async def _initialize_ai_services(
        self, 
        llm_client: Optional[LLMClient],
        basic_services: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """LLM ê¸°ë°˜ AI ì„œë¹„ìŠ¤ë“¤ì„ ì´ˆê¸°í™”"""
        logger.info("ğŸ§  Initializing AI services...")
        
        services = {}
        
        if not llm_client:
            logger.warning("âš ï¸ LLM Client not available, skipping AI services")
            services['quiz_service'] = None
            services['proofreading_service'] = None
            return services
        
        # VectorDB ê°€ì ¸ì˜¤ê¸° (QuizServiceì—ì„œ í•„ìš”) - basic_servicesì—ì„œ ì§ì ‘ ê°€ì ¸ì˜¤ê¸°
        vector_db = basic_services.get('vector_db') if basic_services else None
        
        # Quiz Service ì´ˆê¸°í™”
        try:
            logger.info("ğŸ“ Initializing Quiz Service...")
            quiz_service = QuizService()
            # LLM Client ì¬ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”
            quiz_service.llm_client = llm_client
            if llm_client:
                from src.services.llm_client import QuizLLMClient
                quiz_service.quiz_llm_client = QuizLLMClient(llm_client)
            
            # VectorDB ì£¼ì… (ì¤‘ìš”!)
            quiz_service.vector_db = vector_db
            logger.info(f"ğŸ“Š QuizService VectorDB injection: {'âœ… Success' if vector_db else 'âŒ VectorDB not available'}")
            
            await quiz_service.initialize()
            services['quiz_service'] = quiz_service
            self.status.quiz_service = True
            logger.info("âœ… Quiz Service initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Quiz Service failed: {e}")
            logger.info("ğŸ’¡ Quiz generation will use mock data")
            services['quiz_service'] = None
            self.status.quiz_service = False
        
        # Proofreading Service ì´ˆê¸°í™”
        try:
            logger.info("âœï¸ Initializing Proofreading Service...")
            proofreading_service = ProofreadingService()
            # LLM Client ì¬ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°í™”
            proofreading_service.llm_client = llm_client
            if llm_client:
                from src.services.llm_client import ProofreadingLLMClient
                proofreading_service.proofreading_llm_client = ProofreadingLLMClient(llm_client)
            await proofreading_service.initialize()
            services['proofreading_service'] = proofreading_service
            self.status.proofreading_service = True
            logger.info("âœ… Proofreading Service initialized")
        except Exception as e:
            logger.warning(f"âš ï¸ Proofreading Service failed: {e}")
            logger.info("ğŸ’¡ Text proofreading will use mock data")
            services['proofreading_service'] = None
            self.status.proofreading_service = False
        
        return services
    
    def get_initialization_status(self) -> ServiceInitializationStatus:
        """í˜„ì¬ ì´ˆê¸°í™” ìƒíƒœ ë°˜í™˜"""
        return self.status
    
    def get_initialized_services(self) -> Dict[str, Any]:
        """ì´ˆê¸°í™”ëœ ì„œë¹„ìŠ¤ë“¤ ë°˜í™˜"""
        return self.services.copy()
    
    async def cleanup_services(self):
        """ì„œë¹„ìŠ¤ë“¤ ì •ë¦¬"""
        logger.info("ğŸ§¹ Cleaning up services...")
        
        try:
            if self.services.get('vector_db'):
                # VectorDB cleanup if available
                if hasattr(self.services['vector_db'], 'cleanup'):
                    await self.services['vector_db'].cleanup()
                logger.info("âœ… Vector DB cleaned up")
        except Exception as e:
            logger.error(f"âš ï¸ Error cleaning up Vector DB: {e}")
        
        try:
            if self.services.get('redis_manager'):
                await self.services['redis_manager'].cleanup()
                logger.info("âœ… Redis connections cleaned up")
        except Exception as e:
            logger.error(f"âš ï¸ Error cleaning up Redis: {e}")
        
        logger.info("âœ… Service cleanup complete")

"""
OCR Service for processing PDF documents
Enhanced version with multiple OCR engines and intelligent engine selection
Stage 2: Multi-engine integration with language detection
"""
import asyncio
import io
import time
import re
from typing import List, Dict, Any, Tuple, Optional

import fitz  # PyMuPDF
import pytesseract
from PIL import Image, ImageEnhance, ImageFilter
from loguru import logger

# Import enhanced OCR service
from .enhanced_ocr_service import EnhancedOCRService, OCRConfig, OCREngine

# Tesseract-OCR ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
# ì˜ˆ: pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'

class OcrService:
    """Handles PDF parsing and OCR extraction with enhanced capabilities - Stage 2"""

    def __init__(self):
        # Stage 2: Enhanced multi-engine configuration
        self.config = OCRConfig(
            primary_engine=OCREngine.TESSERACT,  # ì•ˆì •ì„± ìš°ì„ 
            fallback_engines=[OCREngine.EASYOCR, OCREngine.PADDLEOCR],  # ë‹¤ì¤‘ fallback
            languages=['ko', 'en'],
            confidence_threshold=0.3,  # 0.1 â†’ 0.3 (í’ˆì§ˆ í–¥ìƒ)
            enable_preprocessing=True,  # ì „ì²˜ë¦¬ í™œì„±í™”
            max_image_size=1536,
            dpi=200,
            use_gpu=False
        )
        
        self.enhanced_ocr = EnhancedOCRService(self.config)
        
        # Stage 2: Language detection patterns
        self.korean_pattern = re.compile(r'[ê°€-í£]')
        self.english_pattern = re.compile(r'[a-zA-Z]')
        self.number_pattern = re.compile(r'[0-9]')
        
        # Stage 2: Engine selection strategy
        self.engine_strategy = {
            'korean_heavy': OCREngine.PADDLEOCR,  # í•œêµ­ì–´ ì§‘ì¤‘ ë¬¸ì„œ
            'english_heavy': OCREngine.EASYOCR,   # ì˜ì–´ ì§‘ì¤‘ ë¬¸ì„œ
            'mixed': OCREngine.TESSERACT,         # í•œì˜ í˜¼í•© ë¬¸ì„œ
            'numbers_heavy': OCREngine.TESSERACT  # ìˆ«ì ì§‘ì¤‘ ë¬¸ì„œ
        }
        
        logger.info(f"ğŸš€ [STAGE 2] Multi-engine OcrService initialized:")
        logger.info(f"   Primary: {self.config.primary_engine.value}")
        logger.info(f"   Fallbacks: {[e.value for e in self.config.fallback_engines]}")
        logger.info(f"   Language detection: Enabled")
        logger.info(f"   Preprocessing: {self.config.enable_preprocessing}")
    
    def _enhance_image_for_ocr(self, image: Image.Image) -> Image.Image:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ í•¨ìˆ˜ - 1ë‹¨ê³„ ìµœì í™”
        ëŒ€ë¹„ í–¥ìƒ, ì„ ëª…ë„ ê°œì„ , ë…¸ì´ì¦ˆ ì œê±° ì ìš©
        """
        try:
            start_time = time.time()
            
            # Convert to RGB if necessary
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            # ì´ë¯¸ì§€ í¬ê¸° ì œí•œ (ë©”ëª¨ë¦¬ ìµœì í™”)
            max_size = 1536  # ê³„íšì„œì— ë”°ë¥¸ ìµœì í™”ëœ í¬ê¸°
            if max(image.size) > max_size:
                image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                logger.debug(f"Image resized to {image.size}")
            
            # 1. ëŒ€ë¹„(Contrast) í–¥ìƒ: 1.2ë°° ì ìš©
            enhancer = ImageEnhance.Contrast(image)
            image = enhancer.enhance(1.2)
            
            # 2. ì„ ëª…ë„(Sharpness) ê°œì„ : 1.1ë°° ì ìš©
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.1)
            
            # 3. ë…¸ì´ì¦ˆ ì œê±°: MedianFilter ì ìš©
            image = image.filter(ImageFilter.MedianFilter(size=3))
            
            processing_time = time.time() - start_time
            logger.debug(f"Image preprocessing completed in {processing_time:.3f}s")
            
            return image
            
        except Exception as e:
            logger.warning(f"Image preprocessing failed: {e}, using original image")
            return image
    
    def _validate_ocr_text(self, text: str, confidence: float = None) -> bool:
        """
        í…ìŠ¤íŠ¸ í’ˆì§ˆ ê²€ì¦ ë¡œì§ - 1ë‹¨ê³„ ìµœì í™”
        ê°œì„ ëœ í’ˆì§ˆ ê¸°ì¤€ ì ìš©
        """
        # ê¸°ë³¸ í…ìŠ¤íŠ¸ ê¸¸ì´ ê²€ì‚¬ (50ì â†’ 10ìë¡œ ì™„í™”)
        if len(text.strip()) < 10:
            return False
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
        if confidence is not None and confidence < 0.3:
            return False
        
        # ì˜ë¯¸ìˆëŠ” ë¬¸ì ë¹„ìœ¨ ê²€ì‚¬ (ì•ŒíŒŒë²³, ìˆ«ì, í•œê¸€)
        meaningful_chars = sum(1 for c in text if c.isalnum() or ord(c) > 127)
        total_chars = len(text.replace(' ', '').replace('\n', ''))
        
        if total_chars > 0 and meaningful_chars / total_chars < 0.3:
            return False
        
        return True
    
    def _detect_document_language(self, sample_text: str) -> str:
        """
        Stage 2: ë¬¸ì„œì˜ ì£¼ìš” ì–¸ì–´ ê°ì§€
        ìƒ˜í”Œ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  OCR ì—”ì§„ ì „ëµ ê²°ì •
        """
        if not sample_text or len(sample_text.strip()) < 10:
            return 'mixed'  # ê¸°ë³¸ê°’
        
        # ê° ì–¸ì–´ íŒ¨í„´ ë§¤ì¹­
        korean_matches = len(self.korean_pattern.findall(sample_text))
        english_matches = len(self.english_pattern.findall(sample_text))
        number_matches = len(self.number_pattern.findall(sample_text))
        
        total_chars = len(sample_text.replace(' ', '').replace('\n', ''))
        
        if total_chars == 0:
            return 'mixed'
        
        # ë¹„ìœ¨ ê³„ì‚°
        korean_ratio = korean_matches / total_chars
        english_ratio = english_matches / total_chars
        number_ratio = number_matches / total_chars
        
        logger.debug(f"Language detection - KR: {korean_ratio:.2f}, EN: {english_ratio:.2f}, NUM: {number_ratio:.2f}")
        
        # ì „ëµ ê²°ì • ë¡œì§
        if korean_ratio > 0.3:
            return 'korean_heavy'
        elif english_ratio > 0.5:
            return 'english_heavy'
        elif number_ratio > 0.3:
            return 'numbers_heavy'
        else:
            return 'mixed'
    
    def _get_optimal_engine(self, language_type: str) -> OCREngine:
        """
        Stage 2: ì–¸ì–´ íƒ€ì…ì— ë”°ë¥¸ ìµœì  OCR ì—”ì§„ ì„ íƒ
        """
        optimal_engine = self.engine_strategy.get(language_type, OCREngine.TESSERACT)
        logger.info(f"ğŸ¯ Language type '{language_type}' â†’ Optimal engine: {optimal_engine.value}")
        return optimal_engine
    
    async def _try_multiple_engines(self, pdf_stream: bytes, document_id: str, 
                                  primary_engine: OCREngine) -> Dict[str, Any]:
        """
        Stage 2: ë‹¤ì¤‘ ì—”ì§„ ì‹œë„ ë¡œì§ (fallback ë©”ì»¤ë‹ˆì¦˜)
        """
        engines_to_try = [primary_engine] + [e for e in self.config.fallback_engines if e != primary_engine]
        
        for i, engine in enumerate(engines_to_try):
            try:
                logger.info(f"ğŸ”§ Trying engine {i+1}/{len(engines_to_try)}: {engine.value}")
                
                # ì—”ì§„ë³„ ì„¤ì • ì¡°ì •
                temp_config = OCRConfig(
                    primary_engine=engine,
                    fallback_engines=[],  # ê°œë³„ ì‹œë„ ì‹œì—ëŠ” fallback ë¹„í™œì„±í™”
                    languages=self.config.languages,
                    confidence_threshold=self.config.confidence_threshold,
                    enable_preprocessing=self.config.enable_preprocessing,
                    max_image_size=self.config.max_image_size,
                    dpi=self.config.dpi,
                    use_gpu=self.config.use_gpu
                )
                
                temp_ocr_service = EnhancedOCRService(temp_config)
                result = await temp_ocr_service.process_pdf_stream(pdf_stream, f"{document_id}_attempt_{i+1}")
                
                if result.get("success", False):
                    # ê²°ê³¼ í’ˆì§ˆ ê²€ì¦
                    text_blocks = result.get("text_blocks", [])
                    total_text = " ".join([block.get("text", "") for block in text_blocks])
                    
                    if self._validate_ocr_text(total_text):
                        logger.info(f"âœ… Success with {engine.value}: {len(text_blocks)} blocks, {len(total_text)} chars")
                        result["engine_used"] = f"{engine.value} (Multi-Engine v2.0)"
                        result["engine_attempt"] = i + 1
                        return result
                    else:
                        logger.warning(f"âš ï¸ {engine.value} produced low quality result, trying next engine")
                else:
                    logger.warning(f"âŒ {engine.value} failed: {result.get('error', 'Unknown error')}")
                    
            except Exception as e:
                logger.error(f"ğŸ’¥ Exception with {engine.value}: {e}")
                continue
        
        # ëª¨ë“  ì—”ì§„ ì‹¤íŒ¨ ì‹œ
        return {
            "success": False,
            "error": "All OCR engines failed",
            "document_id": document_id,
            "engines_tried": [e.value for e in engines_to_try]
        }

    async def process_pdf_stream(self, pdf_stream: bytes, document_id: str) -> Dict[str, Any]:
        """
        Stage 2: ë‹¤ì¤‘ OCR ì—”ì§„ ë° ì§€ëŠ¥í˜• ì–¸ì–´ ê°ì§€ê°€ ì ìš©ëœ PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ì–¸ì–´ë³„ ìµœì  ì—”ì§„ ì„ íƒ ë° fallback ë©”ì»¤ë‹ˆì¦˜ í¬í•¨
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸš€ [STAGE 2] Starting multi-engine OCR process for document: {document_id}")
            
            # PDF ë¬¸ì„œ ì—´ê¸°
            pdf_document = None
            try:
                if hasattr(fitz, 'Document'):
                    pdf_document = fitz.Document(stream=pdf_stream, filetype="pdf")
                else:
                    pdf_document = fitz.open(stream=pdf_stream, filetype="pdf")
            except Exception as e:
                logger.error(f"Failed to open PDF: {e}")
                return {"success": False, "error": f"Cannot open PDF: {e}"}
            
            total_pages = len(pdf_document)
            logger.info(f"ğŸ“„ PDF has {total_pages} pages")

            # Stage 2: ì–¸ì–´ ê°ì§€ë¥¼ ìœ„í•œ ìƒ˜í”Œ í…ìŠ¤íŠ¸ ìˆ˜ì§‘ (ì²« 1-2 í˜ì´ì§€)
            sample_pages = min(2, total_pages)
            sample_text = ""
            
            for page_num in range(sample_pages):
                page = pdf_document.load_page(page_num)
                text_content = page.get_text()
                
                if self._validate_ocr_text(text_content):
                    sample_text += text_content + " "
                else:
                    # ê°„ë‹¨í•œ OCRë¡œ ìƒ˜í”Œë§ (ë¹ ë¥¸ ì–¸ì–´ ê°ì§€ìš©)
                    try:
                        pix = page.get_pixmap(dpi=150)  # ë‚®ì€ DPIë¡œ ë¹ ë¥¸ ì²˜ë¦¬
                        img = Image.open(io.BytesIO(pix.tobytes()))
                        quick_text = pytesseract.image_to_string(img, lang='kor+eng', config='--psm 6')
                        sample_text += quick_text + " "
                        del img, pix
                    except Exception as e:
                        logger.warning(f"Quick sampling failed for page {page_num + 1}: {e}")
                
                if len(sample_text) > 500:  # ì¶©ë¶„í•œ ìƒ˜í”Œ ìˆ˜ì§‘ì‹œ ì¤‘ë‹¨
                    break
            
            # Stage 2: ì–¸ì–´ ê°ì§€ ë° ìµœì  ì—”ì§„ ì„ íƒ
            language_type = self._detect_document_language(sample_text)
            optimal_engine = self._get_optimal_engine(language_type)
            
            logger.info(f"ğŸ¯ Document analysis complete:")
            logger.info(f"   ğŸ“ Sample text length: {len(sample_text)} chars")
            logger.info(f"   ğŸŒ Language type: {language_type}")
            logger.info(f"   ğŸ”§ Optimal engine: {optimal_engine.value}")
            
            # Stage 2: ì„ íƒëœ ì—”ì§„ìœ¼ë¡œ ì „ì²´ ë¬¸ì„œ ì²˜ë¦¬ (fallback í¬í•¨)
            result = await self._try_multiple_engines(pdf_stream, document_id, optimal_engine)
            
            if result.get("success", False):
                # Stage 2: í˜¸í™˜ì„±ì„ ìœ„í•´ ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                text_blocks = result.get("text_blocks", [])
                full_text = "\n\n".join([block.get("text", "") for block in text_blocks if block.get("text", "").strip()])
                
                # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì„±
                page_texts = []
                page_groups = {}
                
                for block in text_blocks:
                    page_num = block.get("page_number", 1)
                    if page_num not in page_groups:
                        page_groups[page_num] = []
                    page_groups[page_num].append(block.get("text", ""))
                
                for page_num in range(1, total_pages + 1):
                    page_text = "\n".join(page_groups.get(page_num, []))
                    page_texts.append({
                        "page_number": page_num,
                        "text": page_text.strip(),
                        "processing_time": 0  # ì „ì²´ ì²˜ë¦¬ì— í¬í•¨ë¨
                    })
                
                total_time = time.time() - start_time
                
                # Stage 2: ê³ ê¸‰ ì„±ëŠ¥ ë¡œê¹…
                logger.info(f"âœ… [STAGE 2] Multi-engine OCR completed for {document_id}:")
                logger.info(f"   ğŸ•’ Total time: {total_time:.2f}s")
                logger.info(f"   ğŸ“„ Pages processed: {total_pages}")
                logger.info(f"   ğŸ”§ Engine used: {result.get('engine_used', 'Unknown')}")
                logger.info(f"   ğŸ† Engine attempt: {result.get('engine_attempt', 'N/A')}")
                logger.info(f"   ğŸ“Š Text blocks: {len(text_blocks)}")
                logger.info(f"   ğŸ¯ Total characters: {len(full_text)}")
                logger.info(f"   ğŸŒ Language type: {language_type}")

                return {
                    "success": True,
                    "document_id": document_id,
                    "total_pages": total_pages,
                    "full_text": full_text,
                    "page_texts": page_texts,
                    "engine_used": result.get("engine_used", "Multi-Engine v2.0"),
                    "processing_stats": {
                        "total_time": total_time,
                        "engine_attempt": result.get("engine_attempt", 1),
                        "language_type": language_type,
                        "optimal_engine": optimal_engine.value,
                        "text_blocks_count": len(text_blocks),
                        "total_characters": len(full_text),
                        "stage": "Stage 2 - Multi-Engine"
                    }
                }
            else:
                # Stage 2 ì‹¤íŒ¨ ì‹œ Stage 1 fallback
                logger.warning(f"âš ï¸ Stage 2 failed, falling back to Stage 1 processing")
                return await self._stage1_fallback_process(pdf_stream, document_id)

        except Exception as e:
            logger.error(f"Stage 2 OCR processing failed for {document_id}: {e}")
            logger.info(f"ğŸ”„ Attempting Stage 1 fallback...")
            try:
                return await self._stage1_fallback_process(pdf_stream, document_id)
            except Exception as e2:
                logger.error(f"Stage 1 fallback also failed: {e2}")
                return {
                    "success": False, 
                    "error": f"Stage 2 error: {str(e)}, Stage 1 fallback error: {str(e2)}",
                    "document_id": document_id
                }
    
    async def _stage1_fallback_process(self, pdf_stream: bytes, document_id: str) -> Dict[str, Any]:
        """
        Stage 1 fallback: ê¸°ë³¸ Tesseract ì²˜ë¦¬ (í˜¸í™˜ì„± ë³´ì¥)
        Stage 2 ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ë˜ëŠ” ì•ˆì •ì ì¸ ì²˜ë¦¬ ë°©ì‹
        """
        try:
            start_time = time.time()
            logger.info(f"ğŸ”„ [STAGE 1 FALLBACK] Starting basic OCR process for document: {document_id}")
            
            # PDF ë¬¸ì„œ ì—´ê¸°
            pdf_document = None
            try:
                if hasattr(fitz, 'Document'):
                    pdf_document = fitz.Document(stream=pdf_stream, filetype="pdf")
                else:
                    pdf_document = fitz.open(stream=pdf_stream, filetype="pdf")
            except Exception as e:
                logger.error(f"Failed to open PDF: {e}")
                return {"success": False, "error": f"Cannot open PDF: {e}"}
            
            total_pages = len(pdf_document)
            logger.info(f"ğŸ“„ PDF has {total_pages} pages (fallback processing)")

            # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ìˆ˜ì§‘
            full_text = ""
            page_texts = []
            ocr_stats = {
                "pages_with_text_layer": 0,
                "pages_ocr_processed": 0,
                "total_preprocessing_time": 0,
                "total_ocr_time": 0
            }
            
            for page_num in range(total_pages):
                page_start_time = time.time()
                page = pdf_document.load_page(page_num)
                
                # ë¨¼ì € í…ìŠ¤íŠ¸ ë ˆì´ì–´ê°€ ìˆëŠ”ì§€ í™•ì¸
                text_content = page.get_text()
                
                if self._validate_ocr_text(text_content):
                    page_text = text_content
                    ocr_stats["pages_with_text_layer"] += 1
                    logger.info(f"ğŸ“ Page {page_num + 1}: Using text layer ({len(text_content)} chars)")
                else:
                    # í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ OCR ìˆ˜í–‰ (ì´ë¯¸ì§€ PDF)
                    ocr_start_time = time.time()
                    
                    # ìµœì í™”ëœ DPI ì„¤ì •: 200
                    pix = page.get_pixmap(dpi=200)
                    img = Image.open(io.BytesIO(pix.tobytes()))
                    
                    # Stage 1 ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì ìš©
                    img = self._enhance_image_for_ocr(img)
                    ocr_stats["total_preprocessing_time"] += time.time() - ocr_start_time
                    
                    # Tesseract OCR ì²˜ë¦¬
                    ocr_process_start = time.time()
                    page_text = pytesseract.image_to_string(
                        img, 
                        lang='kor+eng',
                        config='--oem 3 --psm 6'
                    )
                    ocr_process_time = time.time() - ocr_process_start
                    ocr_stats["total_ocr_time"] += ocr_process_time
                    ocr_stats["pages_ocr_processed"] += 1
                    
                    # ë©”ëª¨ë¦¬ ì •ë¦¬
                    del img, pix
                    
                    logger.info(f"ğŸ” Page {page_num + 1}: Fallback OCR processed ({ocr_process_time:.2f}s, {len(page_text)} chars)")
                
                # í…ìŠ¤íŠ¸ í’ˆì§ˆ ì¬ê²€ì¦
                if self._validate_ocr_text(page_text):
                    page_texts.append({
                        "page_number": page_num + 1,
                        "text": page_text.strip(),
                        "processing_time": time.time() - page_start_time
                    })
                    full_text += page_text + "\n\n"
                else:
                    logger.warning(f"Page {page_num + 1}: Text quality too low, skipping")
                    page_texts.append({
                        "page_number": page_num + 1,
                        "text": "",
                        "processing_time": time.time() - page_start_time,
                        "skipped": True
                    })

            # ì „ì²´ í…ìŠ¤íŠ¸ ì •ë¦¬
            full_text = full_text.strip()
            total_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë¡œê¹…
            logger.info(f"âœ… [STAGE 1 FALLBACK] OCR completed for {document_id}:")
            logger.info(f"   ğŸ“Š Total time: {total_time:.2f}s")
            logger.info(f"   ğŸ“„ Pages processed: {total_pages}")
            logger.info(f"   ğŸ“ Text layer pages: {ocr_stats['pages_with_text_layer']}")
            logger.info(f"   ğŸ” OCR processed pages: {ocr_stats['pages_ocr_processed']}")
            logger.info(f"   ğŸ¯ Characters extracted: {len(full_text)}")

            return {
                "success": True,
                "document_id": document_id,
                "total_pages": total_pages,
                "full_text": full_text,
                "page_texts": page_texts,
                "engine_used": "Tesseract Enhanced v1.0 (Fallback)",
                "processing_stats": {
                    "total_time": total_time,
                    "pages_with_text_layer": ocr_stats["pages_with_text_layer"],
                    "pages_ocr_processed": ocr_stats["pages_ocr_processed"],
                    "avg_preprocessing_time": ocr_stats["total_preprocessing_time"] / max(1, ocr_stats["pages_ocr_processed"]),
                    "total_characters": len(full_text),
                    "stage": "Stage 1 - Fallback"
                }
            }

        except Exception as e:
            logger.error(f"Stage 1 fallback processing failed for {document_id}: {e}")
            return {
                "success": False, 
                "error": str(e),
                "document_id": document_id
            }

    async def _legacy_process_pdf_stream(self, pdf_stream: bytes, document_id: str) -> Dict[str, Any]:
        """
        Legacy OCR processing using Tesseract (fallback method)
        """
        try:
            logger.info(f"Starting legacy OCR process for document: {document_id}")
            
            # Open PDF from byte stream (backward compatible)
            pdf_document = None
            try:
                # Try Document constructor first (recommended for newer versions)
                if hasattr(fitz, 'Document'):
                    pdf_document = fitz.Document(stream=pdf_stream, filetype="pdf")
                    logger.debug("Using fitz.Document() constructor")
                else:
                    raise AttributeError("Document class not available")
            except (AttributeError, TypeError) as e:
                logger.debug(f"fitz.Document() failed: {e}, trying fitz.open()")
                try:
                    # Fallback to open function (for older versions)
                    if hasattr(fitz, 'open'):
                        pdf_document = fitz.open(stream=pdf_stream, filetype="pdf")
                        logger.debug("Using fitz.open() function")
                    else:
                        raise AttributeError("open function not available")
                except Exception as e2:
                    logger.error(f"Both fitz.Document() and fitz.open() failed: {e2}")
                    raise Exception(f"Cannot open PDF: {e2}")
            
            if pdf_document is None:
                raise Exception("Failed to open PDF document")
            total_pages = len(pdf_document)
            logger.info(f"PDF has {total_pages} pages (legacy processing).")

            all_text_blocks = []
            
            for page_num in range(total_pages):
                page = pdf_document.load_page(page_num)
                
                # Render page to an image (pixmap)
                pix = page.get_pixmap(dpi=300)
                img = Image.open(io.BytesIO(pix.tobytes()))

                # Use pytesseract to get detailed OCR data
                # lang='kor+eng' for Korean and English
                ocr_data = pytesseract.image_to_data(
                    img, 
                    lang='kor+eng', 
                    output_type=pytesseract.Output.DICT,
                    config='--psm 11' #  Page segmentation mode 11 (sparse text)
                )

                page_blocks = self._parse_tesseract_data(ocr_data, page_num + 1)
                all_text_blocks.extend(page_blocks)

            logger.info(f"Legacy OCR extracted {len(all_text_blocks)} text blocks from document {document_id}.")

            return {
                "success": True,
                "document_id": document_id,
                "total_pages": total_pages,
                "text_blocks": all_text_blocks,
                "engine_used": "TesseractEngine (Legacy)"
            }

        except Exception as e:
            logger.error(f"Error during legacy PDF processing for {document_id}: {e}")
            return {"success": False, "error": str(e)}

    def _parse_tesseract_data(self, data: Dict[str, List], page_number: int) -> List[Dict[str, Any]]:
        """Parses the raw data dictionary from pytesseract into TextBlock format."""
        blocks = []
        n_boxes = len(data['level'])
        
        for i in range(n_boxes):
            # We are interested in text lines, so we look at level 4 (text line)
            if data['level'][i] == 4 and data['text'][i].strip():
                confidence = float(data['conf'][i]) / 100.0 if data['conf'][i] > 0 else 0.0
                
                # Apply confidence threshold
                if confidence >= 0.3:  # Lower threshold for legacy fallback
                    (x, y, w, h) = (data['left'][i], data['top'][i], data['width'][i], data['height'][i])
                    
                    blocks.append({
                        "text": data['text'][i],
                        "page_number": page_number,
                        "x0": x,
                        "y0": y,
                        "x1": x + w,
                        "y1": y + h,
                        "confidence": confidence,
                        "block_type": "text"
                    })
        return blocks


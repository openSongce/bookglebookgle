"""
ë‹¨ìˆœí™”ëœ OCR ì„œë¹„ìŠ¤
PaddleOCR ì „ìš© OCR ì„œë¹„ìŠ¤ - LLM í›„ì²˜ë¦¬ ì—†ì´ ê³ ì„±ëŠ¥ í…ìŠ¤íŠ¸ ì¶”ì¶œ
ê¸°ì¡´ì˜ ë³µì¡í•œ ë‹¤ì¤‘ ì—”ì§„ êµ¬ì¡°ë¥¼ ëŒ€ì²´í•˜ëŠ” ìµœì í™”ëœ ì„œë¹„ìŠ¤
"""

import asyncio
import time
import traceback
from typing import Dict, Any, List, Optional, Tuple
import psutil
import os

import fitz  # PyMuPDF
from loguru import logger

from src.models.ocr_models import (
    OCRBlock, ProcessedOCRBlock, ProcessingMetrics
)
from src.services.paddleocr_engine import PaddleOCREngine, PaddleOCRConfig


class SimplifiedOCRService:
    """
    ë‹¨ìˆœí™”ëœ OCR ì„œë¹„ìŠ¤ - PaddleOCR ê¸°ë°˜, LLM í›„ì²˜ë¦¬ ì—†ëŠ” ê³ ì„±ëŠ¥ ì„œë¹„ìŠ¤
    ê¸°ì¡´ ë³µì¡í•œ ë‹¤ì¤‘ ì—”ì§„ êµ¬ì¡°ë¥¼ ëŒ€ì²´í•˜ëŠ” ìµœì í™”ëœ ì„œë¹„ìŠ¤
    """
    
    def __init__(
        self,
        paddleocr_config: Optional[PaddleOCRConfig] = None,
        enable_llm_postprocessing: bool = False  # ê¸°ë³¸ê°’ì„ Falseë¡œ ë³€ê²½
    ):
        """
        SimplifiedOCRService ì´ˆê¸°í™”
        
        Args:
            paddleocr_config: PaddleOCR ì„¤ì • (Noneì´ë©´ ê¸°ë³¸ ì„¤ì •)
            enable_llm_postprocessing: LLM í›„ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€ (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        """
        # ì„¤ì • ì´ˆê¸°í™”
        self.paddleocr_config = paddleocr_config or PaddleOCRConfig()
        self.enable_llm_postprocessing = False  # ê°•ì œë¡œ Falseë¡œ ì„¤ì •
        
        # ì—”ì§„ ì´ˆê¸°í™”
        self.ocr_engine = PaddleOCREngine(self.paddleocr_config)
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.processing_stats = {
            'total_documents': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_processing_time': 0.0,
            'total_ocr_time': 0.0,
            'total_pages_processed': 0,
            'total_blocks_extracted': 0,
            'total_vectordb_time': 0.0
        }
        
        logger.info(f"ğŸš€ SimplifiedOCRService initialized:")
        logger.info(f"   ğŸ”§ PaddleOCR language: {self.paddleocr_config.lang}")
        logger.info(f"   ğŸ¤– LLM post-processing: Disabled")
        logger.info(f"   ğŸ–¥ï¸ GPU usage: {self.paddleocr_config.use_gpu}")
        logger.info(f"   ğŸ”„ Angle classification: {self.paddleocr_config.use_angle_cls}")
    
    async def initialize(self) -> bool:
        """
        ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ë¹„ë™ê¸° ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™”)
        
        Returns:
            ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
        """
        try:
            logger.info("ğŸ”„ Initializing SimplifiedOCRService components...")
            
            # 1. PaddleOCR ì—”ì§„ ì´ˆê¸°í™”
            ocr_success = await self.ocr_engine.initialize()
            if not ocr_success:
                logger.error("âŒ PaddleOCR engine initialization failed")
                return False
            
            # VectorDB ì´ˆê¸°í™”ëŠ” AI Servicerì—ì„œ ë‹´ë‹¹
            
            logger.info("âœ… SimplifiedOCRService initialization completed")
            logger.info("ğŸ“ Pipeline: PDF â†’ PaddleOCR (LLM í›„ì²˜ë¦¬ ì—†ìŒ, VectorDBëŠ” AI Servicerì—ì„œ ì²˜ë¦¬)")
            return True
            
        except Exception as e:
            logger.error(f"âŒ SimplifiedOCRService initialization failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False
    
    async def process_pdf_stream(
        self, 
        pdf_stream: bytes, 
        document_id: str,
        enable_llm_postprocessing: Optional[bool] = None
    ) -> Dict[str, Any]:
        """
        PDF ìŠ¤íŠ¸ë¦¼ì„ ì²˜ë¦¬í•˜ì—¬ PaddleOCRë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (VectorDB ì €ì¥ì€ AI Servicerì—ì„œ ë‹´ë‹¹)
        
        Args:
            pdf_stream: PDF ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
            document_id: ë¬¸ì„œ ID
            enable_llm_postprocessing: LLM í›„ì²˜ë¦¬ í™œì„±í™” ì—¬ë¶€ (ë¬´ì‹œë¨)
            
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        # ì²˜ë¦¬ ì‹œì‘
        start_time = time.time()
        process_memory_start = self._get_memory_usage()
        
        logger.info(f"ğŸš€ Starting PDF processing for document: {document_id}")
        logger.info(f"   ğŸ“„ PDF size: {len(pdf_stream):,} bytes")
        logger.info(f"   ğŸ¤– LLM post-processing: Disabled (new pipeline)")
        
        try:
            # 1ë‹¨ê³„: PaddleOCRì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            ocr_result = await self._extract_with_paddleocr(pdf_stream, document_id)
            
            if not ocr_result["success"]:
                return self._create_error_response(
                    document_id, 
                    ocr_result["error"], 
                    start_time
                )
            
            ocr_blocks = ocr_result["ocr_blocks"]
            ocr_time = ocr_result["processing_time"]
            
            # 2ë‹¨ê³„: LLM í›„ì²˜ë¦¬ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°
            logger.info("ğŸ¤– Skipping LLM post-processing as per the new pipeline.")
            
            # 3ë‹¨ê³„: VectorDB ì €ì¥ì€ AI Servicerì—ì„œ ë‹´ë‹¹í•˜ë¯€ë¡œ ê±´ë„ˆë›°ê¸°
            logger.info("ğŸ’¾ VectorDB storage will be handled by AI Servicer")
            vectordb_time = 0.0  # VectorDB ì €ì¥ ì‹œê°„ì€ 0ìœ¼ë¡œ ì„¤ì •
            
            # 4ë‹¨ê³„: ìµœì¢… ì‘ë‹µ ìƒì„±
            final_result = await self._create_final_response(
                document_id=document_id,
                ocr_blocks=ocr_blocks,
                ocr_time=ocr_time,
                vectordb_time=vectordb_time,
                start_time=start_time,
                process_memory_start=process_memory_start,
                pdf_size=len(pdf_stream)
            )
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            self._update_processing_stats(final_result, success=True)
            
            return final_result
            
        except Exception as e:
            logger.error(f"âŒ PDF processing failed for {document_id}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            
            error_result = self._create_error_response(document_id, str(e), start_time)
            self._update_processing_stats(error_result, success=False)
            
            return error_result
    
    async def _extract_with_paddleocr(
        self, 
        pdf_stream: bytes, 
        document_id: str
    ) -> Dict[str, Any]:
        """
        PaddleOCRì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        
        Args:
            pdf_stream: PDF ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
            document_id: ë¬¸ì„œ ID
            
        Returns:
            OCR ì²˜ë¦¬ ê²°ê³¼
        """
        try:
            ocr_start_time = time.time()
            logger.info(f"ğŸ” Starting PaddleOCR extraction for document: {document_id}")
            
            # PaddleOCR ì—”ì§„ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            ocr_blocks = await self.ocr_engine.extract_from_pdf(pdf_stream, document_id)
            
            ocr_time = time.time() - ocr_start_time
            
            logger.info(f"âœ… PaddleOCR extraction completed for {document_id}:")
            logger.info(f"   â±ï¸ OCR time: {ocr_time:.2f}s")
            logger.info(f"   ğŸ“Š Blocks extracted: {len(ocr_blocks)}")
            logger.info(f"   ğŸ“ Total characters: {sum(len(block.text) for block in ocr_blocks)}")
            
            return {
                "success": True,
                "ocr_blocks": ocr_blocks,
                "processing_time": ocr_time
            }
            
        except Exception as e:
            logger.error(f"âŒ PaddleOCR extraction failed for {document_id}: {e}")
            return {"success": False, "error": str(e)}
    
    async def _create_final_response(
        self,
        document_id: str,
        ocr_blocks: List[OCRBlock],
        ocr_time: float,
        vectordb_time: float,
        start_time: float,
        process_memory_start: int,
        pdf_size: int
    ) -> Dict[str, Any]:
        """ìµœì¢… ì‘ë‹µ ìƒì„±"""
        total_time = time.time() - start_time
        process_memory_peak = self._get_memory_usage()
        memory_used = process_memory_peak - process_memory_start
        
        # ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜ (API í˜¸í™˜ì„±)
        processed_blocks = self._convert_to_processed_blocks(ocr_blocks)
        
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ API í˜¸í™˜ì„±)
        page_texts = self._create_page_texts(processed_blocks)
        
        # ì „ì²´ í…ìŠ¤íŠ¸ êµ¬ì„±
        full_text = "\n\n".join([
            block.text for block in processed_blocks 
            if block.text.strip()
        ])
        
        # í…ìŠ¤íŠ¸ ë¸”ë¡ í˜•íƒœë¡œ ë³€í™˜ (ê¸°ì¡´ API í˜¸í™˜ì„±)
        text_blocks = [block.to_dict() for block in processed_blocks]
        
        # ì²˜ë¦¬ í†µê³„ ìƒì„±
        avg_ocr_confidence = (sum(block.confidence for block in processed_blocks) 
                             / len(processed_blocks) if processed_blocks else 0.0)
        
        # í˜ì´ì§€ ìˆ˜ ê³„ì‚°
        total_pages = max((block.page_number for block in processed_blocks), default=0)
        
        # ProcessingMetrics ìƒì„±
        metrics = ProcessingMetrics(
            document_id=document_id,
            total_pages=total_pages,
            ocr_time=ocr_time,
            llm_processing_time=0.0,  # LLM ì‚¬ìš© ì•ˆí•¨
            total_time=total_time,
            memory_peak=memory_used,
            text_blocks_count=len(processed_blocks),
            corrections_count=0,  # LLM êµì • ì—†ìŒ
            average_ocr_confidence=avg_ocr_confidence,
            average_processing_confidence=avg_ocr_confidence  # OCR ì‹ ë¢°ë„ì™€ ë™ì¼
        )
        
        logger.info(f"ğŸ‰ Final processing completed for {document_id}:")
        logger.info(f"   â±ï¸ Total time: {total_time:.2f}s")
        logger.info(f"   ğŸ“„ Pages: {total_pages}")
        logger.info(f"   ğŸ“Š Blocks: {len(processed_blocks)}")
        logger.info(f"   ğŸ’¾ VectorDB time: {vectordb_time:.2f}s")
        logger.info(f"   ğŸ’¾ Memory used: {memory_used / 1024 / 1024:.1f} MB")
        logger.info(f"   âš¡ Speed: {len(processed_blocks) / total_time:.1f} blocks/sec")
        
        return {
            "success": True,
            "document_id": document_id,
            "total_pages": total_pages,
            "full_text": full_text,
            "page_texts": page_texts,
            "text_blocks": text_blocks,
            "engine_used": f"SimplifiedOCRService v2.0 (PaddleOCR-only)",
            "processing_stats": metrics.to_dict(),
            "llm_postprocessing_enabled": False,
            "vectordb_stored": False,  # VectorDB ì €ì¥ì€ AI Servicerì—ì„œ ë‹´ë‹¹
            "performance_metrics": {
                "pdf_size_bytes": pdf_size,
                "processing_speed_blocks_per_sec": len(processed_blocks) / total_time if total_time > 0 else 0,
                "memory_efficiency_mb_per_page": (memory_used / 1024 / 1024) / max(total_pages, 1),
                "ocr_to_total_time_ratio": ocr_time / total_time if total_time > 0 else 0,
                "vectordb_to_total_time_ratio": vectordb_time / total_time if total_time > 0 else 0
            }
        }
    
    def _convert_to_processed_blocks(self, ocr_blocks: List[OCRBlock]) -> List[ProcessedOCRBlock]:
        """OCRBlockì„ ProcessedOCRBlockìœ¼ë¡œ ë³€í™˜ (LLM í›„ì²˜ë¦¬ ì—†ì´)"""
        processed_blocks = []
        
        for block in ocr_blocks:
            processed_block = ProcessedOCRBlock(
                text=block.text,
                page_number=block.page_number,
                bbox=block.bbox,
                confidence=block.confidence,
                block_type=block.block_type,
                original_text=block.text,
                corrections=[],  # êµì • ì—†ìŒ
                processing_confidence=block.confidence,  # OCR ì‹ ë¢°ë„ì™€ ë™ì¼
                llm_model="none (PaddleOCR only)"
            )
            processed_blocks.append(processed_block)
        
        return processed_blocks
    
    def _create_page_texts(self, processed_blocks: List[ProcessedOCRBlock]) -> List[Dict[str, Any]]:
        """í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ êµ¬ì„± (ê¸°ì¡´ API í˜¸í™˜ì„±)"""
        page_groups = {}
        
        # í˜ì´ì§€ë³„ë¡œ ë¸”ë¡ ê·¸ë£¹í™”
        for block in processed_blocks:
            page_num = block.page_number
            if page_num not in page_groups:
                page_groups[page_num] = []
            page_groups[page_num].append(block.text)
        
        # í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ ìƒì„±
        page_texts = []
        for page_num in sorted(page_groups.keys()):
            page_text = "\n".join(page_groups[page_num])
            page_texts.append({
                "page_number": page_num,
                "text": page_text.strip(),
                "processing_time": 0  # ì „ì²´ ì²˜ë¦¬ì— í¬í•¨ë¨
            })
        
        return page_texts
    
    def _create_error_response(
            self, 
            document_id: str, 
            error_message: str, 
            start_time: float
        ) -> Dict[str, Any]:
            """ì˜¤ë¥˜ ì‘ë‹µ ìƒì„±"""
            total_time = time.time() - start_time
            
            return {
                "success": False,
                "document_id": document_id,
                "error": error_message,
                "total_pages": 0,
                "full_text": "",
                "page_texts": [],
                "text_blocks": [],
                "engine_used": "SimplifiedOCRService v2.0 (Failed)",
                "processing_stats": {
                    "total_time": total_time,
                    "error": error_message
                },
                "llm_postprocessing_enabled": False,
                "vectordb_stored": False
            }
    
    def _get_memory_usage(self) -> int:
        """í˜„ì¬ í”„ë¡œì„¸ìŠ¤ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë°˜í™˜ (ë°”ì´íŠ¸)"""
        try:
            process = psutil.Process(os.getpid())
            return process.memory_info().rss
        except:
            return 0
    
    def _update_processing_stats(self, result: Dict[str, Any], success: bool):
        """ì²˜ë¦¬ í†µê³„ ì—…ë°ì´íŠ¸"""
        self.processing_stats['total_documents'] += 1
        
        if success:
            self.processing_stats['successful_documents'] += 1
            stats = result.get('processing_stats', {})
            self.processing_stats['total_processing_time'] += stats.get('total_time', 0)
            self.processing_stats['total_ocr_time'] += stats.get('ocr_time', 0)
            self.processing_stats['total_pages_processed'] += result.get('total_pages', 0)
            self.processing_stats['total_blocks_extracted'] += stats.get('text_blocks_count', 0)
            # VectorDB ì‹œê°„ (AI Servicerì—ì„œ ì²˜ë¦¬)
            perf_metrics = result.get('performance_metrics', {})
            total_time = stats.get('total_time', 0)
            vectordb_ratio = perf_metrics.get('vectordb_to_total_time_ratio', 0)
            self.processing_stats['total_vectordb_time'] += total_time * vectordb_ratio
        else:
            self.processing_stats['failed_documents'] += 1
    
    def get_service_info(self) -> Dict[str, Any]:
        """ì„œë¹„ìŠ¤ ì •ë³´ ë°˜í™˜"""
        return {
            "service_name": "SimplifiedOCRService",
            "version": "2.0.0",
            "ocr_engine": self.ocr_engine.get_engine_info(),
            "llm_postprocessing_enabled": False,
            "vectordb_direct_storage": True,
            "processing_statistics": self.processing_stats.copy()
        }
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        stats = self.processing_stats.copy()
        
        # ì¶”ê°€ ê³„ì‚°ëœ í†µê³„
        if stats['successful_documents'] > 0:
            stats['average_processing_time'] = stats['total_processing_time'] / stats['successful_documents']
            stats['average_pages_per_document'] = stats['total_pages_processed'] / stats['successful_documents']
            stats['average_blocks_per_document'] = stats['total_blocks_extracted'] / stats['successful_documents']
            stats['average_vectordb_time'] = stats['total_vectordb_time'] / stats['successful_documents']
        
        if stats['total_documents'] > 0:
            stats['success_rate'] = stats['successful_documents'] / stats['total_documents']
        
        return stats

    async def cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        try:
            if self.ocr_engine:
                await self.ocr_engine.cleanup()
            
            # VectorDB cleanupì€ AI Servicerì—ì„œ ë‹´ë‹¹
            pass
            
            logger.info("âœ… SimplifiedOCRService cleanup completed")
            
        except Exception as e:
            logger.error(f"âš ï¸ Error during SimplifiedOCRService cleanup: {e}")
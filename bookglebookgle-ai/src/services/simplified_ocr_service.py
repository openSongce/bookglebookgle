"""
Îã®ÏàúÌôîÎêú OCR ÏÑúÎπÑÏä§
PaddleOCR Ï†ÑÏö© OCR ÏÑúÎπÑÏä§ - LLM ÌõÑÏ≤òÎ¶¨ ÏóÜÏù¥ Í≥†ÏÑ±Îä• ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
Í∏∞Ï°¥Ïùò Î≥µÏû°Ìïú Îã§Ï§ë ÏóîÏßÑ Íµ¨Ï°∞Î•º ÎåÄÏ≤¥ÌïòÎäî ÏµúÏ†ÅÌôîÎêú ÏÑúÎπÑÏä§
"""

import asyncio
import time
import traceback
from typing import Dict, Any, List, Optional, Tuple
import psutil
import os

import fitz  # PyMuPDF
from loguru import logger

from src.models.ocr_models import (
    OCRBlock, ProcessedOCRBlock, ProcessingMetrics
)
from src.services.paddleocr_engine import PaddleOCREngine, PaddleOCRConfig
from src.services.vector_db import VectorDBManager


class SimplifiedOCRService:
    """
    Îã®ÏàúÌôîÎêú OCR ÏÑúÎπÑÏä§ - PaddleOCR Í∏∞Î∞ò, LLM ÌõÑÏ≤òÎ¶¨ ÏóÜÎäî Í≥†ÏÑ±Îä• ÏÑúÎπÑÏä§
    Í∏∞Ï°¥ Î≥µÏû°Ìïú Îã§Ï§ë ÏóîÏßÑ Íµ¨Ï°∞Î•º ÎåÄÏ≤¥ÌïòÎäî ÏµúÏ†ÅÌôîÎêú ÏÑúÎπÑÏä§
    """
    
    def __init__(
        self,
        paddleocr_config: Optional[PaddleOCRConfig] = None,
        enable_llm_postprocessing: bool = False  # Í∏∞Î≥∏Í∞íÏùÑ FalseÎ°ú Î≥ÄÍ≤Ω
    ):
        """
        SimplifiedOCRService Ï¥àÍ∏∞Ìôî
        
        Args:
            paddleocr_config: PaddleOCR ÏÑ§Ï†ï (NoneÏù¥Î©¥ Í∏∞Î≥∏ ÏÑ§Ï†ï)
            enable_llm_postprocessing: LLM ÌõÑÏ≤òÎ¶¨ ÌôúÏÑ±Ìôî Ïó¨Î∂Ä (ÏÇ¨Ïö©ÌïòÏßÄ ÏïäÏùå)
        """
        # ÏÑ§Ï†ï Ï¥àÍ∏∞Ìôî
        self.paddleocr_config = paddleocr_config or PaddleOCRConfig()
        self.enable_llm_postprocessing = False  # Í∞ïÏ†úÎ°ú FalseÎ°ú ÏÑ§Ï†ï
        
        # ÏóîÏßÑ Ï¥àÍ∏∞Ìôî
        self.ocr_engine = PaddleOCREngine(self.paddleocr_config)
        self.vector_db = VectorDBManager()  # VectorDB ÏßÅÏ†ë Ïó∞Í≤∞
        
        # ÏÑ±Îä• Î™®ÎãàÌÑ∞ÎßÅ
        self.processing_stats = {
            'total_documents': 0,
            'successful_documents': 0,
            'failed_documents': 0,
            'total_processing_time': 0.0,
            'total_ocr_time': 0.0,
            'total_pages_processed': 0,
            'total_blocks_extracted': 0,
            'total_vectordb_time': 0.0
        }
        
        logger.info(f"üöÄ SimplifiedOCRService initialized:")
        logger.info(f"   üîß PaddleOCR language: {self.paddleocr_config.lang}")
        logger.info(f"   ü§ñ LLM post-processing: Disabled (ÏßÅÏ†ë VectorDB Ï†ÄÏû•)")
        logger.info(f"   üñ•Ô∏è GPU usage: {self.paddleocr_config.use_gpu}")
        logger.info(f"   üîÑ Angle classification: {self.paddleocr_config.use_angle_cls}")
    
    async def initialize(self) -> bool:
        """
        ÏÑúÎπÑÏä§ Ï¥àÍ∏∞Ìôî (ÎπÑÎèôÍ∏∞ Ïª¥Ìè¨ÎÑåÌä∏ Ï¥àÍ∏∞Ìôî)
        
        Returns:
            Ï¥àÍ∏∞Ìôî ÏÑ±Í≥µ Ïó¨Î∂Ä
        """
        try:
            logger.info("üîÑ Initializing SimplifiedOCRService components...")
            
            # 1. PaddleOCR ÏóîÏßÑ Ï¥àÍ∏∞Ìôî
            ocr_success = await self.ocr_engine.initialize()
            if not ocr_success:
                logger.error("‚ùå PaddleOCR engine initialization failed")
                return False
            
            # 2. VectorDB Ï¥àÍ∏∞Ìôî
            try:
                await self.vector_db.initialize()
                logger.info("‚úÖ VectorDB initialized successfully")
            except Exception as e:
                logger.error(f"‚ùå VectorDB initialization failed: {e}")
                return False
            
            logger.info("‚úÖ SimplifiedOCRService initialization completed")
            logger.info("üìù Pipeline: PDF ‚Üí PaddleOCR ‚Üí VectorDB (LLM ÌõÑÏ≤òÎ¶¨ ÏóÜÏùå)")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå SimplifiedOCRService initialization failed: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            return False
    
    async def process_pdf_stream(
        self, 
        pdf_stream: bytes, 
        document_id: str,
        enable_llm_postprocessing: Optional[bool] = None
    ) -> Dict[str, Any]:
        """
        PDF Ïä§Ìä∏Î¶ºÏùÑ Ï≤òÎ¶¨ÌïòÏó¨ PaddleOCRÎ°ú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú ÌõÑ VectorDBÏóê ÏßÅÏ†ë Ï†ÄÏû•
        
        Args:
            pdf_stream: PDF Î∞îÏù¥Ìä∏ Ïä§Ìä∏Î¶º
            document_id: Î¨∏ÏÑú ID
            enable_llm_postprocessing: LLM ÌõÑÏ≤òÎ¶¨ ÌôúÏÑ±Ìôî Ïó¨Î∂Ä (Î¨¥ÏãúÎê®)
            
        Returns:
            Ï≤òÎ¶¨ Í≤∞Í≥º ÎîïÏÖîÎÑàÎ¶¨
        """
        # Ï≤òÎ¶¨ ÏãúÏûë
        start_time = time.time()
        process_memory_start = self._get_memory_usage()
        
        logger.info(f"üöÄ Starting PDF processing for document: {document_id}")
        logger.info(f"   üìÑ PDF size: {len(pdf_stream):,} bytes")
        logger.info(f"   ü§ñ LLM post-processing: Disabled (new pipeline)")
        
        try:
            # 1Îã®Í≥Ñ: PaddleOCRÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
            ocr_result = await self._extract_with_paddleocr(pdf_stream, document_id)
            
            if not ocr_result["success"]:
                return self._create_error_response(
                    document_id, 
                    ocr_result["error"], 
                    start_time
                )
            
            ocr_blocks = ocr_result["ocr_blocks"]
            ocr_time = ocr_result["processing_time"]
            
            # 2Îã®Í≥Ñ: LLM ÌõÑÏ≤òÎ¶¨ Îã®Í≥Ñ Í±¥ÎÑàÎõ∞Í∏∞
            logger.info("ü§ñ Skipping LLM post-processing as per the new pipeline.")
            
            # 3Îã®Í≥Ñ: OCR Í≤∞Í≥ºÎ•º VectorDBÏóê ÏßÅÏ†ë Ï†ÄÏû•
            vectordb_result = await self._store_in_vectordb(ocr_blocks, document_id)
            vectordb_time = vectordb_result["processing_time"]
            
            if not vectordb_result["success"]:
                return self._create_error_response(
                    document_id, 
                    f"VectorDB storage failed: {vectordb_result['error']}", 
                    start_time
                )
            
            # 4Îã®Í≥Ñ: ÏµúÏ¢Ö ÏùëÎãµ ÏÉùÏÑ±
            final_result = await self._create_final_response(
                document_id=document_id,
                ocr_blocks=ocr_blocks,
                ocr_time=ocr_time,
                vectordb_time=vectordb_time,
                start_time=start_time,
                process_memory_start=process_memory_start,
                pdf_size=len(pdf_stream)
            )
            
            # ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏
            self._update_processing_stats(final_result, success=True)
            
            return final_result
            
        except Exception as e:
            logger.error(f"‚ùå PDF processing failed for {document_id}: {e}")
            logger.error(f"Traceback: {traceback.format_exc()}")
            
            error_result = self._create_error_response(document_id, str(e), start_time)
            self._update_processing_stats(error_result, success=False)
            
            return error_result
    
    async def _extract_with_paddleocr(
        self, 
        pdf_stream: bytes, 
        document_id: str
    ) -> Dict[str, Any]:
        """
        PaddleOCRÏùÑ ÏÇ¨Ïö©Ìïú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
        
        Args:
            pdf_stream: PDF Î∞îÏù¥Ìä∏ Ïä§Ìä∏Î¶º
            document_id: Î¨∏ÏÑú ID
            
        Returns:
            OCR Ï≤òÎ¶¨ Í≤∞Í≥º
        """
        try:
            ocr_start_time = time.time()
            logger.info(f"üîç Starting PaddleOCR extraction for document: {document_id}")
            
            # PaddleOCR ÏóîÏßÑÏúºÎ°ú ÌÖçÏä§Ìä∏ Ï∂îÏ∂ú
            ocr_blocks = await self.ocr_engine.extract_from_pdf(pdf_stream, document_id)
            
            ocr_time = time.time() - ocr_start_time
            
            logger.info(f"‚úÖ PaddleOCR extraction completed for {document_id}:")
            logger.info(f"   ‚è±Ô∏è OCR time: {ocr_time:.2f}s")
            logger.info(f"   üìä Blocks extracted: {len(ocr_blocks)}")
            logger.info(f"   üìù Total characters: {sum(len(block.text) for block in ocr_blocks)}")
            
            return {
                "success": True,
                "ocr_blocks": ocr_blocks,
                "processing_time": ocr_time
            }
            
        except Exception as e:
            logger.error(f"‚ùå PaddleOCR extraction failed for {document_id}: {e}")
            return {"success": False, "error": str(e)}
    
    async def _store_in_vectordb(
        self, 
        ocr_blocks: List[OCRBlock], 
        document_id: str
    ) -> Dict[str, Any]:
        """
        OCR Í≤∞Í≥ºÎ•º VectorDBÏóê ÏßÅÏ†ë Ï†ÄÏû•
        
        Args:
            ocr_blocks: OCR Î∏îÎ°ù Î¶¨Ïä§Ìä∏
            document_id: Î¨∏ÏÑú ID
            
        Returns:
            VectorDB Ï†ÄÏû• Í≤∞Í≥º
        """
        try:
            vectordb_start_time = time.time()
            logger.info(f"üíæ Starting VectorDB storage for document: {document_id}")
            logger.info(f"   üìä Blocks to store: {len(ocr_blocks)}")
            
            # VectorDBÏóê Ï†ÄÏû•
            success = await self.vector_db.store_document_with_positions(
                document_id=document_id,
                ocr_blocks=ocr_blocks,
                metadata={"ocr_engine": "paddleocr", "llm_postprocessing_enabled": False}
            )
            
            vectordb_time = time.time() - vectordb_start_time
            
            if success:
                logger.info(f"‚úÖ VectorDB storage completed for {document_id}:")
                logger.info(f"   ‚è±Ô∏è Storage time: {vectordb_time:.2f}s")
                logger.info(f"   üìä Blocks stored: {len(ocr_blocks)}")
                
                return {
                    "success": True,
                    "processing_time": vectordb_time,
                    "blocks_stored": len(ocr_blocks)
                }
            else:
                raise Exception("VectorDB storage operation failed")
            
        except Exception as e:
            vectordb_time = time.time() - vectordb_start_time
            logger.error(f"‚ùå VectorDB storage failed for {document_id}: {e}")
            return {
                "success": False, 
                "error": str(e),
                "processing_time": vectordb_time
            }
    
    async def _create_final_response(
        self,
        document_id: str,
        ocr_blocks: List[OCRBlock],
        ocr_time: float,
        vectordb_time: float,
        start_time: float,
        process_memory_start: int,
        pdf_size: int
    ) -> Dict[str, Any]:
        """ÏµúÏ¢Ö ÏùëÎãµ ÏÉùÏÑ±"""
        total_time = time.time() - start_time
        process_memory_peak = self._get_memory_usage()
        memory_used = process_memory_peak - process_memory_start
        
        # ProcessedOCRBlockÏúºÎ°ú Î≥ÄÌôò (API Ìò∏ÌôòÏÑ±)
        processed_blocks = self._convert_to_processed_blocks(ocr_blocks)
        
        # ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ Íµ¨ÏÑ± (Í∏∞Ï°¥ API Ìò∏ÌôòÏÑ±)
        page_texts = self._create_page_texts(processed_blocks)
        
        # Ï†ÑÏ≤¥ ÌÖçÏä§Ìä∏ Íµ¨ÏÑ±
        full_text = "\n\n".join([
            block.text for block in processed_blocks 
            if block.text.strip()
        ])
        
        # ÌÖçÏä§Ìä∏ Î∏îÎ°ù ÌòïÌÉúÎ°ú Î≥ÄÌôò (Í∏∞Ï°¥ API Ìò∏ÌôòÏÑ±)
        text_blocks = [block.to_dict() for block in processed_blocks]
        
        # Ï≤òÎ¶¨ ÌÜµÍ≥Ñ ÏÉùÏÑ±
        avg_ocr_confidence = (sum(block.confidence for block in processed_blocks) 
                             / len(processed_blocks) if processed_blocks else 0.0)
        
        # ÌéòÏù¥ÏßÄ Ïàò Í≥ÑÏÇ∞
        total_pages = max((block.page_number for block in processed_blocks), default=0)
        
        # ProcessingMetrics ÏÉùÏÑ±
        metrics = ProcessingMetrics(
            document_id=document_id,
            total_pages=total_pages,
            ocr_time=ocr_time,
            llm_processing_time=0.0,  # LLM ÏÇ¨Ïö© ÏïàÌï®
            total_time=total_time,
            memory_peak=memory_used,
            text_blocks_count=len(processed_blocks),
            corrections_count=0,  # LLM ÍµêÏ†ï ÏóÜÏùå
            average_ocr_confidence=avg_ocr_confidence,
            average_processing_confidence=avg_ocr_confidence  # OCR Ïã†Î¢∞ÎèÑÏôÄ ÎèôÏùº
        )
        
        logger.info(f"üéâ Final processing completed for {document_id}:")
        logger.info(f"   ‚è±Ô∏è Total time: {total_time:.2f}s")
        logger.info(f"   üìÑ Pages: {total_pages}")
        logger.info(f"   üìä Blocks: {len(processed_blocks)}")
        logger.info(f"   üíæ VectorDB time: {vectordb_time:.2f}s")
        logger.info(f"   üíæ Memory used: {memory_used / 1024 / 1024:.1f} MB")
        logger.info(f"   ‚ö° Speed: {len(processed_blocks) / total_time:.1f} blocks/sec")
        
        return {
            "success": True,
            "document_id": document_id,
            "total_pages": total_pages,
            "full_text": full_text,
            "page_texts": page_texts,
            "text_blocks": text_blocks,
            "engine_used": f"SimplifiedOCRService v2.0 (PaddleOCR-only)",
            "processing_stats": metrics.to_dict(),
            "llm_postprocessing_enabled": False,
            "vectordb_stored": True,
            "performance_metrics": {
                "pdf_size_bytes": pdf_size,
                "processing_speed_blocks_per_sec": len(processed_blocks) / total_time if total_time > 0 else 0,
                "memory_efficiency_mb_per_page": (memory_used / 1024 / 1024) / max(total_pages, 1),
                "ocr_to_total_time_ratio": ocr_time / total_time if total_time > 0 else 0,
                "vectordb_to_total_time_ratio": vectordb_time / total_time if total_time > 0 else 0
            }
        }
    
    def _convert_to_processed_blocks(self, ocr_blocks: List[OCRBlock]) -> List[ProcessedOCRBlock]:
        """OCRBlockÏùÑ ProcessedOCRBlockÏúºÎ°ú Î≥ÄÌôò (LLM ÌõÑÏ≤òÎ¶¨ ÏóÜÏù¥)"""
        processed_blocks = []
        
        for block in ocr_blocks:
            processed_block = ProcessedOCRBlock(
                text=block.text,
                page_number=block.page_number,
                bbox=block.bbox,
                confidence=block.confidence,
                block_type=block.block_type,
                original_text=block.text,
                corrections=[],  # ÍµêÏ†ï ÏóÜÏùå
                processing_confidence=block.confidence,  # OCR Ïã†Î¢∞ÎèÑÏôÄ ÎèôÏùº
                llm_model="none (PaddleOCR only)"
            )
            processed_blocks.append(processed_block)
        
        return processed_blocks
    
    def _create_page_texts(self, processed_blocks: List[ProcessedOCRBlock]) -> List[Dict[str, Any]]:
        """ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ Íµ¨ÏÑ± (Í∏∞Ï°¥ API Ìò∏ÌôòÏÑ±)"""
        page_groups = {}
        
        # ÌéòÏù¥ÏßÄÎ≥ÑÎ°ú Î∏îÎ°ù Í∑∏Î£πÌôî
        for block in processed_blocks:
            page_num = block.page_number
            if page_num not in page_groups:
                page_groups[page_num] = []
            page_groups[page_num].append(block.text)
        
        # ÌéòÏù¥ÏßÄÎ≥Ñ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
        page_texts = []
        for page_num in sorted(page_groups.keys()):
            page_text = "\n".join(page_groups[page_num])
            page_texts.append({
                "page_number": page_num,
                "text": page_text.strip(),
                "processing_time": 0  # Ï†ÑÏ≤¥ Ï≤òÎ¶¨Ïóê Ìè¨Ìï®Îê®
            })
        
        return page_texts
    
    def _create_error_response(
            self, 
            document_id: str, 
            error_message: str, 
            start_time: float
        ) -> Dict[str, Any]:
            """Ïò§Î•ò ÏùëÎãµ ÏÉùÏÑ±"""
            total_time = time.time() - start_time
            
            return {
                "success": False,
                "document_id": document_id,
                "error": error_message,
                "total_pages": 0,
                "full_text": "",
                "page_texts": [],
                "text_blocks": [],
                "engine_used": "SimplifiedOCRService v2.0 (Failed)",
                "processing_stats": {
                    "total_time": total_time,
                    "error": error_message
                },
                "llm_postprocessing_enabled": False,
                "vectordb_stored": False
            }
    
    def _get_memory_usage(self) -> int:
        """ÌòÑÏû¨ ÌîÑÎ°úÏÑ∏Ïä§Ïùò Î©îÎ™®Î¶¨ ÏÇ¨Ïö©Îüâ Î∞òÌôò (Î∞îÏù¥Ìä∏)"""
        try:
            process = psutil.Process(os.getpid())
            return process.memory_info().rss
        except:
            return 0
    
    def _update_processing_stats(self, result: Dict[str, Any], success: bool):
        """Ï≤òÎ¶¨ ÌÜµÍ≥Ñ ÏóÖÎç∞Ïù¥Ìä∏"""
        self.processing_stats['total_documents'] += 1
        
        if success:
            self.processing_stats['successful_documents'] += 1
            stats = result.get('processing_stats', {})
            self.processing_stats['total_processing_time'] += stats.get('total_time', 0)
            self.processing_stats['total_ocr_time'] += stats.get('ocr_time', 0)
            self.processing_stats['total_pages_processed'] += result.get('total_pages', 0)
            self.processing_stats['total_blocks_extracted'] += stats.get('text_blocks_count', 0)
            # VectorDB ÏãúÍ∞Ñ Ï∂îÍ∞Ä
            perf_metrics = result.get('performance_metrics', {})
            total_time = stats.get('total_time', 0)
            vectordb_ratio = perf_metrics.get('vectordb_to_total_time_ratio', 0)
            self.processing_stats['total_vectordb_time'] += total_time * vectordb_ratio
        else:
            self.processing_stats['failed_documents'] += 1
    
    def get_service_info(self) -> Dict[str, Any]:
        """ÏÑúÎπÑÏä§ Ï†ïÎ≥¥ Î∞òÌôò"""
        return {
            "service_name": "SimplifiedOCRService",
            "version": "2.0.0",
            "ocr_engine": self.ocr_engine.get_engine_info(),
            "llm_postprocessing_enabled": False,
            "vectordb_direct_storage": True,
            "processing_statistics": self.processing_stats.copy()
        }
    
    def get_processing_statistics(self) -> Dict[str, Any]:
        """Ï≤òÎ¶¨ ÌÜµÍ≥Ñ Î∞òÌôò"""
        stats = self.processing_stats.copy()
        
        # Ï∂îÍ∞Ä Í≥ÑÏÇ∞Îêú ÌÜµÍ≥Ñ
        if stats['successful_documents'] > 0:
            stats['average_processing_time'] = stats['total_processing_time'] / stats['successful_documents']
            stats['average_pages_per_document'] = stats['total_pages_processed'] / stats['successful_documents']
            stats['average_blocks_per_document'] = stats['total_blocks_extracted'] / stats['successful_documents']
            stats['average_vectordb_time'] = stats['total_vectordb_time'] / stats['successful_documents']
        
        if stats['total_documents'] > 0:
            stats['success_rate'] = stats['successful_documents'] / stats['total_documents']
        
        return stats

    async def cleanup(self):
        """Î¶¨ÏÜåÏä§ Ï†ïÎ¶¨"""
        try:
            if self.ocr_engine:
                await self.ocr_engine.cleanup()
            
            if self.vector_db:
                await self.vector_db.cleanup()
            
            logger.info("‚úÖ SimplifiedOCRService cleanup completed")
            
        except Exception as e:
            logger.error(f"‚ö†Ô∏è Error during SimplifiedOCRService cleanup: {e}")
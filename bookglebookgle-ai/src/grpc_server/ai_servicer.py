"""
AI Service gRPC Servicer Implementation
"""

from typing import Any, Dict
import uuid
import time
import asyncio

import grpc
from loguru import logger

# Import generated protobuf files
from .generated import ai_service_pb2, ai_service_pb2_grpc

from src.services.discussion_service import DiscussionService
from src.services.ocr_service import OcrService
from src.services.vector_db import VectorDBManager
from src.config.settings import get_settings


class AIServicer(ai_service_pb2_grpc.AIServiceServicer):
    """gRPC servicer for AI operations"""
    
    def __init__(self, vector_db_manager: VectorDBManager):
        self.settings = get_settings()
        self.discussion_service = DiscussionService()
        self.ocr_service = OcrService()
        
        # Use the initialized VectorDBManager passed from the outside
        self.vector_db_manager = vector_db_manager
        self.discussion_service.initialize_manager(self.vector_db_manager)
        
        logger.info("AI Servicer initialized with injected dependencies.")
    
    # í€´ì¦ˆ ìƒì„±ê³¼ êµì • ê¸°ëŠ¥ì€ ë‚˜ì¤‘ì— êµ¬í˜„ ì˜ˆì •ìœ¼ë¡œ ì œê±°
    
    async def InitializeDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± ë…ì„œ ëª¨ì„ í† ë¡  ì‹œì‘ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ¯ Starting mobile discussion for meeting: {request.meeting_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì‹œì‘
            result = await self.discussion_service.start_discussion(
                document_id=request.document_id,
                meeting_id=request.meeting_id,
                session_id=request.session_id, 
                participants=[{"user_id": p.user_id, "nickname": p.nickname} for p in request.participants]
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion started for session: {request.session_id}")
                response = ai_service_pb2.DiscussionInitResponse(
                    success=True, 
                    message=result.get("message", "Discussion started successfully")
                )
                
                # í† ë¡  ì£¼ì œê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if "discussion_topics" in result and result["discussion_topics"]:
                    response.discussion_topics.extend(result["discussion_topics"])
                if "recommended_topic" in result:
                    response.recommended_topic = result["recommended_topic"]
                    
                return response
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to start discussion"))
                return None

        except Exception as e:
            logger.error(f"Discussion initialization failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessChatMessage(self, request_iterator, context):
        """ëª¨ë°”ì¼ ì•± ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ - ê°„ì†Œí™”ëœ ìŠ¤íŠ¸ë¦¬ë°"""
        try:
            logger.debug("ğŸ“± Starting mobile chat stream processing")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                await context.abort(grpc.StatusCode.UNAVAILABLE, "Discussion AI is disabled")
                return

            # ê°„ì†Œí™”ëœ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
            async for request in request_iterator:
                try:
                    logger.debug(f"ğŸ’¬ Processing message from: {request.sender.nickname}")

                    message_data = {
                        "session_id": request.discussion_session_id,
                        "sender": {"nickname": request.sender.nickname, "user_id": request.sender.user_id},
                        "message": request.message,
                        "timestamp": request.timestamp
                    }

                    # ê°„ì†Œí™”ëœ ì±„íŒ… ì²˜ë¦¬
                    result = await self.discussion_service.process_chat_message(
                        session_id=request.discussion_session_id,
                        message_data=message_data
                    )

                    # ê°„ë‹¨í•œ ì‘ë‹µ ìƒì„±
                    response = ai_service_pb2.ChatMessageResponse(
                        success=result.get("success", True),
                        message=result.get("message", "Message processed"),
                        ai_response=result.get("ai_response", ""),
                        requires_moderation=result.get("requires_moderation", False)
                    )
                    yield response

                except Exception as e:
                    logger.error(f"Error processing message: {e}")
                    error_response = ai_service_pb2.ChatMessageResponse(
                        success=False,
                        message=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                    )
                    yield error_response

        except Exception as e:
            logger.error(f"Chat stream failed: {e}")
            await context.abort(grpc.StatusCode.INTERNAL, f"Chat error: {str(e)}")
    
    async def EndDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± í† ë¡  ì¢…ë£Œ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ Ending mobile discussion for session: {request.session_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì¢…ë£Œ
            result = await self.discussion_service.end_discussion(
                meeting_id=request.meeting_id,
                session_id=request.session_id
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion ended for session: {request.session_id}")
                return ai_service_pb2.DiscussionEndResponse(
                    success=True,
                    message=result.get("message", "Discussion ended successfully")
                )
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to end discussion"))
                return None

        except Exception as e:
            logger.error(f"Failed to end discussion: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
            
    # ì‚¬ìš©ì ë¶„ì„ ê¸°ëŠ¥ì€ ëª¨ë°”ì¼ ì•±ì—ì„œ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°

    async def ProcessStructuredDocument(self, request, context):
        """Process structured text document (PDF with text data) and store in vector DB"""
        try:
            logger.info(f"Structured document processing requested for: {request.document_id}")

            doc_id = request.document_id
            file_name = request.file_name
            metadata = dict(request.metadata)
            ocr_results = request.ocr_results
            
            if not doc_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID is required")
                return None

            if not ocr_results:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("OCR results are required")
                return None

            meeting_id = metadata.get("meeting_id")
            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required in metadata")
                return None

            logger.info(f"ğŸ“„ Processing structured document for meeting {meeting_id}, document: {doc_id}")

            # OCR ê²°ê³¼ë¥¼ í…ìŠ¤íŠ¸ë¡œ ê²°í•©
            full_text = ""
            for text_block in ocr_results:
                full_text += text_block.text + "\n"

            # ë²¡í„°DBì— ì €ì¥
            chunk_ids = await self.vector_db_manager.process_bookclub_document(
                meeting_id=meeting_id,
                document_id=doc_id,
                text=full_text,
                metadata={
                    "file_name": file_name,
                    "processing_type": "structured_text",
                    "source": "text_pdf",
                    **metadata
                }
            )
            
            logger.info(f"âœ… Structured document processed: {len(chunk_ids)} chunks created for meeting {meeting_id}")

            # ê°„ì†Œí™”ëœ ì‘ë‹µ
            chunks_data = []
            for i, chunk_id in enumerate(chunk_ids):
                chunks_data.append(ai_service_pb2.DocumentChunk(
                    chunk_id=chunk_id,
                    text=f"Chunk {i+1} from structured document",
                    start_position=0,
                    end_position=0
                ))

            return ai_service_pb2.DocumentResponse(
                success=True,
                message=f"Structured document processed successfully for meeting {meeting_id}. {len(chunk_ids)} chunks created.",
                chunks=chunks_data
            )

        except Exception as e:
            logger.error(f"Structured document processing failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None

    async def GenerateQuiz(self, request, context):
        """Generate quiz based on progress percentage (50% or 100%)"""
        try:
            logger.info(f"Quiz generation requested for document: {request.document_id}, meeting: {request.meeting_id}, progress: {request.progress_percentage}%")

            doc_id = request.document_id
            meeting_id = request.meeting_id
            progress = request.progress_percentage
            
            if not doc_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID is required")
                return None

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Meeting ID is required")
                return None

            if progress not in [50, 100]:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Progress percentage must be 50 or 100")
                return None

            # ë²¡í„°DBì—ì„œ ì§„ë„ìœ¨ì— ë§ëŠ” ì»¨í…ì¸  ê²€ìƒ‰
            # TODO: ì§„ë„ìœ¨ ê¸°ë°˜ ì»¨í…ì¸  ê²€ìƒ‰ ë¡œì§ êµ¬í˜„ í•„ìš”
            content_chunks = await self.vector_db_manager.search_by_progress(
                meeting_id=meeting_id,
                document_id=doc_id,
                progress_percentage=progress
            )

            if not content_chunks:
                return ai_service_pb2.QuizResponse(
                    success=False,
                    message="No content found for the specified progress percentage"
                )

            # TODO: LLMì„ ì‚¬ìš©í•œ í€´ì¦ˆ ìƒì„± ë¡œì§ êµ¬í˜„
            # ì„ì‹œ ì‘ë‹µ
            questions = [
                ai_service_pb2.Question(
                    question_text="ì„ì‹œ í€´ì¦ˆ ì§ˆë¬¸ì…ë‹ˆë‹¤.",
                    options=["ì„ íƒì§€ 1", "ì„ íƒì§€ 2", "ì„ íƒì§€ 3", "ì„ íƒì§€ 4"],
                    correct_answer_index=0
                )
            ]

            quiz_id = f"quiz_{uuid.uuid4().hex[:8]}"
            
            return ai_service_pb2.QuizResponse(
                success=True,
                message="Quiz generated successfully",
                questions=questions,
                quiz_id=quiz_id
            )

        except Exception as e:
            logger.error(f"Quiz generation failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None

    async def ProofreadText(self, request, context):
        """Proofread and correct text for grammar and context"""
        try:
            logger.info(f"Text proofreading requested from user: {request.user.nickname}")

            original_text = request.original_text.text
            context_text = request.context_text.text if request.context_text else ""
            
            if not original_text:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Original text is required")
                return None

            # TODO: LLMì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ êµì • ë¡œì§ êµ¬í˜„
            # ì„ì‹œ ì‘ë‹µ
            corrected_text = original_text  # ì„ì‹œë¡œ ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            corrections = [
                ai_service_pb2.TextCorrection(
                    original="ì„ì‹œ",
                    corrected="ì„ì‹œ",
                    correction_type="grammar",
                    explanation="ì„ì‹œ êµì • ì„¤ëª…",
                    start_position=0,
                    end_position=2
                )
            ]

            return ai_service_pb2.ProofreadResponse(
                success=True,
                message="Text proofreading completed",
                corrected_text=corrected_text,
                corrections=corrections,
                confidence_score=0.95
            )

        except Exception as e:
            logger.error(f"Text proofreading failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessPdf(self, request_iterator, context):
        """Process PDF stream, perform OCR, and store results in VectorDB automatically"""
        document_id = None
        file_name = None
        metadata = {}
        pdf_data_chunks = []

        try:
            async for request in request_iterator:
                if request.HasField("info"):
                    # First message should contain PdfInfo
                    document_id = request.info.document_id or str(uuid.uuid4())
                    file_name = request.info.file_name
                    metadata = dict(request.info.metadata)
                    logger.info(f"Received PDF info for document: {document_id}, file: {file_name}")
                elif request.HasField("chunk"):
                    # Subsequent messages contain PDF data chunks
                    pdf_data_chunks.append(request.chunk)
                else:
                    logger.warning("Received unknown message type in ProcessPdf stream.")

            if not document_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID not provided in PdfInfo.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="Document ID missing.")

            if not pdf_data_chunks:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("No PDF data chunks received.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="No PDF data.")

            full_pdf_data = b"".join(pdf_data_chunks)
            meeting_id = metadata.get("meeting_id")
            
            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required in metadata.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="meeting_id missing.")

            logger.info(f"ğŸ“„ Processing PDF for meeting {meeting_id}, document: {document_id}")

            # OCR ì²˜ë¦¬
            ocr_result = await self.ocr_service.process_pdf_stream(full_pdf_data, document_id)

            if not ocr_result["success"]:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"OCR processing failed: {ocr_result.get('error', 'Unknown error')}")
                return ai_service_pb2.ProcessPdfResponse(success=False, message=ocr_result.get('error', 'OCR failed'))

            # OCR ê²°ê³¼ ì¶”ì¶œ
            full_text = ocr_result.get("full_text", "")
            page_texts = ocr_result.get("page_texts", [])
            total_pages = ocr_result.get("total_pages", 0)
            
            # ë²¡í„°DBì— ìë™ ì €ì¥ (meeting_idë³„ë¡œ ê²©ë¦¬)
            try:
                chunk_ids = await self.vector_db_manager.process_bookclub_document(
                    meeting_id=meeting_id,
                    document_id=document_id,
                    text=full_text,
                    metadata={
                        "file_name": file_name,
                        "total_pages": total_pages,
                        "processing_type": "ocr",
                        **metadata
                    }
                )
                logger.info(f"âœ… PDF processed and stored: {len(chunk_ids)} chunks created for meeting {meeting_id}")
            except Exception as e:
                logger.error(f"Failed to store PDF in vector DB: {e}")
                # OCRì€ ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ê²°ê³¼ëŠ” ë°˜í™˜, í•˜ì§€ë§Œ ì €ì¥ ì‹¤íŒ¨ í‘œì‹œ
                pass

            # ê°„ì†Œí™”ëœ ì‘ë‹µ - í˜ì´ì§€ë³„ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜
            response_text_blocks = []
            for page_data in page_texts:
                response_text_blocks.append(ai_service_pb2.TextBlock(
                    text=page_data.get("text", ""),
                    page_number=page_data.get("page_number", 0),
                    x0=0.0, y0=0.0, x1=0.0, y1=0.0,  # ìœ„ì¹˜ ì •ë³´ëŠ” ë‹¨ìˆœí™”
                    block_type="page_text"
                ))

            return ai_service_pb2.ProcessPdfResponse(
                success=True,
                message="PDF OCR processing and vector DB storage completed successfully",
                document_id=document_id,
                total_pages=total_pages,
                text_blocks=response_text_blocks
            )

        except Exception as e:
            logger.error(f"Error in ProcessPdf RPC for document {document_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal server error: {str(e)}")
            return ai_service_pb2.ProcessPdfResponse(success=False, message=f"Internal error: {str(e)}")

    # ë¶ˆí•„ìš”í•œ response builder ë©”ì„œë“œë“¤ ì œê±° (í€´ì¦ˆ, êµì •, ì‚¬ìš©ì ë¶„ì„ ê´€ë ¨)
"""
AI Service gRPC Servicer Implementation
"""

from typing import Any, Dict
import uuid
import time
import asyncio

import grpc
from loguru import logger

# Import generated protobuf files
from .generated import ai_service_pb2, ai_service_pb2_grpc

from src.services.discussion_service import DiscussionService
from src.services.simplified_ocr_service import SimplifiedOCRService
from src.services.vector_db import VectorDBManager
from src.services.meeting_service import MeetingService
from src.config.settings import get_settings


class AIServicer(ai_service_pb2_grpc.AIServiceServicer):
    """gRPC servicer for AI operations"""
    
    def __init__(self, vector_db_manager: VectorDBManager, redis_manager=None, llm_client=None, 
                 quiz_service=None, proofreading_service=None):
        self.settings = get_settings()
        self.discussion_service = DiscussionService()
        self.meeting_service = MeetingService()  # ìƒˆë¡œ ì¶”ê°€
        
        # Initialize SimplifiedOCRService with LLM post-processing enabled
        self.ocr_service = SimplifiedOCRService(enable_llm_postprocessing=True)
        
        # Use the initialized services passed from the outside
        self.vector_db_manager = vector_db_manager
        self.redis_manager = redis_manager
        self.llm_client = llm_client
        self.quiz_service = quiz_service
        self.proofreading_service = proofreading_service
        
        logger.info("AI Servicer initialized with all injected dependencies.")
    
    async def initialize_services(self):
        """Initialize all services asynchronously"""
        try:
            # Initialize discussion service with vector DB
            await self.discussion_service.initialize_manager(self.vector_db_manager)
            
            # Initialize meeting service with vector DB and discussion service
            await self.meeting_service.initialize(self.vector_db_manager, self.discussion_service)
            
            # Initialize OCR service
            ocr_success = await self.initialize_ocr_service()
            
            # Log service availability status
            self._log_service_status()
            
            logger.info("âœ… All AI services initialized successfully")
            return ocr_success
        except Exception as e:
            logger.error(f"âŒ Service initialization error: {e}")
            return False
    
    def _log_service_status(self):
        """Log the status of all injected services"""
        services_status = {
            "Vector DB Manager": self.vector_db_manager is not None,
            "Redis Manager": self.redis_manager is not None,
            "LLM Client": self.llm_client is not None,
            "Quiz Service": self.quiz_service is not None,
            "Proofreading Service": self.proofreading_service is not None,
            "Discussion Service": True,  # Always available
            "OCR Service": True  # Always available
        }
        
        logger.info("ğŸ“Š AI Servicer Service Status:")
        for service_name, is_available in services_status.items():
            status_icon = "âœ…" if is_available else "âŒ"
            logger.info(f"  {status_icon} {service_name}")
        
        # Log feature availability
        ai_features_available = self.quiz_service is not None and self.proofreading_service is not None
        feature_status = "âœ… Enabled" if ai_features_available else "âš ï¸ Using Mock Data"
        logger.info(f"ğŸ§  AI Features (Quiz/Proofreading): {feature_status}")
    
    async def initialize_ocr_service(self):
        """Initialize the OCR service asynchronously"""
        try:
            success = await self.ocr_service.initialize()
            if success:
                logger.info("âœ… SimplifiedOCRService initialized successfully")
            else:
                logger.error("âŒ SimplifiedOCRService initialization failed")
            return success
        except Exception as e:
            logger.error(f"âŒ SimplifiedOCRService initialization error: {e}")
            return False
    
    # í€´ì¦ˆ ìƒì„±ê³¼ êµì • ê¸°ëŠ¥ì€ ë‚˜ì¤‘ì— êµ¬í˜„ ì˜ˆì •ìœ¼ë¡œ ì œê±°
    
    async def InitializeDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± ë…ì„œ ëª¨ì„ í† ë¡  ì‹œì‘ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ¯ Starting mobile discussion for meeting: {request.meeting_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì‹œì‘
            result = await self.discussion_service.start_discussion(
                document_id=request.document_id,
                meeting_id=request.meeting_id,
                session_id=request.session_id, 
                participants=[{"user_id": p.user_id, "nickname": p.nickname} for p in request.participants]
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion started for session: {request.session_id}")
                response = ai_service_pb2.DiscussionInitResponse(
                    success=True, 
                    message=result.get("message", "Discussion started successfully")
                )
                
                # í† ë¡  ì£¼ì œê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if "discussion_topics" in result and result["discussion_topics"]:
                    response.discussion_topics.extend(result["discussion_topics"])
                if "recommended_topic" in result:
                    response.recommended_topic = result["recommended_topic"]
                    
                return response
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to start discussion"))
                return None

        except Exception as e:
            logger.error(f"Discussion initialization failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessChatMessage(self, request_iterator, context):
        """ëª¨ë°”ì¼ ì•± ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ - ì±„íŒ… ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ ì§€ì›"""
        try:
            logger.debug("ğŸ“± Starting mobile chat stream processing with chat history support")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                await context.abort(grpc.StatusCode.UNAVAILABLE, "Discussion AI is disabled")
                return

            # ì±„íŒ… ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì§€ì›í•˜ëŠ” ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
            async for request in request_iterator:
                try:
                    logger.debug(f"ğŸ’¬ Processing message from: {request.sender.nickname}")

                    # ì±„íŒ… ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ ì˜µì…˜ ì²˜ë¦¬
                    use_chat_context = getattr(request, 'use_chat_context', True)
                    context_window_size = getattr(request, 'context_window_size', 5)
                    store_in_history = getattr(request, 'store_in_history', True)

                    message_data = {
                        "session_id": request.discussion_session_id,
                        "sender": {
                            "nickname": request.sender.nickname, 
                            "user_id": request.sender.user_id
                        },
                        "message": request.message,
                        "timestamp": request.timestamp,
                        "use_chat_context": use_chat_context,
                        "context_window_size": context_window_size,
                        "store_in_history": store_in_history
                    }

                    # ì±„íŒ… ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ë¥¼ í™œìš©í•œ ì±„íŒ… ì²˜ë¦¬
                    result = await self.discussion_service.process_chat_message(
                        session_id=request.discussion_session_id,
                        message_data=message_data
                    )

                    # ì±„íŒ… ê¸°ë¡ ì •ë³´ë¥¼ í¬í•¨í•œ ì‘ë‹µ ìƒì„±
                    response = ai_service_pb2.ChatMessageResponse(
                        success=result.get("success", True),
                        message=result.get("message", "Message processed"),
                        ai_response=result.get("ai_response", ""),
                        requires_moderation=result.get("requires_moderation", False),
                        context_messages_used=result.get("chat_context_used", 0),
                        chat_history_enabled=True
                    )
                    
                    # ìµœê·¼ ì»¨í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì¶”ê°€ (ì„ íƒì )
                    if use_chat_context and result.get("recent_context"):
                        for ctx_msg in result.get("recent_context", []):
                            history_msg = ai_service_pb2.ChatHistoryMessage(
                                message_id=ctx_msg.get("message_id", ""),
                                session_id=ctx_msg.get("session_id", ""),
                                content=ctx_msg.get("content", ""),
                                timestamp=ctx_msg.get("timestamp", 0),
                                message_type=ctx_msg.get("message_type", "USER")
                            )
                            # sender ì •ë³´ ì„¤ì •
                            if "sender" in ctx_msg:
                                history_msg.sender.user_id = ctx_msg["sender"].get("user_id", "")
                                history_msg.sender.nickname = ctx_msg["sender"].get("nickname", "")
                            
                            response.recent_context.append(history_msg)
                    
                    yield response

                except Exception as e:
                    logger.error(f"Error processing message: {e}")
                    error_response = ai_service_pb2.ChatMessageResponse(
                        success=False,
                        message=f"ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                        chat_history_enabled=True
                    )
                    yield error_response

        except Exception as e:
            logger.error(f"Chat stream failed: {e}")
            await context.abort(grpc.StatusCode.INTERNAL, f"Chat error: {str(e)}")
    
    async def EndDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± í† ë¡  ì¢…ë£Œ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ Ending mobile discussion for session: {request.session_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì¢…ë£Œ
            result = await self.discussion_service.end_discussion(
                meeting_id=request.meeting_id,
                session_id=request.session_id
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion ended for session: {request.session_id}")
                return ai_service_pb2.DiscussionEndResponse(
                    success=True,
                    message=result.get("message", "Discussion ended successfully")
                )
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to end discussion"))
                return None

        except Exception as e:
            logger.error(f"Failed to end discussion: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def EndMeeting(self, request, context):
        """í†µí•© ëª¨ì„ ì¢…ë£Œ API - ëª¨ë“  ëª¨ì„ íƒ€ì… ì§€ì›"""
        try:
            logger.info(f"ğŸ Ending {request.meeting_type} meeting: {request.meeting_id}")
            
            # MeetingService ì´ˆê¸°í™” í™•ì¸
            if not self.meeting_service.is_initialized():
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("MeetingService is not initialized")
                return None
            
            # ëª¨ì„ íƒ€ì…ë³„ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            kwargs = {}
            if request.meeting_type == "discussion" and request.HasField("session_id"):
                kwargs["session_id"] = request.session_id
            
            # í†µí•© ëª¨ì„ ì¢…ë£Œ ì²˜ë¦¬
            result = await self.meeting_service.end_meeting(
                meeting_id=request.meeting_id,
                meeting_type=request.meeting_type,
                **kwargs
            )
            
            if result["success"]:
                logger.info(f"âœ… {request.meeting_type.title()} meeting ended: {request.meeting_id}")
                return ai_service_pb2.MeetingEndResponse(
                    success=True,
                    message=result.get("message", f"{request.meeting_type.title()} meeting ended successfully"),
                    meeting_type=request.meeting_type
                )
            else:
                logger.error(f"âŒ Failed to end {request.meeting_type} meeting {request.meeting_id}: {result.get('message')}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("message", "Failed to end meeting"))
                return None
                
        except Exception as e:
            logger.error(f"Failed to end {request.meeting_type} meeting {request.meeting_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def GetChatHistory(self, request, context):
        """ì±„íŒ… ê¸°ë¡ ì¡°íšŒ"""
        try:
            logger.debug(f"ğŸ“œ Chat history requested for session: {request.session_id}")

            session_id = request.session_id
            limit = getattr(request, 'limit', 10)
            since_timestamp = getattr(request, 'since_timestamp', None)
            user_id = getattr(request, 'user_id', None)

            if not session_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Session ID is required")
                return None

            try:
                # ì±„íŒ… ê¸°ë¡ ë§¤ë‹ˆì €ì—ì„œ ë©”ì‹œì§€ ì¡°íšŒ
                if user_id:
                    # íŠ¹ì • ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë§Œ ì¡°íšŒ
                    messages = await self.discussion_service.chat_history_manager.get_user_messages(
                        session_id, user_id, limit
                    )
                else:
                    # ìµœê·¼ ë©”ì‹œì§€ ì¡°íšŒ
                    messages = await self.discussion_service.chat_history_manager.get_recent_messages(
                        session_id, limit
                    )

                # since_timestamp í•„í„°ë§
                if since_timestamp:
                    messages = [
                        msg for msg in messages 
                        if msg.timestamp.timestamp() > since_timestamp
                    ]

                # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
                response_messages = []
                for msg in messages:
                    history_msg = ai_service_pb2.ChatHistoryMessage(
                        message_id=msg.message_id,
                        session_id=msg.session_id,
                        content=msg.content,
                        timestamp=int(msg.timestamp.timestamp()),
                        message_type=msg.message_type.value
                    )
                    
                    # sender ì •ë³´ ì„¤ì •
                    history_msg.sender.user_id = msg.user_id
                    history_msg.sender.nickname = msg.nickname
                    
                    # metadata ì„¤ì •
                    if msg.metadata:
                        for key, value in msg.metadata.items():
                            history_msg.metadata[key] = str(value)
                    
                    response_messages.append(history_msg)

                return ai_service_pb2.GetChatHistoryResponse(
                    success=True,
                    message="Chat history retrieved successfully",
                    messages=response_messages,
                    total_count=len(response_messages),
                    has_more=len(response_messages) >= limit
                )

            except Exception as e:
                logger.error(f"Failed to get chat history: {e}")
                return ai_service_pb2.GetChatHistoryResponse(
                    success=False,
                    message=f"Failed to retrieve chat history: {str(e)}",
                    messages=[],
                    total_count=0,
                    has_more=False
                )

        except Exception as e:
            logger.error(f"GetChatHistory failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def GetChatSessionStats(self, request, context):
        """ì±„íŒ… ì„¸ì…˜ í†µê³„ ì¡°íšŒ"""
        try:
            logger.debug(f"ğŸ“Š Chat session stats requested for: {request.session_id}")

            session_id = request.session_id
            if not session_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Session ID is required")
                return None

            try:
                # ì„¸ì…˜ í†µê³„ ì¡°íšŒ
                stats = await self.discussion_service.get_chat_history_stats(session_id)
                
                if "error" in stats:
                    return ai_service_pb2.ChatSessionStatsResponse(
                        success=False,
                        message=f"Failed to get session stats: {stats['error']}",
                        session_id=session_id,
                        chat_history_enabled=False
                    )

                # ì°¸ì—¬ì í†µê³„ ìƒì„±
                participant_stats = []
                if "participant_engagement" in stats:
                    for user_id, engagement in stats["participant_engagement"].items():
                        participant_stat = ai_service_pb2.ParticipantStats(
                            message_count=stats.get("participant_message_counts", {}).get(user_id, 0),
                            last_activity=int(stats.get("last_activity_times", {}).get(user_id, 0)),
                            engagement_level=engagement
                        )
                        participant_stat.participant.user_id = user_id
                        participant_stat.participant.nickname = stats.get("participant_nicknames", {}).get(user_id, user_id)
                        participant_stats.append(participant_stat)

                return ai_service_pb2.ChatSessionStatsResponse(
                    success=True,
                    message="Session stats retrieved successfully",
                    session_id=session_id,
                    total_messages=stats.get("message_count", 0),
                    total_participants=stats.get("participant_count", 0),
                    participant_stats=participant_stats,
                    session_start_time=int(stats.get("created_at", 0)),
                    last_activity_time=int(stats.get("last_activity", 0)),
                    chat_history_enabled=stats.get("chat_history_enabled", False)
                )

            except Exception as e:
                logger.error(f"Failed to get session stats: {e}")
                return ai_service_pb2.ChatSessionStatsResponse(
                    success=False,
                    message=f"Failed to retrieve session stats: {str(e)}",
                    session_id=session_id,
                    chat_history_enabled=False
                )

        except Exception as e:
            logger.error(f"GetChatSessionStats failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
            
    # ì‚¬ìš©ì ë¶„ì„ ê¸°ëŠ¥ì€ ëª¨ë°”ì¼ ì•±ì—ì„œ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°

    async def GenerateQuiz(self, request, context):
        """Generate quiz based on progress percentage (50% or 100%)"""
        try:
            logger.info(f"Quiz generation requested for document: {request.document_id}, meeting: {request.meeting_id}, progress: {request.progress_percentage}%")

            doc_id = request.document_id
            meeting_id = request.meeting_id
            progress = request.progress_percentage
            
            if not doc_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID is required")
                return None

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Meeting ID is required")
                return None

            if progress not in [50, 100]:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Progress percentage must be 50 or 100")
                return None

            # ë²¡í„°DBì—ì„œ ì§„ë„ìœ¨ì— ë§ëŠ” ì»¨í…ì¸  ê²€ìƒ‰
            content_chunks = await self.vector_db_manager.search_by_progress(
                meeting_id=meeting_id,
                document_id=doc_id,
                progress_percentage=progress
            )

            if not content_chunks:
                return ai_service_pb2.QuizResponse(
                    success=False,
                    message="No content found for the specified progress percentage"
                )

            # QuizServiceë¥¼ í†µí•œ í€´ì¦ˆ ìƒì„±
            quiz_data = {
                "document_id": doc_id,
                "content": " ".join(content_chunks),
                "progress_percentage": progress,
                "question_count": 5,
                "difficulty_level": "medium",
                "language": "ko"
            }
            
            # QuizService ì´ˆê¸°í™” í™•ì¸
            if not self.quiz_service:
                logger.warning("QuizService not initialized, using mock data")
                # Fallback to basic mock quiz
                questions = [
                    ai_service_pb2.Question(
                        question_text="ë¬¸ì„œì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        options=["ê°œë… A", "ê°œë… B", "ê°œë… C", "ê°œë… D"],
                        correct_answer_index=0
                    )
                ]
                quiz_id = f"quiz_{uuid.uuid4().hex[:8]}"
            else:
                # ì‹¤ì œ QuizServiceë¥¼ í†µí•œ í€´ì¦ˆ ìƒì„±
                result = await self.quiz_service.generate_quiz(quiz_data)
                
                if result["success"]:
                    questions = []
                    for q in result["questions"]:
                        questions.append(ai_service_pb2.Question(
                            question_text=q["question_text"],
                            options=q["options"],
                            correct_answer_index=q["correct_answer_index"]
                        ))
                    quiz_id = result["quiz_id"]
                else:
                    return ai_service_pb2.QuizResponse(
                        success=False,
                        message=result.get("error", "Quiz generation failed")
                    )
            
            return ai_service_pb2.QuizResponse(
                success=True,
                message="Quiz generated successfully",
                questions=questions,
                quiz_id=quiz_id
            )

        except Exception as e:
            logger.error(f"Quiz generation failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None

    async def ProofreadText(self, request, context):
        """Proofread and correct text for grammar and context"""
        try:
            logger.info(f"Text proofreading requested from user: {request.user.nickname}")

            original_text = request.original_text.text
            context_text = request.context_text.text if request.context_text else ""
            
            if not original_text:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Original text is required")
                return None

            # ProofreadingServiceë¥¼ í†µí•œ ì‹¤ì œ ì²¨ì‚­ ì²˜ë¦¬
            proofread_data = {
                "original_text": original_text,
                "context_text": context_text,
                "language": request.original_text.language or "ko",
                "user_id": request.user.user_id
            }
            
            # ProofreadingService ì´ˆê¸°í™” í™•ì¸
            if not self.proofreading_service:
                logger.warning("ProofreadingService not initialized, using fallback")
                # Fallback response
                return ai_service_pb2.ProofreadResponse(
                    success=True,
                    message="Proofreading service not available (using fallback)",
                    corrected_text=original_text,
                    corrections=[],
                    confidence_score=0.5
                )
            
            # ì‹¤ì œ ProofreadingServiceë¥¼ í†µí•œ ì²¨ì‚­ ì²˜ë¦¬
            result = await self.proofreading_service.proofread_text(proofread_data)
            
            if result["success"]:
                corrections = []
                for correction in result.get("corrections", []):
                    corrections.append(ai_service_pb2.TextCorrection(
                        original=correction.get("original", ""),
                        corrected=correction.get("corrected", ""),
                        correction_type=correction.get("type", "grammar"),
                        explanation=correction.get("explanation", ""),
                        start_position=correction.get("start_position", 0),
                        end_position=correction.get("end_position", 0)
                    ))
                
                return ai_service_pb2.ProofreadResponse(
                    success=True,
                    message="Text proofreading completed",
                    corrected_text=result.get("corrected_text", original_text),
                    corrections=corrections,
                    confidence_score=result.get("confidence_score", 0.85)
                )
            else:
                return ai_service_pb2.ProofreadResponse(
                    success=False,
                    message=result.get("error", "Proofreading failed")
                )

        except Exception as e:
            logger.error(f"Text proofreading failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessPdf(self, request_iterator, context):
        """Process PDF stream, perform OCR, and store results in VectorDB automatically"""
        document_id = None
        file_name = None
        metadata = {}
        meeting_id = None
        pdf_data_chunks = []

        try:
            async for request in request_iterator:
                if request.HasField("info"):
                    # First message should contain PdfInfo
                    document_id = request.info.document_id or str(uuid.uuid4())
                    file_name = request.info.file_name
                    meeting_id = request.info.meeting_id  # ì§ì ‘ í•„ë“œì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    metadata = dict(request.info.metadata)
                    logger.info(f"Received PDF info for document: {document_id}, file: {file_name}, meeting: {meeting_id}")
                elif request.HasField("chunk"):
                    # Subsequent messages contain PDF data chunks
                    pdf_data_chunks.append(request.chunk)
                else:
                    logger.warning("Received unknown message type in ProcessPdf stream.")

            if not document_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID not provided in PdfInfo.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="Document ID missing.")

            if not pdf_data_chunks:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("No PDF data chunks received.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="No PDF data.")

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="meeting_id missing.")

            full_pdf_data = b"".join(pdf_data_chunks)

            logger.info(f"ğŸ“„ Processing PDF with response for meeting {meeting_id}, document: {document_id}")

            # OCR ì²˜ë¦¬
            ocr_result = await self.ocr_service.process_pdf_stream(full_pdf_data, document_id)

            if not ocr_result["success"]:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"OCR processing failed: {ocr_result.get('error', 'Unknown error')}")
                return ai_service_pb2.ProcessPdfResponse(success=False, message=ocr_result.get('error', 'OCR failed'))

            # OCR ê²°ê³¼ ì¶”ì¶œ
            full_text = ocr_result.get("full_text", "")
            page_texts = ocr_result.get("page_texts", [])
            total_pages = ocr_result.get("total_pages", 0)
            
            # ë²¡í„°DBì— ìë™ ì €ì¥ (meeting_idë³„ë¡œ ê²©ë¦¬)
            try:
                chunk_ids = await self.vector_db_manager.process_bookclub_document(
                    meeting_id=meeting_id,
                    document_id=document_id,
                    text=full_text,
                    metadata={
                        "file_name": file_name,
                        "total_pages": total_pages,
                        "processing_type": "ocr",
                        **metadata
                    }
                )
                logger.info(f"âœ… PDF processed and stored in VectorDB: {len(chunk_ids)} chunks created for meeting {meeting_id}")
            except Exception as e:
                logger.error(f"Failed to store PDF in vector DB: {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"Failed to store in vector DB: {str(e)}")
                return ai_service_pb2.ProcessPdfResponse(
                    success=False, 
                    message=f"VectorDB storage failed: {str(e)}",
                    document_id=document_id
                )

            # ì‹¤ì œ OCR ë¸”ë¡ë³„ ì‘ë‹µ - ìœ„ì¹˜ ì •ë³´ í¬í•¨
            response_text_blocks = []
            
            # OCR ê²°ê³¼ì—ì„œ ì‹¤ì œ ë¸”ë¡ ì •ë³´ ì‚¬ìš© (íƒ€ì… ì•ˆì „ì„± ê²€ì‚¬ í¬í•¨)
            text_blocks_data = ocr_result.get("text_blocks", [])
            if not isinstance(text_blocks_data, list):
                logger.warning(f"text_blocks is not a list: {type(text_blocks_data)}")
                text_blocks_data = []
                
            for text_block in text_blocks_data:
                if not isinstance(text_block, dict):
                    logger.warning(f"text_block is not a dict: {type(text_block)}")
                    continue
                    
                try:
                    response_text_blocks.append(ai_service_pb2.TextBlock(
                        text=str(text_block.get("text", "")),
                        page_number=int(text_block.get("page_number", 0)),
                        x0=float(text_block.get("x0", 0.0)),
                        y0=float(text_block.get("y0", 0.0)), 
                        x1=float(text_block.get("x1", 0.0)),
                        y1=float(text_block.get("y1", 0.0)),
                        block_type=str(text_block.get("block_type", "text")),
                        confidence=float(text_block.get("confidence", 0.0))
                    ))
                except (ValueError, TypeError) as e:
                    logger.warning(f"Failed to convert text_block data: {e}, block: {text_block}")
                    continue

            return ai_service_pb2.ProcessPdfResponse(
                success=True,
                message="PDF OCR processing and vector DB storage completed successfully",
                document_id=document_id,
                total_pages=total_pages,
                text_blocks=response_text_blocks
            )

        except Exception as e:
            logger.error(f"Error in ProcessPdf RPC for document {document_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal server error: {str(e)}")
            return ai_service_pb2.ProcessPdfResponse(success=False, message=f"Internal error: {str(e)}")

    async def ProcessPdfStream(self, request_iterator, context):
        """Process PDF stream with fire-and-forget approach (no response data)"""
        document_id = None
        file_name = None
        metadata = {}
        meeting_id = None
        pdf_data_chunks = []

        try:
            async for request in request_iterator:
                if request.HasField("info"):
                    # First message should contain PdfInfo
                    document_id = request.info.document_id or str(uuid.uuid4())
                    file_name = request.info.file_name
                    meeting_id = request.info.meeting_id
                    metadata = dict(request.info.metadata)
                    logger.info(f"Received PDF info for fire-and-forget processing: {document_id}, file: {file_name}, meeting: {meeting_id}")
                elif request.HasField("chunk"):
                    # Subsequent messages contain PDF data chunks
                    pdf_data_chunks.append(request.chunk)
                else:
                    logger.warning("Received unknown message type in ProcessPdfStream stream.")

            if not document_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID not provided in PdfInfo.")
                return

            if not pdf_data_chunks:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("No PDF data chunks received.")
                return

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required.")
                return

            full_pdf_data = b"".join(pdf_data_chunks)

            logger.info(f"ğŸ“„ Processing PDF fire-and-forget for meeting {meeting_id}, document: {document_id}")

            # OCR ì²˜ë¦¬
            ocr_result = await self.ocr_service.process_pdf_stream(full_pdf_data, document_id)

            if not ocr_result["success"]:
                logger.error(f"OCR processing failed for {document_id}: {ocr_result.get('error', 'Unknown error')}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"OCR processing failed: {ocr_result.get('error', 'Unknown error')}")
                return

            # OCR ê²°ê³¼ ì¶”ì¶œ (ì‘ë‹µìš© ë°ì´í„°ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ)
            full_text = ocr_result.get("full_text", "")
            total_pages = ocr_result.get("total_pages", 0)
            
            # ë²¡í„°DBì— ìë™ ì €ì¥ (meeting_idë³„ë¡œ ê²©ë¦¬)
            try:
                chunk_ids = await self.vector_db_manager.process_bookclub_document(
                    meeting_id=meeting_id,
                    document_id=document_id,
                    text=full_text,
                    metadata={
                        "file_name": file_name,
                        "total_pages": total_pages,
                        "processing_type": "ocr_stream",
                        **metadata
                    }
                )
                logger.info(f"âœ… PDF processed and stored in VectorDB (fire-and-forget): {len(chunk_ids)} chunks created for meeting {meeting_id}")
            except Exception as e:
                logger.error(f"Failed to store PDF in vector DB (fire-and-forget): {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"Failed to store in vector DB: {str(e)}")
                return

            # Fire-and-forget: ì‘ë‹µ ë°ì´í„° ìƒì„±í•˜ì§€ ì•Šê³  Empty ë°˜í™˜
            from google.protobuf.empty_pb2 import Empty
            return Empty()

        except Exception as e:
            logger.error(f"Error in ProcessPdfStream RPC for document {document_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal server error: {str(e)}")
            return

    async def cleanup(self):
        """Clean up resources when shutting down"""
        try:
            if hasattr(self, 'discussion_service'):
                await self.discussion_service.cleanup()
                logger.info("DiscussionService cleaned up")
        except Exception as e:
            logger.error(f"Error during AIServicer cleanup: {e}")
    
    # ë¶ˆí•„ìš”í•œ response builder ë©”ì„œë“œë“¤ ì œê±° (í€´ì¦ˆ, êµì •, ì‚¬ìš©ì ë¶„ì„ ê´€ë ¨)
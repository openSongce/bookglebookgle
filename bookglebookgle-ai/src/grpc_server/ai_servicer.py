"""
AI Service gRPC Servicer Implementation
"""

from typing import Any, Dict
import uuid
import time
import asyncio

import grpc
from loguru import logger

# Import generated protobuf files
from .generated import ai_service_pb2, ai_service_pb2_grpc

from src.services.discussion_service import DiscussionService
from src.services.tailscale_ocr_client import TailscaleOCRClient
from src.services.vector_db import VectorDBManager
from src.services.meeting_service import MeetingService
from src.config.settings import get_settings


class AIServicer(ai_service_pb2_grpc.AIServiceServicer):
    """gRPC servicer for AI operations"""
    
    def __init__(self, vector_db_manager: VectorDBManager, redis_manager=None, llm_client=None, 
                 quiz_service=None, proofreading_service=None):
        self.settings = get_settings()
        self.discussion_service = DiscussionService()
        self.meeting_service = MeetingService()  # ìƒˆë¡œ ì¶”ê°€
        
        # Initialize TailscaleOCRClient for remote OCR processing
        self.ocr_service = TailscaleOCRClient()
        
        # Use the initialized services passed from the outside
        self.vector_db_manager = vector_db_manager
        self.redis_manager = redis_manager
        self.llm_client = llm_client
        self.quiz_service = quiz_service
        self.proofreading_service = proofreading_service
        
        logger.info("AI Servicer initialized with all injected dependencies.")
    
    async def initialize_services(self):
        """Initialize all services asynchronously"""
        try:
            # Initialize discussion service with vector DB
            await self.discussion_service.initialize_manager(self.vector_db_manager)
            
            # Initialize meeting service with vector DB, discussion service, and other services
            await self.meeting_service.initialize(
                self.vector_db_manager, 
                self.discussion_service,
                quiz_service=self.quiz_service,
                proofreading_service=self.proofreading_service
            )
            
            # Initialize Tailscale OCR service (critical for EC2)
            ocr_success = await self.initialize_ocr_service()
            if not ocr_success:
                logger.error("âŒ Tailscale OCR service initialization failed - EC2 cannot start without local OCR")
                raise Exception("EC2 requires Tailscale OCR service - server cannot start without it")
            
            # Log service availability status
            self._log_service_status()
            
            logger.info("âœ… All AI services initialized successfully")
            return ocr_success
        except Exception as e:
            logger.error(f"âŒ Service initialization error: {e}")
            return False
    
    def _log_service_status(self):
        """Log the status of all injected services"""
        services_status = {
            "Vector DB Manager": self.vector_db_manager is not None,
            "Redis Manager": self.redis_manager is not None,
            "LLM Client": self.llm_client is not None,
            "Quiz Service": self.quiz_service is not None,
            "Proofreading Service": self.proofreading_service is not None,
            "Discussion Service": True,  # Always available
            "Tailscale OCR Service": getattr(self.ocr_service, 'initialized', False)
        }
        
        logger.info("ğŸ“Š AI Servicer Service Status:")
        for service_name, is_available in services_status.items():
            status_icon = "âœ…" if is_available else "âŒ"
            logger.info(f"  {status_icon} {service_name}")
        
        # Log feature availability
        ai_features_available = self.quiz_service is not None and self.proofreading_service is not None
        feature_status = "âœ… Enabled" if ai_features_available else "âš ï¸ Using Mock Data"
        logger.info(f"ğŸ§  AI Features (Quiz/Proofreading): {feature_status}")
    
    async def initialize_ocr_service(self):
        """Initialize the Tailscale OCR service asynchronously"""
        try:
            logger.info("ğŸŒ Initializing Tailscale OCR client connection...")
            success = await self.ocr_service.initialize()
            if success:
                logger.info("âœ… Tailscale OCR client initialized successfully")
                logger.info(f"ğŸ”— Connected to: {self.ocr_service.host}:{self.ocr_service.port}")
            else:
                logger.error("âŒ Tailscale OCR client initialization failed")
                logger.error("ğŸš¨ EC2 server cannot start without local OCR service connection")
            return success
        except Exception as e:
            logger.error(f"âŒ Tailscale OCR client initialization error: {e}")
            logger.error("ğŸš¨ EC2 server requires Tailscale OCR service to be running")
            return False
    
    # í€´ì¦ˆ ìƒì„±ê³¼ êµì • ê¸°ëŠ¥ì€ ë‚˜ì¤‘ì— êµ¬í˜„ ì˜ˆì •ìœ¼ë¡œ ì œê±°
    
    async def InitializeDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± ë…ì„œ ëª¨ì„ í† ë¡  ì‹œì‘ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ¯ Starting mobile discussion for meeting: {request.meeting_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì‹œì‘
            result = await self.discussion_service.start_discussion(
                document_id=request.document_id,
                meeting_id=request.meeting_id,
                session_id=request.session_id, 
                participants=[{"user_id": p.user_id, "nickname": p.nickname} for p in request.participants]
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion started for session: {request.session_id}")
                response = ai_service_pb2.DiscussionInitResponse(
                    success=True, 
                    message=result.get("message", "Discussion started successfully")
                )
                
                # í† ë¡  ì£¼ì œê°€ ìˆìœ¼ë©´ ì¶”ê°€
                if "discussion_topics" in result and result["discussion_topics"]:
                    response.discussion_topics.extend(result["discussion_topics"])
                if "recommended_topic" in result:
                    response.recommended_topic = result["recommended_topic"]
                    
                return response
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to start discussion"))
                return None

        except Exception as e:
            logger.error(f"Discussion initialization failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessChatMessage(self, request_iterator, context):
        """ëª¨ë°”ì¼ ì•± ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬ - ì±„íŒ… ê¸°ë¡ ì»¨í…ìŠ¤íŠ¸ ì§€ì›"""
        session_id = None
        try:
            first_request = await anext(request_iterator)
            session_id = first_request.discussion_session_id
            
            logger.info(f"ğŸ—¨ï¸ Starting chat stream for session: {session_id}")
            await self.discussion_service.register_stream(session_id, context)

            async def message_generator():
                yield first_request
                async for req in request_iterator:
                    yield req

            async for request in message_generator():
                try:
                    # ChatMessageRequest í•„ë“œ ì‚¬ìš©
                    message_text = request.message
                    sender = request.sender  # User ê°ì²´
                    current_session_id = request.discussion_session_id
                    
                    # meeting_id ì¶”ì¶œ (session_idì—ì„œ íŒŒì‹±í•˜ê±°ë‚˜ ê¸°ë³¸ê°’ ì‚¬ìš©)
                    meeting_id = current_session_id.split('_')[0] if '_' in current_session_id else 'default_meeting'
                    
                    # ë©”ì‹œì§€ ë°ì´í„° êµ¬ì„±
                    message_data = {
                        "message": message_text,
                        "sender": {
                            "user_id": sender.user_id,
                            "nickname": sender.nickname
                        },
                        "sender_nickname": sender.nickname  # ë°±ì›Œë“œ í˜¸í™˜ì„±
                    }
                    
                    logger.debug(f"Processing message from {sender.nickname}: {message_text[:50]}...")
                    
                    # Discussion Serviceë¥¼ í†µí•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ
                    async for response_chunk in self.discussion_service.process_bookclub_chat_message_stream(
                        meeting_id=meeting_id,
                        session_id=current_session_id,
                        message_data=message_data
                    ):
                        if response_chunk:  # ë¹ˆ ì²­í¬ í•„í„°ë§
                            yield ai_service_pb2.ChatMessageResponse(
                                success=True,
                                ai_response=response_chunk,
                                message="AI response chunk",
                                suggested_topics=[],
                                requires_moderation=False,
                                context_messages_used=3,  # ê¸°ë³¸ê°’
                                chat_history_enabled=True,
                                recent_context=""
                            )
                    
                    logger.debug(f"âœ… Message processed for session {current_session_id}")
                    
                except Exception as msg_error:
                    logger.error(f"Failed to process individual message in session {session_id}: {msg_error}")
                    # ê°œë³„ ë©”ì‹œì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œì—ë„ ìŠ¤íŠ¸ë¦¼ ìœ ì§€
                    yield ai_service_pb2.ChatMessageResponse(
                        success=False,
                        message=f"ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(msg_error)}",
                        ai_response="ì£„ì†¡í•©ë‹ˆë‹¤. ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                        suggested_topics=[],
                        requires_moderation=False,
                        context_messages_used=0,
                        chat_history_enabled=True,
                        recent_context=""
                    )

        except (grpc.aio.AioRpcError, asyncio.CancelledError) as e:
            logger.info(f"Client disconnected from session {session_id}: {e})")
        except StopAsyncIteration:
            logger.info(f"Client stream finished for session {session_id}")
        except Exception as e:
            logger.error(f"Chat stream failed for session {session_id}: {e}")
            if not context.done():
                await context.abort(grpc.StatusCode.INTERNAL, f"Chat error: {str(e)}")
        finally:
            if session_id:
                await self.discussion_service.unregister_stream(session_id, context)
                logger.info(f"Cleaned up stream for session {session_id}")
    
    async def EndDiscussion(self, request, context):
        """ëª¨ë°”ì¼ ì•± í† ë¡  ì¢…ë£Œ - ê°„ì†Œí™”ëœ ë²„ì „"""
        try:
            logger.info(f"ğŸ Ending mobile discussion for session: {request.session_id}")

            if not self.settings.ai.ENABLE_DISCUSSION_AI:
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("Discussion AI is disabled")
                return None

            # ê°„ì†Œí™”ëœ í† ë¡  ì¢…ë£Œ
            result = await self.discussion_service.end_discussion(
                meeting_id=request.meeting_id,
                session_id=request.session_id
            )

            if result["success"]:
                logger.info(f"âœ… Mobile discussion ended for session: {request.session_id}")
                return ai_service_pb2.DiscussionEndResponse(
                    success=True,
                    message=result.get("message", "Discussion ended successfully")
                )
            else:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("error", "Failed to end discussion"))
                return None

        except Exception as e:
            logger.error(f"Failed to end discussion: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def EndMeeting(self, request, context):
        """í†µí•© ëª¨ì„ ì¢…ë£Œ API - ëª¨ë“  ëª¨ì„ íƒ€ì… ì§€ì›"""
        try:
            logger.info(f"ğŸ Ending {request.meeting_type} meeting: {request.meeting_id}")
            
            # MeetingService ì´ˆê¸°í™” í™•ì¸
            if not self.meeting_service.is_initialized():
                context.set_code(grpc.StatusCode.UNAVAILABLE)
                context.set_details("MeetingService is not initialized")
                return None
            
            # ëª¨ì„ íƒ€ì…ë³„ íŒŒë¼ë¯¸í„° ì¤€ë¹„
            kwargs = {}
            if request.meeting_type == "discussion" and request.HasField("session_id"):
                kwargs["session_id"] = request.session_id
            
            # í†µí•© ëª¨ì„ ì¢…ë£Œ ì²˜ë¦¬
            result = await self.meeting_service.end_meeting(
                meeting_id=request.meeting_id,
                meeting_type=request.meeting_type,
                **kwargs
            )
            
            if result["success"]:
                logger.info(f"âœ… {request.meeting_type.title()} meeting ended: {request.meeting_id}")
                return ai_service_pb2.MeetingEndResponse(
                    success=True,
                    message=result.get("message", f"{request.meeting_type.title()} meeting ended successfully"),
                    meeting_type=request.meeting_type
                )
            else:
                logger.error(f"âŒ Failed to end {request.meeting_type} meeting {request.meeting_id}: {result.get('message')}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(result.get("message", "Failed to end meeting"))
                return None
                
        except Exception as e:
            logger.error(f"Failed to end {request.meeting_type} meeting {request.meeting_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def GetChatHistory(self, request, context):
        """ì±„íŒ… ê¸°ë¡ ì¡°íšŒ"""
        try:
            logger.debug(f"ğŸ“œ Chat history requested for session: {request.session_id}")

            session_id = request.session_id
            limit = getattr(request, 'limit', 10)
            since_timestamp = getattr(request, 'since_timestamp', None)
            user_id = getattr(request, 'user_id', None)

            if not session_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Session ID is required")
                return None

            try:
                # ì±„íŒ… ê¸°ë¡ ë§¤ë‹ˆì €ì—ì„œ ë©”ì‹œì§€ ì¡°íšŒ
                if user_id:
                    # íŠ¹ì • ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë§Œ ì¡°íšŒ
                    messages = await self.discussion_service.chat_history_manager.get_user_messages(
                        session_id, user_id, limit
                    )
                else:
                    # ìµœê·¼ ë©”ì‹œì§€ ì¡°íšŒ
                    messages = await self.discussion_service.chat_history_manager.get_recent_messages(
                        session_id, limit
                    )

                # since_timestamp í•„í„°ë§
                if since_timestamp:
                    messages = [
                        msg for msg in messages 
                        if msg.timestamp.timestamp() > since_timestamp
                    ]

                # ì‘ë‹µ ë©”ì‹œì§€ ìƒì„±
                response_messages = []
                for msg in messages:
                    history_msg = ai_service_pb2.ChatHistoryMessage(
                        message_id=msg.message_id,
                        session_id=msg.session_id,
                        content=msg.content,
                        timestamp=int(msg.timestamp.timestamp()),
                        message_type=msg.message_type.value
                    )
                    
                    # sender ì •ë³´ ì„¤ì •
                    history_msg.sender.user_id = msg.user_id
                    history_msg.sender.nickname = msg.nickname
                    
                    # metadata ì„¤ì •
                    if msg.metadata:
                        for key, value in msg.metadata.items():
                            history_msg.metadata[key] = str(value)
                    
                    response_messages.append(history_msg)

                return ai_service_pb2.GetChatHistoryResponse(
                    success=True,
                    message="Chat history retrieved successfully",
                    messages=response_messages,
                    total_count=len(response_messages),
                    has_more=len(response_messages) >= limit
                )

            except Exception as e:
                logger.error(f"Failed to get chat history: {e}")
                return ai_service_pb2.GetChatHistoryResponse(
                    success=False,
                    message=f"Failed to retrieve chat history: {str(e)}",
                    messages=[],
                    total_count=0,
                    has_more=False
                )

        except Exception as e:
            logger.error(f"GetChatHistory failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def GetChatSessionStats(self, request, context):
        """ì±„íŒ… ì„¸ì…˜ í†µê³„ ì¡°íšŒ"""
        try:
            logger.debug(f"ğŸ“Š Chat session stats requested for: {request.session_id}")

            session_id = request.session_id
            if not session_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Session ID is required")
                return None

            try:
                # ì„¸ì…˜ í†µê³„ ì¡°íšŒ
                stats = await self.discussion_service.get_chat_history_stats(session_id)
                
                if "error" in stats:
                    return ai_service_pb2.ChatSessionStatsResponse(
                        success=False,
                        message=f"Failed to get session stats: {stats['error']}",
                        session_id=session_id,
                        chat_history_enabled=False
                    )

                # ì°¸ì—¬ì í†µê³„ ìƒì„±
                participant_stats = []
                if "participant_engagement" in stats:
                    for user_id, engagement in stats["participant_engagement"].items():
                        participant_stat = ai_service_pb2.ParticipantStats(
                            message_count=stats.get("participant_message_counts", {}).get(user_id, 0),
                            last_activity=int(stats.get("last_activity_times", {}).get(user_id, 0)),
                            engagement_level=engagement
                        )
                        participant_stat.participant.user_id = user_id
                        participant_stat.participant.nickname = stats.get("participant_nicknames", {}).get(user_id, user_id)
                        participant_stats.append(participant_stat)

                return ai_service_pb2.ChatSessionStatsResponse(
                    success=True,
                    message="Session stats retrieved successfully",
                    session_id=session_id,
                    total_messages=stats.get("message_count", 0),
                    total_participants=stats.get("participant_count", 0),
                    participant_stats=participant_stats,
                    session_start_time=int(stats.get("created_at", 0)),
                    last_activity_time=int(stats.get("last_activity", 0)),
                    chat_history_enabled=stats.get("chat_history_enabled", False)
                )

            except Exception as e:
                logger.error(f"Failed to get session stats: {e}")
                return ai_service_pb2.ChatSessionStatsResponse(
                    success=False,
                    message=f"Failed to retrieve session stats: {str(e)}",
                    session_id=session_id,
                    chat_history_enabled=False
                )

        except Exception as e:
            logger.error(f"GetChatSessionStats failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
            
    # ì‚¬ìš©ì ë¶„ì„ ê¸°ëŠ¥ì€ ëª¨ë°”ì¼ ì•±ì—ì„œ ë¶ˆí•„ìš”í•˜ë¯€ë¡œ ì œê±°

    async def GenerateQuiz(self, request, context):
        """Generate quiz based on progress percentage (50% or 100%)"""
        try:
            logger.info(f"Quiz generation requested for document: {request.document_id}, meeting: {request.meeting_id}, progress: {request.progress_percentage}%")
            
            # DEBUG: QuizService ìƒíƒœ í™•ì¸
            logger.info(f"ğŸ” DEBUG - AIServicer QuizService: {'Available' if self.quiz_service else 'None'}")
            if self.quiz_service:
                logger.info(f"ğŸ” DEBUG - QuizService VectorDB: {'Available' if self.quiz_service.vector_db else 'None'}")

            doc_id = request.document_id
            meeting_id = request.meeting_id
            progress = request.progress_percentage
            
            if not doc_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID is required")
                return None

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Meeting ID is required")
                return None

            if progress not in [50, 100]:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Progress percentage must be 50 or 100")
                return None

            # QuizServiceë¥¼ í†µí•œ í€´ì¦ˆ ìƒì„± (ë²¡í„°DB ì—°ë™ì€ QuizService ë‚´ë¶€ì—ì„œ ì²˜ë¦¬)
            quiz_data = {
                "document_id": doc_id,
                "meeting_id": meeting_id,
                "progress_percentage": progress
            }
            
            # QuizService ì´ˆê¸°í™” í™•ì¸
            if not self.quiz_service:
                logger.warning("QuizService not initialized, using mock data")
                # Fallback to basic mock quiz (4 questions fixed)
                questions = [
                    ai_service_pb2.Question(
                        question_text=f"ë¬¸ì„œ {progress}% ì§„ë„ì˜ ì£¼ìš” ë‚´ìš©ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        options=["ê¸°ë³¸ ê°œë…", "ì‹¬í™” ë‚´ìš©", "ì‘ìš© ì‚¬ë¡€", "ì°¸ê³  ìë£Œ"],
                        correct_answer_index=0
                    ),
                    ai_service_pb2.Question(
                        question_text=f"{progress}% ì§„ë„ì—ì„œ ë‹¤ë£¨ëŠ” í•µì‹¬ ì£¼ì œëŠ”?",
                        options=["ì£¼ì œ A", "ì£¼ì œ B", "ì£¼ì œ C", "ì£¼ì œ D"],
                        correct_answer_index=1
                    ),
                    ai_service_pb2.Question(
                        question_text=f"ë¬¸ì„œ {progress}% êµ¬ê°„ì˜ íŠ¹ì§•ì€?",
                        options=["ë„ì…ë¶€", "ì „ê°œë¶€", "ì‹¬í™”ë¶€", "ê²°ë¡ ë¶€"],
                        correct_answer_index=2 if progress == 100 else 0
                    ),
                    ai_service_pb2.Question(
                        question_text=f"{progress}% ì§„ë„ ì™„ë£Œ ì‹œ ì´í•´í•  ìˆ˜ ìˆëŠ” ê²ƒì€?",
                        options=["ê¸°ì´ˆ ì´í•´", "ë¶€ë¶„ ì´í•´", "ì „ì²´ ì´í•´", "ì‹¬í™” ì´í•´"],
                        correct_answer_index=3 if progress == 100 else 1
                    )
                ]
                quiz_id = f"quiz_{uuid.uuid4().hex[:8]}"
            else:
                # ì‹¤ì œ QuizServiceë¥¼ í†µí•œ í€´ì¦ˆ ìƒì„±
                result = await self.quiz_service.generate_quiz(quiz_data)
                
                if result["success"]:
                    questions = []
                    for q in result["questions"]:
                        # QuizServiceì—ì„œ ì˜¤ëŠ” ë°ì´í„° êµ¬ì¡°ë¥¼ gRPC êµ¬ì¡°ë¡œ ë³€í™˜
                        questions.append(ai_service_pb2.Question(
                            question_text=q.get("question", q.get("question_text", "")),
                            options=q.get("options", []),
                            correct_answer_index=q.get("correct_answer", q.get("correct_answer_index", 0))
                        ))
                    quiz_id = result["quiz_id"]
                    logger.info(f"âœ… Successfully generated quiz with {len(questions)} questions")
                else:
                    logger.error(f"Quiz generation failed: {result.get('error')}")
                    return ai_service_pb2.QuizResponse(
                        success=False,
                        message=result.get("error", "Quiz generation failed")
                    )
            
            logger.info(f"ğŸ¯ Returning quiz response with {len(questions)} questions")
            return ai_service_pb2.QuizResponse(
                success=True,
                message="Quiz generated successfully",
                questions=questions,
                quiz_id=quiz_id
            )

        except Exception as e:
            logger.error(f"Quiz generation failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None

    async def ProofreadText(self, request, context):
        """Proofread and correct text for grammar and context"""
        try:
            logger.info(f"Text proofreading requested from user: {request.user.nickname}")

            original_text = request.original_text.text
            context_text = request.context_text.text if request.context_text else ""
            
            if not original_text:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Original text is required")
                return None

            # ProofreadingServiceë¥¼ í†µí•œ ì‹¤ì œ ì²¨ì‚­ ì²˜ë¦¬
            proofread_data = {
                "original_text": original_text,
                "context_text": context_text,
                "language": request.original_text.language or "ko",
                "user_id": request.user.user_id
            }
            
            # ProofreadingService ì´ˆê¸°í™” í™•ì¸
            if not self.proofreading_service:
                logger.warning("ProofreadingService not initialized, using fallback")
                # Fallback response
                return ai_service_pb2.ProofreadResponse(
                    success=True,
                    message="Proofreading service not available (using fallback)",
                    corrected_text=original_text,
                    corrections=[],
                    confidence_score=0.5
                )
            
            # ì‹¤ì œ ProofreadingServiceë¥¼ í†µí•œ ì²¨ì‚­ ì²˜ë¦¬
            result = await self.proofreading_service.proofread_text(proofread_data)
            
            if result["success"]:
                corrections = []
                for correction in result.get("corrections", []):
                    corrections.append(ai_service_pb2.TextCorrection(
                        original=correction.get("original", ""),
                        corrected=correction.get("corrected", ""),
                        correction_type=correction.get("type", "grammar"),
                        explanation=correction.get("explanation", ""),
                        start_position=correction.get("start_position", 0),
                        end_position=correction.get("end_position", 0)
                    ))
                
                return ai_service_pb2.ProofreadResponse(
                    success=True,
                    message="Text proofreading completed",
                    corrected_text=result.get("corrected_text", original_text),
                    corrections=corrections,
                    confidence_score=result.get("confidence_score", 0.85)
                )
            else:
                return ai_service_pb2.ProofreadResponse(
                    success=False,
                    message=result.get("error", "Proofreading failed")
                )

        except Exception as e:
            logger.error(f"Text proofreading failed: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal error: {str(e)}")
            return None
    
    async def ProcessPdf(self, request_iterator, context):
        """Process PDF stream, perform OCR, and store results in VectorDB automatically"""
        document_id = None
        file_name = None
        metadata = {}
        meeting_id = None
        pdf_data_chunks = []

        try:
            async for request in request_iterator:
                if request.HasField("info"):
                    # First message should contain PdfInfo
                    document_id = request.info.document_id or str(uuid.uuid4())
                    file_name = request.info.file_name
                    meeting_id = request.info.meeting_id  # ì§ì ‘ í•„ë“œì—ì„œ ê°€ì ¸ì˜¤ê¸°
                    metadata = dict(request.info.metadata)
                    logger.info(f"Received PDF info for document: {document_id}, file: {file_name}, meeting: {meeting_id}")
                elif request.HasField("chunk"):
                    # Subsequent messages contain PDF data chunks
                    pdf_data_chunks.append(request.chunk)
                else:
                    logger.warning("Received unknown message type in ProcessPdf stream.")

            if not document_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID not provided in PdfInfo.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="Document ID missing.")

            if not pdf_data_chunks:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("No PDF data chunks received.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="No PDF data.")

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required.")
                return ai_service_pb2.ProcessPdfResponse(success=False, message="meeting_id missing.")

            full_pdf_data = b"".join(pdf_data_chunks)

            logger.info(f"ğŸ“„ Processing PDF with response for meeting {meeting_id}, document: {document_id}")

            # OCR ì²˜ë¦¬
            ocr_result = await self.ocr_service.process_pdf_stream(full_pdf_data, document_id)

            if not ocr_result["success"]:
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"OCR processing failed: {ocr_result.get('error', 'Unknown error')}")
                return ai_service_pb2.ProcessPdfResponse(success=False, message=ocr_result.get('error', 'OCR failed'))

            # OCR ê²°ê³¼ ì¶”ì¶œ
            full_text = ocr_result.get("full_text", "")
            page_texts = ocr_result.get("page_texts", [])
            total_pages = ocr_result.get("total_pages", 0)
            
            # ë²¡í„°DBì— ìë™ ì €ì¥ (meeting_idë³„ë¡œ ê²©ë¦¬)
            try:
                chunk_ids = await self.vector_db_manager.process_bookclub_document(
                    meeting_id=meeting_id,
                    document_id=document_id,
                    text=full_text,
                    metadata={
                        "file_name": file_name,
                        "total_pages": total_pages,
                        "processing_type": "ocr",
                        **metadata
                    }
                )
                logger.info(f"âœ… PDF processed and stored in VectorDB: {len(chunk_ids)} chunks created for meeting {meeting_id}")
            except Exception as e:
                logger.error(f"Failed to store PDF in vector DB: {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"Failed to store in vector DB: {str(e)}")
                return ai_service_pb2.ProcessPdfResponse(
                    success=False, 
                    message=f"VectorDB storage failed: {str(e)}",
                    document_id=document_id
                )

            # ì‹¤ì œ OCR ë¸”ë¡ë³„ ì‘ë‹µ - ìœ„ì¹˜ ì •ë³´ í¬í•¨
            response_text_blocks = []
            
            # OCR ê²°ê³¼ì—ì„œ ì‹¤ì œ ë¸”ë¡ ì •ë³´ ì‚¬ìš© (íƒ€ì… ì•ˆì „ì„± ê²€ì‚¬ í¬í•¨)
            text_blocks_data = ocr_result.get("ocr_blocks", [])
            if not isinstance(text_blocks_data, list):
                logger.warning(f"ocr_blocks is not a list: {type(text_blocks_data)}")
                text_blocks_data = []
                
            for ocr_block in text_blocks_data:
                # OCRBlock ê°ì²´ì—ì„œ ì†ì„± ì§ì ‘ ì ‘ê·¼
                try:
                    response_text_blocks.append(ai_service_pb2.TextBlock(
                        text=str(ocr_block.text),
                        page_number=int(ocr_block.page_number),
                        x0=float(ocr_block.bbox.x0),
                        y0=float(ocr_block.bbox.y0), 
                        x1=float(ocr_block.bbox.x1),
                        y1=float(ocr_block.bbox.y1),
                        block_type=str(ocr_block.block_type),
                        confidence=float(ocr_block.confidence)
                    ))
                except (ValueError, TypeError, AttributeError) as e:
                    logger.warning(f"Failed to convert OCRBlock data: {e}, block: {ocr_block}")
                    continue

            return ai_service_pb2.ProcessPdfResponse(
                success=True,
                message="PDF OCR processing and vector DB storage completed successfully",
                document_id=document_id,
                total_pages=total_pages,
                text_blocks=response_text_blocks
            )

        except Exception as e:
            logger.error(f"Error in ProcessPdf RPC for document {document_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal server error: {str(e)}")
            return ai_service_pb2.ProcessPdfResponse(success=False, message=f"Internal error: {str(e)}")

    async def ProcessPdfStream(self, request_iterator, context):
        """Process PDF stream with fire-and-forget approach (no response data)"""
        document_id = None
        file_name = None
        metadata = {}
        meeting_id = None
        pdf_data_chunks = []

        try:
            async for request in request_iterator:
                if request.HasField("info"):
                    # First message should contain PdfInfo
                    document_id = request.info.document_id
                    file_name = request.info.file_name
                    meeting_id = request.info.meeting_id
                    metadata = dict(request.info.metadata)
                    logger.info(f"Received PDF info for fire-and-forget processing: {document_id}, file: {file_name}, meeting: {meeting_id}")
                elif request.HasField("chunk"):
                    # Subsequent messages contain PDF data chunks
                    pdf_data_chunks.append(request.chunk)
                else:
                    logger.warning("Received unknown message type in ProcessPdfStream stream.")

            if not document_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("Document ID not provided in PdfInfo.")
                return

            if not pdf_data_chunks:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("No PDF data chunks received.")
                return

            if not meeting_id:
                context.set_code(grpc.StatusCode.INVALID_ARGUMENT)
                context.set_details("meeting_id is required.")
                return

            full_pdf_data = b"".join(pdf_data_chunks)

            logger.info(f"ğŸ“„ Processing PDF fire-and-forget for meeting {meeting_id}, document: {document_id}")

            # OCR ì²˜ë¦¬
            ocr_result = await self.ocr_service.process_pdf_stream(full_pdf_data, document_id)

            if not ocr_result["success"]:
                logger.error(f"OCR processing failed for {document_id}: {ocr_result.get('error', 'Unknown error')}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"OCR processing failed: {ocr_result.get('error', 'Unknown error')}")
                return

            # OCR ê²°ê³¼ ì¶”ì¶œ (ì‘ë‹µìš© ë°ì´í„°ëŠ” ìƒì„±í•˜ì§€ ì•ŠìŒ)
            full_text = ocr_result.get("full_text", "")
            total_pages = ocr_result.get("total_pages", 0)
            
            # ë²¡í„°DBì— ìë™ ì €ì¥ (meeting_idë³„ë¡œ ê²©ë¦¬)
            try:
                chunk_ids = await self.vector_db_manager.process_bookclub_document(
                    meeting_id=meeting_id,
                    document_id=document_id,
                    text=full_text,
                    metadata={
                        "file_name": file_name,
                        "total_pages": total_pages,
                        "processing_type": "ocr_stream",
                        **metadata
                    }
                )
                logger.info(f"âœ… PDF processed and stored in VectorDB (fire-and-forget): {len(chunk_ids)} chunks created for meeting {meeting_id}")
            except Exception as e:
                logger.error(f"Failed to store PDF in vector DB (fire-and-forget): {e}")
                context.set_code(grpc.StatusCode.INTERNAL)
                context.set_details(f"Failed to store in vector DB: {str(e)}")
                return

            # Fire-and-forget: ì‘ë‹µ ë°ì´í„° ìƒì„±í•˜ì§€ ì•Šê³  Empty ë°˜í™˜
            from google.protobuf.empty_pb2 import Empty
            return Empty()

        except Exception as e:
            logger.error(f"Error in ProcessPdfStream RPC for document {document_id}: {e}")
            context.set_code(grpc.StatusCode.INTERNAL)
            context.set_details(f"Internal server error: {str(e)}")
            return

    async def cleanup(self):
        """Clean up resources when shutting down"""
        try:
            if hasattr(self, 'discussion_service'):
                await self.discussion_service.cleanup()
                logger.info("DiscussionService cleaned up")
        except Exception as e:
            logger.error(f"Error during AIServicer cleanup: {e}")
    
    # ë¶ˆí•„ìš”í•œ response builder ë©”ì„œë“œë“¤ ì œê±° (í€´ì¦ˆ, êµì •, ì‚¬ìš©ì ë¶„ì„ ê´€ë ¨)